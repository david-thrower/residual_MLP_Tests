{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "add2f2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_SET_SIZE = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d224726b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.5.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.3 MB 8.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (21.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (2.8.2)\n",
      "Collecting pillow>=6.2.0\n",
      "  Downloading Pillow-9.0.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.3 MB 27.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (1.19.4)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.3.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 27.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.28.5-py3-none-any.whl (890 kB)\n",
      "\u001b[K     |████████████████████████████████| 890 kB 24.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (2.4.7)\n",
      "Collecting cycler>=0.10\n",
      "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7->matplotlib) (1.15.0)\n",
      "Installing collected packages: pillow, kiwisolver, fonttools, cycler, matplotlib\n",
      "Successfully installed cycler-0.11.0 fonttools-4.28.5 kiwisolver-1.3.2 matplotlib-3.5.1 pillow-9.0.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.8/dist-packages (0.13.1)\n",
      "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.8/dist-packages (from tensorflow-addons) (2.12.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting pandas\n",
      "  Downloading pandas-1.3.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.5 MB 21.6 MB/s eta 0:00:01    |███████████████████████▉        | 8.6 MB 21.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (1.19.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "Installing collected packages: pandas\n",
      "Successfully installed pandas-1.3.5\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting pendulum\n",
      "  Downloading pendulum-2.1.2-cp38-cp38-manylinux1_x86_64.whl (155 kB)\n",
      "\u001b[K     |████████████████████████████████| 155 kB 25.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pytzdata>=2020.1\n",
      "  Downloading pytzdata-2020.1-py2.py3-none-any.whl (489 kB)\n",
      "\u001b[K     |████████████████████████████████| 489 kB 28.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil<3.0,>=2.6 in /usr/local/lib/python3.8/dist-packages (from pendulum) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil<3.0,>=2.6->pendulum) (1.15.0)\n",
      "Installing collected packages: pytzdata, pendulum\n",
      "Successfully installed pendulum-2.1.2 pytzdata-2020.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.3.0 and strictly below 2.6.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.6.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "! pip3 install matplotlib\n",
    "! pip3 install tensorflow-addons\n",
    "! pip3 install pandas\n",
    "! pip3 install pendulum\n",
    "import os\n",
    "import pendulum\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_addons as tfa\n",
    "from residualmlp.residual_mlp import ResidualMLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99355821",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "weight_decay = 0.0001\n",
    "batch_size = 50\n",
    "num_epochs = 100\n",
    "image_size = 32  # We'll resize input images to this size\n",
    "patch_size = 6  # Size of the patches to be extract from the input images\n",
    "num_patches = (image_size // patch_size) ** 2\n",
    "projection_dim = 64\n",
    "num_heads = 4\n",
    "transformer_units = [\n",
    "    projection_dim * 2,\n",
    "    projection_dim,\n",
    "]  # Size of the transformer layers\n",
    "transformer_layers = 5\n",
    "mlp_head_units = [2048, 1024]  # Size of the dense layers of the final classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "877f41fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 8s 0us/step\n",
      "170508288/170498071 [==============================] - 8s 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-15 20:23:39.410601: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-15 20:23:39.421297: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-15 20:23:39.422886: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-15 20:23:39.424783: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-15 20:23:39.425402: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-15 20:23:39.425958: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-15 20:23:40.795281: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-15 20:23:40.795922: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-15 20:23:40.796473: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-15 20:23:40.797003: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6695 MB memory:  -> device: 0, name: Quadro RTX 4000, pci bus id: 0000:00:05.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "cifar = tf.keras.datasets.cifar10.load_data()\n",
    "(x_train, y_train), (x_test, y_test) = cifar\n",
    "\n",
    "y_train_ohe = tf.one_hot([i[0] for i in y_train], 10)\n",
    "indexes_for_rows = tf.range(0, y_train.shape[0])\n",
    "shuffled_indexes = tf.random.shuffle(indexes_for_rows)\n",
    "selected_indexes = shuffled_indexes[:TRAINING_SET_SIZE]\n",
    "selected_x_train = x_train[selected_indexes, :, :, :]\n",
    "selected_y_train_ohe = y_train_ohe.numpy()[selected_indexes, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5c63047",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-15 20:23:54.154349: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    }
   ],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.Normalization(),\n",
    "        layers.Resizing(image_size, image_size),\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(factor=0.02),\n",
    "        layers.RandomZoom(\n",
    "            height_factor=0.2, width_factor=0.2\n",
    "        ),\n",
    "    ],\n",
    "    name=\"data_augmentation\",\n",
    ")\n",
    "data_augmentation.layers[0].adapt(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4759d34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Patches(layers.Layer):\n",
    "    def __init__(self, patch_size):\n",
    "        super(Patches, self).__init__()\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    def call(self, images):\n",
    "        batch_size = tf.shape(images)[0]\n",
    "        patches = tf.image.extract_patches(\n",
    "            images=images,\n",
    "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
    "            strides=[1, self.patch_size, self.patch_size, 1],\n",
    "            rates=[1, 1, 1, 1],\n",
    "            padding=\"VALID\",\n",
    "        )\n",
    "        patch_dims = patches.shape[-1]\n",
    "        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
    "        return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "efbae6ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 31.5, 31.5, -0.5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(4, 4))\n",
    "image = x_train[np.random.choice(range(x_train.shape[0]))]\n",
    "plt.imshow(image.astype(\"uint8\"))\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8477d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image size: 32 X 32\n",
      "Patch size: 6 X 6\n",
      "Patches per image: 25\n",
      "Elements per patch: 108\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "resized_image = tf.image.resize(\n",
    "    tf.convert_to_tensor([image]), size=(image_size, image_size)\n",
    ")\n",
    "\n",
    "patches = Patches(patch_size)(resized_image)\n",
    "print(f\"Image size: {image_size} X {image_size}\")\n",
    "print(f\"Patch size: {patch_size} X {patch_size}\")\n",
    "print(f\"Patches per image: {patches.shape[1]}\")\n",
    "print(f\"Elements per patch: {patches.shape[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9e587e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 25 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = int(np.sqrt(patches.shape[1]))\n",
    "plt.figure(figsize=(4, 4))\n",
    "for i, patch in enumerate(patches[0]):\n",
    "    ax = plt.subplot(n, n, i + 1)\n",
    "    patch_img = tf.reshape(patch, (patch_size, patch_size, 3))\n",
    "    plt.imshow(patch_img.numpy().astype(\"uint8\"))\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64743dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchEncoder(layers.Layer):\n",
    "    def __init__(self, num_patches, projection_dim):\n",
    "        super(PatchEncoder, self).__init__()\n",
    "        self.num_patches = num_patches\n",
    "        self.projection = layers.Dense(units=projection_dim)\n",
    "        self.position_embedding = layers.Embedding(\n",
    "            input_dim=num_patches, output_dim=projection_dim\n",
    "        )\n",
    "\n",
    "    def call(self, patch):\n",
    "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
    "        encoded = self.projection(patch) + self.position_embedding(positions)\n",
    "        return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3431a5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(x, hidden_units, dropout_rate):\n",
    "    for units in hidden_units:\n",
    "        x = layers.Dense(units, activation=tf.nn.gelu)(x)\n",
    "        x = layers.Dropout(dropout_rate)(x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ebf8c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vit_classifier(vit_base_model_input_shape = (32, 32, 3)):\n",
    "    \n",
    "    inputs = layers.Input(shape=vit_base_model_input_shape)\n",
    "    # Augment data.\n",
    "    augmented = data_augmentation(inputs)\n",
    "    # Create patches.\n",
    "    patches = Patches(patch_size)(augmented)\n",
    "    # Encode patches.\n",
    "    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n",
    "\n",
    "    # Create multiple layers of the Transformer block.\n",
    "    for _ in range(transformer_layers):\n",
    "        # Layer normalization 1.\n",
    "        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "        # Create a multi-head attention layer.\n",
    "        attention_output = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n",
    "        )(x1, x1)\n",
    "        # Skip connection 1.\n",
    "        x2 = layers.Add()([attention_output, encoded_patches])\n",
    "        # Layer normalization 2.\n",
    "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "        # MLP.\n",
    "        x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1) # x3 = residual_mlp\n",
    "        # Skip connection 2.\n",
    "        encoded_patches = layers.Add()([x3, x2])\n",
    "\n",
    "    # Create a [batch_size, projection_dim] tensor.\n",
    "    representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "    representation = layers.Flatten()(representation)\n",
    "    #representation = layers.Dropout(0.5)(representation)\n",
    "    # Add MLP.\n",
    "    #features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=0.5)\n",
    "    # Classify outputs.\n",
    "    #logits = layers.Dense(num_classes)(features)\n",
    "    # Create the Keras model.\n",
    "    \n",
    "    model = keras.Model(inputs=inputs, outputs=representation)\n",
    "    return model\n",
    "    \n",
    "    #model = keras.Model(inputs=inputs, outputs=logits)\n",
    "    #return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85af28b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_vit_model = create_vit_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32062384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 1600), dtype=float32, numpy=\n",
       "array([[ 0.49078047,  0.31151557,  0.64080226, ..., -0.32111868,\n",
       "        -0.04143965, -1.0459325 ],\n",
       "       [-0.9078791 , -0.27025563, -0.12527007, ...,  1.4019847 ,\n",
       "        -0.77094096, -1.1154503 ],\n",
       "       [-0.15557054,  0.19950968, -1.4693693 , ...,  1.9437548 ,\n",
       "        -0.62334067, -0.818525  ],\n",
       "       [ 0.6794414 ,  0.30951262,  0.86282116, ...,  1.2000384 ,\n",
       "        -0.06587029, -1.4938909 ],\n",
       "       [-0.10811228,  0.15729457, -0.8868206 , ...,  1.0465517 ,\n",
       "        -0.8012762 , -1.1354169 ]], dtype=float32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_vit_model(x_train[:5])  # (tf.keras.layers.Resizing(600,600)(x_train[:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0cd76a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_mlp = ResidualMLP(problem_type = 'classification', #\n",
    "                      learning_rate = .0007, #\n",
    "                      input_shape = (32, 32, 3), #(32,32,3), #\n",
    "                      bw_images = False, #\n",
    "                      base_model = base_vit_model, #\n",
    "                      base_model_input_shape = (32, 32, 3),  # (600,600,3), #\n",
    "                      flatten_after_base_model = False, #\n",
    "                      blocks = [[7, 75, 8], [5, 75, 10]], #\n",
    "                      residual_bypass_dense_layers = [[5],[5]], #\n",
    "                      b_norm_or_dropout_residual_bypass_layers = 'dropout', #\n",
    "                      dropout_rate_for_bypass_layers = .7, #\n",
    "                      inter_block_layers_per_block = [10],\n",
    "                      b_norm_or_dropout_last_layers = 'dropout', # | 'bnorm'\n",
    "                      dropout_rate = .18, #\n",
    "                      activation = tf.keras.activations.relu, #\n",
    "                      final_dense_layers = [15], #\n",
    "                      number_of_classes = 10, # 1 if a regression problem\n",
    "                      # final_activation = tf.keras.activations.softmax, #\n",
    "                      #loss = tf.keras.losses.CategoricalCrossentropy(\n",
    "                      #    from_logits=False)\n",
    "                     )\n",
    "final_residual_mlp = res_mlp.make_tandem_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5535dafc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "resizing_4 (Resizing)           (None, 32, 32, 3)    0           input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model (Functional)              (None, 1600)         424711      resizing_4[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_68 (Dense)                (None, 75)           120075      model[3][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 75)           300         dense_68[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_70 (Dense)                (None, 75)           5700        batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 75)           300         dense_70[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_71 (Dense)                (None, 67)           5092        batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 67)           268         dense_71[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_72 (Dense)                (None, 59)           4012        batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 59)           236         dense_72[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_73 (Dense)                (None, 51)           3060        batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 51)           204         dense_73[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_74 (Dense)                (None, 43)           2236        batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 43)           172         dense_74[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_75 (Dense)                (None, 35)           1540        batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 35)           140         dense_75[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)            (None, 75)           0           dense_68[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_76 (Dense)                (None, 27)           972         batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_69 (Dense)                (None, 5)            380         dropout_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 27)           108         dense_76[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)            (None, 5)            0           dense_69[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 32)           0           batch_normalization_52[0][0]     \n",
      "                                                                 dropout_26[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_77 (Dense)                (None, 10)           330         concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 10)           40          dense_77[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_78 (Dense)                (None, 75)           825         batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 75)           300         dense_78[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_80 (Dense)                (None, 75)           5700        batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 75)           300         dense_80[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_81 (Dense)                (None, 65)           4940        batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 65)           260         dense_81[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_82 (Dense)                (None, 55)           3630        batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 55)           220         dense_82[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_83 (Dense)                (None, 45)           2520        batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 45)           180         dense_83[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)            (None, 75)           0           dense_78[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_84 (Dense)                (None, 35)           1610        batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_79 (Dense)                (None, 5)            380         dropout_27[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 35)           140         dense_84[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_28 (Dropout)            (None, 5)            0           dense_79[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 40)           0           batch_normalization_59[0][0]     \n",
      "                                                                 dropout_28[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_85 (Dense)                (None, 15)           615         concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_29 (Dropout)            (None, 15)           0           dense_85[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_86 (Dense)                (None, 10)           160         dropout_29[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 591,656\n",
      "Trainable params: 590,065\n",
      "Non-trainable params: 1,591\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "final_residual_mlp.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd982210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 10), dtype=float32, numpy=\n",
       "array([[0.10273835, 0.09462484, 0.11345865, 0.10274917, 0.0954433 ,\n",
       "        0.10432092, 0.0917118 , 0.0904271 , 0.10610111, 0.09842474],\n",
       "       [0.10179009, 0.09696132, 0.10791425, 0.10176654, 0.09721432,\n",
       "        0.10260683, 0.09503028, 0.09471188, 0.10353538, 0.09846909],\n",
       "       [0.10076949, 0.09834578, 0.10458307, 0.10085841, 0.09890838,\n",
       "        0.10158468, 0.09654684, 0.09591466, 0.10247664, 0.10001197],\n",
       "       [0.09859677, 0.10026058, 0.10389564, 0.09764789, 0.10367682,\n",
       "        0.10235808, 0.09706433, 0.09413392, 0.09869064, 0.1036753 ],\n",
       "       [0.09984931, 0.09991741, 0.10268176, 0.09880993, 0.10167672,\n",
       "        0.10123231, 0.0984302 , 0.09703466, 0.09952668, 0.10084097]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's verify that this beast can accept inputs and return a valid response ...\n",
    "\n",
    "final_residual_mlp(x_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1b3f063f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-15 20:44:50.587547: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n",
      "2022-01-15 20:44:50.587600: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Layer Patches has arguments in `__init__` and therefore must override `get_config`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-15 20:44:50.987569: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n",
      "2022-01-15 20:44:50.987780: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1749] CUPTI activity buffer flushed\n",
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Layer Patches has arguments in `__init__` and therefore must override `get_config`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "  1/140 [..............................] - ETA: 24:58 - loss: 2.5881 - top_1_categorical_accuracy: 0.0400 - top_2_categorical_accuracy: 0.1200 - top_3_categorical_accuracy: 0.2600 - top_4_categorical_accuracy: 0.4400 - top_5_categorical_accuracy: 0.5200 - top_6_categorical_accuracy: 0.5800 - top_7_categorical_accuracy: 0.7200 - top_8_categorical_accuracy: 0.8200 - top_9_categorical_accuracy: 0.9400 - precision_3: 0.0000e+00 - recall_3: 0.0000e+00 - accuracy: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-15 20:45:02.247746: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n",
      "2022-01-15 20:45:02.247810: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "  2/140 [..............................] - ETA: 1:20 - loss: 2.6269 - top_1_categorical_accuracy: 0.0700 - top_2_categorical_accuracy: 0.1300 - top_3_categorical_accuracy: 0.2300 - top_4_categorical_accuracy: 0.4100 - top_5_categorical_accuracy: 0.5200 - top_6_categorical_accuracy: 0.5900 - top_7_categorical_accuracy: 0.7100 - top_8_categorical_accuracy: 0.8200 - top_9_categorical_accuracy: 0.9300 - precision_3: 0.0000e+00 - recall_3: 0.0000e+00 - accuracy: 0.0000e+00 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-15 20:45:03.173616: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2022-01-15 20:45:03.178188: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1749] CUPTI activity buffer flushed\n",
      "2022-01-15 20:45:03.244020: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:673]  GpuTracer has collected 3462 callback api events and 3479 activity events. \n",
      "2022-01-15 20:45:03.345025: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n",
      "2022-01-15 20:45:03.470857: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: logs/vit-ResidualMLP-image-classifier_2022-01-15_20_44_TB/train/plugins/profile/2022_01_15_20_45_03\n",
      "\n",
      "2022-01-15 20:45:03.532069: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to logs/vit-ResidualMLP-image-classifier_2022-01-15_20_44_TB/train/plugins/profile/2022_01_15_20_45_03/nglsh0r8yv.trace.json.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  5/140 [>.............................] - ETA: 1:07 - loss: 2.6185 - top_1_categorical_accuracy: 0.0760 - top_2_categorical_accuracy: 0.1600 - top_3_categorical_accuracy: 0.2680 - top_4_categorical_accuracy: 0.4080 - top_5_categorical_accuracy: 0.5200 - top_6_categorical_accuracy: 0.6000 - top_7_categorical_accuracy: 0.7000 - top_8_categorical_accuracy: 0.8280 - top_9_categorical_accuracy: 0.9440 - precision_3: 0.0000e+00 - recall_3: 0.0000e+00 - accuracy: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-15 20:45:03.693560: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: logs/vit-ResidualMLP-image-classifier_2022-01-15_20_44_TB/train/plugins/profile/2022_01_15_20_45_03\n",
      "\n",
      "2022-01-15 20:45:03.701396: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to logs/vit-ResidualMLP-image-classifier_2022-01-15_20_44_TB/train/plugins/profile/2022_01_15_20_45_03/nglsh0r8yv.memory_profile.json.gz\n",
      "2022-01-15 20:45:03.722151: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: logs/vit-ResidualMLP-image-classifier_2022-01-15_20_44_TB/train/plugins/profile/2022_01_15_20_45_03\n",
      "Dumped tool data for xplane.pb to logs/vit-ResidualMLP-image-classifier_2022-01-15_20_44_TB/train/plugins/profile/2022_01_15_20_45_03/nglsh0r8yv.xplane.pb\n",
      "Dumped tool data for overview_page.pb to logs/vit-ResidualMLP-image-classifier_2022-01-15_20_44_TB/train/plugins/profile/2022_01_15_20_45_03/nglsh0r8yv.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to logs/vit-ResidualMLP-image-classifier_2022-01-15_20_44_TB/train/plugins/profile/2022_01_15_20_45_03/nglsh0r8yv.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to logs/vit-ResidualMLP-image-classifier_2022-01-15_20_44_TB/train/plugins/profile/2022_01_15_20_45_03/nglsh0r8yv.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to logs/vit-ResidualMLP-image-classifier_2022-01-15_20_44_TB/train/plugins/profile/2022_01_15_20_45_03/nglsh0r8yv.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140/140 [==============================] - 21s 72ms/step - loss: 2.4344 - top_1_categorical_accuracy: 0.1136 - top_2_categorical_accuracy: 0.2143 - top_3_categorical_accuracy: 0.3139 - top_4_categorical_accuracy: 0.4136 - top_5_categorical_accuracy: 0.5141 - top_6_categorical_accuracy: 0.6123 - top_7_categorical_accuracy: 0.7124 - top_8_categorical_accuracy: 0.8093 - top_9_categorical_accuracy: 0.9089 - precision_3: 0.1639 - recall_3: 0.0014 - accuracy: 0.0000e+00 - val_loss: 2.3054 - val_top_1_categorical_accuracy: 0.0807 - val_top_2_categorical_accuracy: 0.1730 - val_top_3_categorical_accuracy: 0.2740 - val_top_4_categorical_accuracy: 0.3757 - val_top_5_categorical_accuracy: 0.4863 - val_top_6_categorical_accuracy: 0.5933 - val_top_7_categorical_accuracy: 0.6920 - val_top_8_categorical_accuracy: 0.8250 - val_top_9_categorical_accuracy: 0.9153 - val_precision_3: 0.0000e+00 - val_recall_3: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "140/140 [==============================] - 7s 50ms/step - loss: 2.3491 - top_1_categorical_accuracy: 0.1046 - top_2_categorical_accuracy: 0.2029 - top_3_categorical_accuracy: 0.3036 - top_4_categorical_accuracy: 0.4053 - top_5_categorical_accuracy: 0.5080 - top_6_categorical_accuracy: 0.6041 - top_7_categorical_accuracy: 0.7027 - top_8_categorical_accuracy: 0.8016 - top_9_categorical_accuracy: 0.9004 - precision_3: 0.0000e+00 - recall_3: 0.0000e+00 - accuracy: 0.0000e+00 - val_loss: 2.2916 - val_top_1_categorical_accuracy: 0.1213 - val_top_2_categorical_accuracy: 0.2267 - val_top_3_categorical_accuracy: 0.3480 - val_top_4_categorical_accuracy: 0.4613 - val_top_5_categorical_accuracy: 0.5597 - val_top_6_categorical_accuracy: 0.6517 - val_top_7_categorical_accuracy: 0.7410 - val_top_8_categorical_accuracy: 0.8333 - val_top_9_categorical_accuracy: 0.9217 - val_precision_3: 0.0000e+00 - val_recall_3: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "140/140 [==============================] - 7s 50ms/step - loss: 2.3059 - top_1_categorical_accuracy: 0.1131 - top_2_categorical_accuracy: 0.2164 - top_3_categorical_accuracy: 0.3320 - top_4_categorical_accuracy: 0.4300 - top_5_categorical_accuracy: 0.5284 - top_6_categorical_accuracy: 0.6257 - top_7_categorical_accuracy: 0.7246 - top_8_categorical_accuracy: 0.8193 - top_9_categorical_accuracy: 0.9143 - precision_3: 0.0000e+00 - recall_3: 0.0000e+00 - accuracy: 0.0000e+00 - val_loss: 2.2959 - val_top_1_categorical_accuracy: 0.1207 - val_top_2_categorical_accuracy: 0.2180 - val_top_3_categorical_accuracy: 0.3277 - val_top_4_categorical_accuracy: 0.4330 - val_top_5_categorical_accuracy: 0.5477 - val_top_6_categorical_accuracy: 0.6420 - val_top_7_categorical_accuracy: 0.7380 - val_top_8_categorical_accuracy: 0.8240 - val_top_9_categorical_accuracy: 0.9157 - val_precision_3: 0.0000e+00 - val_recall_3: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "140/140 [==============================] - 7s 50ms/step - loss: 2.2623 - top_1_categorical_accuracy: 0.1366 - top_2_categorical_accuracy: 0.2559 - top_3_categorical_accuracy: 0.3674 - top_4_categorical_accuracy: 0.4721 - top_5_categorical_accuracy: 0.5666 - top_6_categorical_accuracy: 0.6646 - top_7_categorical_accuracy: 0.7601 - top_8_categorical_accuracy: 0.8510 - top_9_categorical_accuracy: 0.9263 - precision_3: 0.5484 - recall_3: 0.0024 - accuracy: 0.0000e+00 - val_loss: 3.0894 - val_top_1_categorical_accuracy: 0.1087 - val_top_2_categorical_accuracy: 0.2113 - val_top_3_categorical_accuracy: 0.3093 - val_top_4_categorical_accuracy: 0.3860 - val_top_5_categorical_accuracy: 0.4587 - val_top_6_categorical_accuracy: 0.5767 - val_top_7_categorical_accuracy: 0.6723 - val_top_8_categorical_accuracy: 0.7947 - val_top_9_categorical_accuracy: 0.9063 - val_precision_3: 0.0029 - val_recall_3: 3.3333e-04 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "140/140 [==============================] - 7s 51ms/step - loss: 2.1962 - top_1_categorical_accuracy: 0.1584 - top_2_categorical_accuracy: 0.3004 - top_3_categorical_accuracy: 0.4213 - top_4_categorical_accuracy: 0.5327 - top_5_categorical_accuracy: 0.6333 - top_6_categorical_accuracy: 0.7266 - top_7_categorical_accuracy: 0.8093 - top_8_categorical_accuracy: 0.8847 - top_9_categorical_accuracy: 0.9439 - precision_3: 0.4167 - recall_3: 0.0100 - accuracy: 0.0000e+00 - val_loss: 2.1551 - val_top_1_categorical_accuracy: 0.1617 - val_top_2_categorical_accuracy: 0.3217 - val_top_3_categorical_accuracy: 0.4583 - val_top_4_categorical_accuracy: 0.5720 - val_top_5_categorical_accuracy: 0.6873 - val_top_6_categorical_accuracy: 0.7903 - val_top_7_categorical_accuracy: 0.8417 - val_top_8_categorical_accuracy: 0.9017 - val_top_9_categorical_accuracy: 0.9583 - val_precision_3: 0.7500 - val_recall_3: 0.0020 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "140/140 [==============================] - 7s 54ms/step - loss: 2.1312 - top_1_categorical_accuracy: 0.1784 - top_2_categorical_accuracy: 0.3391 - top_3_categorical_accuracy: 0.4689 - top_4_categorical_accuracy: 0.5871 - top_5_categorical_accuracy: 0.6967 - top_6_categorical_accuracy: 0.7837 - top_7_categorical_accuracy: 0.8470 - top_8_categorical_accuracy: 0.9086 - top_9_categorical_accuracy: 0.9577 - precision_3: 0.4693 - recall_3: 0.0120 - accuracy: 0.0000e+00 - val_loss: 2.1335 - val_top_1_categorical_accuracy: 0.1750 - val_top_2_categorical_accuracy: 0.3467 - val_top_3_categorical_accuracy: 0.4943 - val_top_4_categorical_accuracy: 0.6343 - val_top_5_categorical_accuracy: 0.7350 - val_top_6_categorical_accuracy: 0.8273 - val_top_7_categorical_accuracy: 0.8843 - val_top_8_categorical_accuracy: 0.9390 - val_top_9_categorical_accuracy: 0.9763 - val_precision_3: 0.4139 - val_recall_3: 0.0577 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "140/140 [==============================] - 7s 52ms/step - loss: 2.0634 - top_1_categorical_accuracy: 0.2046 - top_2_categorical_accuracy: 0.3729 - top_3_categorical_accuracy: 0.5034 - top_4_categorical_accuracy: 0.6294 - top_5_categorical_accuracy: 0.7300 - top_6_categorical_accuracy: 0.8294 - top_7_categorical_accuracy: 0.8810 - top_8_categorical_accuracy: 0.9267 - top_9_categorical_accuracy: 0.9656 - precision_3: 0.5476 - recall_3: 0.0197 - accuracy: 0.0000e+00 - val_loss: 2.0744 - val_top_1_categorical_accuracy: 0.1987 - val_top_2_categorical_accuracy: 0.3563 - val_top_3_categorical_accuracy: 0.4990 - val_top_4_categorical_accuracy: 0.6367 - val_top_5_categorical_accuracy: 0.7557 - val_top_6_categorical_accuracy: 0.8513 - val_top_7_categorical_accuracy: 0.9017 - val_top_8_categorical_accuracy: 0.9463 - val_top_9_categorical_accuracy: 0.9767 - val_precision_3: 0.6000 - val_recall_3: 0.0040 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "140/140 [==============================] - 7s 51ms/step - loss: 1.9782 - top_1_categorical_accuracy: 0.2317 - top_2_categorical_accuracy: 0.4071 - top_3_categorical_accuracy: 0.5516 - top_4_categorical_accuracy: 0.6800 - top_5_categorical_accuracy: 0.7744 - top_6_categorical_accuracy: 0.8660 - top_7_categorical_accuracy: 0.9100 - top_8_categorical_accuracy: 0.9417 - top_9_categorical_accuracy: 0.9711 - precision_3: 0.5352 - recall_3: 0.0271 - accuracy: 0.0000e+00 - val_loss: 2.0000 - val_top_1_categorical_accuracy: 0.2253 - val_top_2_categorical_accuracy: 0.4247 - val_top_3_categorical_accuracy: 0.5563 - val_top_4_categorical_accuracy: 0.6690 - val_top_5_categorical_accuracy: 0.7603 - val_top_6_categorical_accuracy: 0.8710 - val_top_7_categorical_accuracy: 0.9063 - val_top_8_categorical_accuracy: 0.9357 - val_top_9_categorical_accuracy: 0.9743 - val_precision_3: 0.8421 - val_recall_3: 0.0053 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "140/140 [==============================] - 7s 50ms/step - loss: 1.9171 - top_1_categorical_accuracy: 0.2734 - top_2_categorical_accuracy: 0.4640 - top_3_categorical_accuracy: 0.5997 - top_4_categorical_accuracy: 0.7060 - top_5_categorical_accuracy: 0.7994 - top_6_categorical_accuracy: 0.8784 - top_7_categorical_accuracy: 0.9186 - top_8_categorical_accuracy: 0.9473 - top_9_categorical_accuracy: 0.9759 - precision_3: 0.5707 - recall_3: 0.0507 - accuracy: 0.0000e+00 - val_loss: 1.8949 - val_top_1_categorical_accuracy: 0.2487 - val_top_2_categorical_accuracy: 0.4587 - val_top_3_categorical_accuracy: 0.5833 - val_top_4_categorical_accuracy: 0.7113 - val_top_5_categorical_accuracy: 0.8067 - val_top_6_categorical_accuracy: 0.8923 - val_top_7_categorical_accuracy: 0.9227 - val_top_8_categorical_accuracy: 0.9553 - val_top_9_categorical_accuracy: 0.9833 - val_precision_3: 0.5101 - val_recall_3: 0.0587 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100\n",
      "140/140 [==============================] - 7s 50ms/step - loss: 1.8471 - top_1_categorical_accuracy: 0.2954 - top_2_categorical_accuracy: 0.5059 - top_3_categorical_accuracy: 0.6376 - top_4_categorical_accuracy: 0.7409 - top_5_categorical_accuracy: 0.8211 - top_6_categorical_accuracy: 0.8941 - top_7_categorical_accuracy: 0.9274 - top_8_categorical_accuracy: 0.9543 - top_9_categorical_accuracy: 0.9813 - precision_3: 0.5980 - recall_3: 0.0684 - accuracy: 0.0000e+00 - val_loss: 1.7829 - val_top_1_categorical_accuracy: 0.2990 - val_top_2_categorical_accuracy: 0.5540 - val_top_3_categorical_accuracy: 0.6990 - val_top_4_categorical_accuracy: 0.7930 - val_top_5_categorical_accuracy: 0.8547 - val_top_6_categorical_accuracy: 0.9247 - val_top_7_categorical_accuracy: 0.9497 - val_top_8_categorical_accuracy: 0.9733 - val_top_9_categorical_accuracy: 0.9873 - val_precision_3: 0.5830 - val_recall_3: 0.0503 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "140/140 [==============================] - 7s 50ms/step - loss: 1.7820 - top_1_categorical_accuracy: 0.3101 - top_2_categorical_accuracy: 0.5477 - top_3_categorical_accuracy: 0.6801 - top_4_categorical_accuracy: 0.7740 - top_5_categorical_accuracy: 0.8393 - top_6_categorical_accuracy: 0.9030 - top_7_categorical_accuracy: 0.9359 - top_8_categorical_accuracy: 0.9617 - top_9_categorical_accuracy: 0.9833 - precision_3: 0.5898 - recall_3: 0.0774 - accuracy: 0.0000e+00 - val_loss: 1.9338 - val_top_1_categorical_accuracy: 0.2843 - val_top_2_categorical_accuracy: 0.4873 - val_top_3_categorical_accuracy: 0.6317 - val_top_4_categorical_accuracy: 0.7307 - val_top_5_categorical_accuracy: 0.7920 - val_top_6_categorical_accuracy: 0.8510 - val_top_7_categorical_accuracy: 0.8980 - val_top_8_categorical_accuracy: 0.9450 - val_top_9_categorical_accuracy: 0.9783 - val_precision_3: 0.5831 - val_recall_3: 0.0713 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "140/140 [==============================] - 7s 50ms/step - loss: 1.7381 - top_1_categorical_accuracy: 0.3300 - top_2_categorical_accuracy: 0.5749 - top_3_categorical_accuracy: 0.7117 - top_4_categorical_accuracy: 0.7976 - top_5_categorical_accuracy: 0.8577 - top_6_categorical_accuracy: 0.9154 - top_7_categorical_accuracy: 0.9404 - top_8_categorical_accuracy: 0.9640 - top_9_categorical_accuracy: 0.9834 - precision_3: 0.6212 - recall_3: 0.1003 - accuracy: 0.0000e+00 - val_loss: 1.7415 - val_top_1_categorical_accuracy: 0.3240 - val_top_2_categorical_accuracy: 0.5477 - val_top_3_categorical_accuracy: 0.6987 - val_top_4_categorical_accuracy: 0.7850 - val_top_5_categorical_accuracy: 0.8527 - val_top_6_categorical_accuracy: 0.9183 - val_top_7_categorical_accuracy: 0.9453 - val_top_8_categorical_accuracy: 0.9650 - val_top_9_categorical_accuracy: 0.9810 - val_precision_3: 0.5377 - val_recall_3: 0.1190 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "140/140 [==============================] - 7s 50ms/step - loss: 1.7042 - top_1_categorical_accuracy: 0.3539 - top_2_categorical_accuracy: 0.5836 - top_3_categorical_accuracy: 0.7169 - top_4_categorical_accuracy: 0.8054 - top_5_categorical_accuracy: 0.8680 - top_6_categorical_accuracy: 0.9206 - top_7_categorical_accuracy: 0.9494 - top_8_categorical_accuracy: 0.9686 - top_9_categorical_accuracy: 0.9860 - precision_3: 0.6155 - recall_3: 0.1191 - accuracy: 0.0000e+00 - val_loss: 1.6461 - val_top_1_categorical_accuracy: 0.3673 - val_top_2_categorical_accuracy: 0.5910 - val_top_3_categorical_accuracy: 0.7130 - val_top_4_categorical_accuracy: 0.8090 - val_top_5_categorical_accuracy: 0.8707 - val_top_6_categorical_accuracy: 0.9360 - val_top_7_categorical_accuracy: 0.9560 - val_top_8_categorical_accuracy: 0.9750 - val_top_9_categorical_accuracy: 0.9877 - val_precision_3: 0.6807 - val_recall_3: 0.1243 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "140/140 [==============================] - 7s 50ms/step - loss: 1.6671 - top_1_categorical_accuracy: 0.3637 - top_2_categorical_accuracy: 0.5956 - top_3_categorical_accuracy: 0.7301 - top_4_categorical_accuracy: 0.8196 - top_5_categorical_accuracy: 0.8749 - top_6_categorical_accuracy: 0.9253 - top_7_categorical_accuracy: 0.9511 - top_8_categorical_accuracy: 0.9714 - top_9_categorical_accuracy: 0.9861 - precision_3: 0.6341 - recall_3: 0.1300 - accuracy: 0.0000e+00 - val_loss: 1.7276 - val_top_1_categorical_accuracy: 0.3643 - val_top_2_categorical_accuracy: 0.5947 - val_top_3_categorical_accuracy: 0.7237 - val_top_4_categorical_accuracy: 0.8020 - val_top_5_categorical_accuracy: 0.8600 - val_top_6_categorical_accuracy: 0.9190 - val_top_7_categorical_accuracy: 0.9490 - val_top_8_categorical_accuracy: 0.9693 - val_top_9_categorical_accuracy: 0.9863 - val_precision_3: 0.5554 - val_recall_3: 0.1670 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "140/140 [==============================] - 8s 55ms/step - loss: 1.6317 - top_1_categorical_accuracy: 0.3787 - top_2_categorical_accuracy: 0.6130 - top_3_categorical_accuracy: 0.7486 - top_4_categorical_accuracy: 0.8276 - top_5_categorical_accuracy: 0.8787 - top_6_categorical_accuracy: 0.9290 - top_7_categorical_accuracy: 0.9513 - top_8_categorical_accuracy: 0.9713 - top_9_categorical_accuracy: 0.9886 - precision_3: 0.6531 - recall_3: 0.1490 - accuracy: 0.0000e+00 - val_loss: 1.6037 - val_top_1_categorical_accuracy: 0.3813 - val_top_2_categorical_accuracy: 0.6273 - val_top_3_categorical_accuracy: 0.7537 - val_top_4_categorical_accuracy: 0.8287 - val_top_5_categorical_accuracy: 0.8763 - val_top_6_categorical_accuracy: 0.9320 - val_top_7_categorical_accuracy: 0.9533 - val_top_8_categorical_accuracy: 0.9723 - val_top_9_categorical_accuracy: 0.9870 - val_precision_3: 0.6486 - val_recall_3: 0.1557 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "140/140 [==============================] - 7s 51ms/step - loss: 1.5999 - top_1_categorical_accuracy: 0.3944 - top_2_categorical_accuracy: 0.6290 - top_3_categorical_accuracy: 0.7556 - top_4_categorical_accuracy: 0.8334 - top_5_categorical_accuracy: 0.8840 - top_6_categorical_accuracy: 0.9333 - top_7_categorical_accuracy: 0.9577 - top_8_categorical_accuracy: 0.9766 - top_9_categorical_accuracy: 0.9891 - precision_3: 0.6453 - recall_3: 0.1666 - accuracy: 0.0000e+00 - val_loss: 1.7537 - val_top_1_categorical_accuracy: 0.3723 - val_top_2_categorical_accuracy: 0.6007 - val_top_3_categorical_accuracy: 0.7193 - val_top_4_categorical_accuracy: 0.7943 - val_top_5_categorical_accuracy: 0.8507 - val_top_6_categorical_accuracy: 0.9107 - val_top_7_categorical_accuracy: 0.9397 - val_top_8_categorical_accuracy: 0.9653 - val_top_9_categorical_accuracy: 0.9797 - val_precision_3: 0.5566 - val_recall_3: 0.1917 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "140/140 [==============================] - 7s 52ms/step - loss: 1.5736 - top_1_categorical_accuracy: 0.4053 - top_2_categorical_accuracy: 0.6399 - top_3_categorical_accuracy: 0.7640 - top_4_categorical_accuracy: 0.8434 - top_5_categorical_accuracy: 0.8947 - top_6_categorical_accuracy: 0.9406 - top_7_categorical_accuracy: 0.9610 - top_8_categorical_accuracy: 0.9776 - top_9_categorical_accuracy: 0.9883 - precision_3: 0.6586 - recall_3: 0.1744 - accuracy: 0.0000e+00 - val_loss: 1.6334 - val_top_1_categorical_accuracy: 0.4203 - val_top_2_categorical_accuracy: 0.6260 - val_top_3_categorical_accuracy: 0.7407 - val_top_4_categorical_accuracy: 0.8180 - val_top_5_categorical_accuracy: 0.8680 - val_top_6_categorical_accuracy: 0.9220 - val_top_7_categorical_accuracy: 0.9500 - val_top_8_categorical_accuracy: 0.9687 - val_top_9_categorical_accuracy: 0.9823 - val_precision_3: 0.6325 - val_recall_3: 0.1973 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "140/140 [==============================] - 7s 52ms/step - loss: 1.5479 - top_1_categorical_accuracy: 0.4209 - top_2_categorical_accuracy: 0.6523 - top_3_categorical_accuracy: 0.7656 - top_4_categorical_accuracy: 0.8434 - top_5_categorical_accuracy: 0.8951 - top_6_categorical_accuracy: 0.9369 - top_7_categorical_accuracy: 0.9596 - top_8_categorical_accuracy: 0.9761 - top_9_categorical_accuracy: 0.9891 - precision_3: 0.6724 - recall_3: 0.1944 - accuracy: 0.0000e+00 - val_loss: 1.5926 - val_top_1_categorical_accuracy: 0.4267 - val_top_2_categorical_accuracy: 0.6430 - val_top_3_categorical_accuracy: 0.7593 - val_top_4_categorical_accuracy: 0.8300 - val_top_5_categorical_accuracy: 0.8880 - val_top_6_categorical_accuracy: 0.9370 - val_top_7_categorical_accuracy: 0.9587 - val_top_8_categorical_accuracy: 0.9760 - val_top_9_categorical_accuracy: 0.9907 - val_precision_3: 0.6183 - val_recall_3: 0.2457 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/100\n",
      "140/140 [==============================] - 7s 51ms/step - loss: 1.5450 - top_1_categorical_accuracy: 0.4394 - top_2_categorical_accuracy: 0.6641 - top_3_categorical_accuracy: 0.7707 - top_4_categorical_accuracy: 0.8514 - top_5_categorical_accuracy: 0.8989 - top_6_categorical_accuracy: 0.9383 - top_7_categorical_accuracy: 0.9581 - top_8_categorical_accuracy: 0.9753 - top_9_categorical_accuracy: 0.9896 - precision_3: 0.6594 - recall_3: 0.2060 - accuracy: 0.0000e+00 - val_loss: 1.5525 - val_top_1_categorical_accuracy: 0.4407 - val_top_2_categorical_accuracy: 0.6520 - val_top_3_categorical_accuracy: 0.7647 - val_top_4_categorical_accuracy: 0.8360 - val_top_5_categorical_accuracy: 0.8917 - val_top_6_categorical_accuracy: 0.9373 - val_top_7_categorical_accuracy: 0.9613 - val_top_8_categorical_accuracy: 0.9807 - val_top_9_categorical_accuracy: 0.9890 - val_precision_3: 0.6488 - val_recall_3: 0.2180 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "140/140 [==============================] - 8s 55ms/step - loss: 1.5207 - top_1_categorical_accuracy: 0.4407 - top_2_categorical_accuracy: 0.6656 - top_3_categorical_accuracy: 0.7763 - top_4_categorical_accuracy: 0.8547 - top_5_categorical_accuracy: 0.8996 - top_6_categorical_accuracy: 0.9383 - top_7_categorical_accuracy: 0.9610 - top_8_categorical_accuracy: 0.9784 - top_9_categorical_accuracy: 0.9896 - precision_3: 0.6785 - recall_3: 0.2129 - accuracy: 0.0000e+00 - val_loss: 1.5612 - val_top_1_categorical_accuracy: 0.4303 - val_top_2_categorical_accuracy: 0.6267 - val_top_3_categorical_accuracy: 0.7323 - val_top_4_categorical_accuracy: 0.8183 - val_top_5_categorical_accuracy: 0.8867 - val_top_6_categorical_accuracy: 0.9373 - val_top_7_categorical_accuracy: 0.9613 - val_top_8_categorical_accuracy: 0.9790 - val_top_9_categorical_accuracy: 0.9893 - val_precision_3: 0.6531 - val_recall_3: 0.2197 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "140/140 [==============================] - 7s 51ms/step - loss: 1.4878 - top_1_categorical_accuracy: 0.4596 - top_2_categorical_accuracy: 0.6773 - top_3_categorical_accuracy: 0.7820 - top_4_categorical_accuracy: 0.8597 - top_5_categorical_accuracy: 0.9066 - top_6_categorical_accuracy: 0.9456 - top_7_categorical_accuracy: 0.9646 - top_8_categorical_accuracy: 0.9791 - top_9_categorical_accuracy: 0.9910 - precision_3: 0.6864 - recall_3: 0.2273 - accuracy: 0.0000e+00 - val_loss: 1.5487 - val_top_1_categorical_accuracy: 0.4607 - val_top_2_categorical_accuracy: 0.6773 - val_top_3_categorical_accuracy: 0.7717 - val_top_4_categorical_accuracy: 0.8463 - val_top_5_categorical_accuracy: 0.8913 - val_top_6_categorical_accuracy: 0.9347 - val_top_7_categorical_accuracy: 0.9613 - val_top_8_categorical_accuracy: 0.9753 - val_top_9_categorical_accuracy: 0.9890 - val_precision_3: 0.6272 - val_recall_3: 0.2597 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "140/140 [==============================] - 7s 50ms/step - loss: 1.4782 - top_1_categorical_accuracy: 0.4560 - top_2_categorical_accuracy: 0.6830 - top_3_categorical_accuracy: 0.7851 - top_4_categorical_accuracy: 0.8601 - top_5_categorical_accuracy: 0.9053 - top_6_categorical_accuracy: 0.9434 - top_7_categorical_accuracy: 0.9631 - top_8_categorical_accuracy: 0.9794 - top_9_categorical_accuracy: 0.9920 - precision_3: 0.6804 - recall_3: 0.2306 - accuracy: 0.0000e+00 - val_loss: 1.5239 - val_top_1_categorical_accuracy: 0.4630 - val_top_2_categorical_accuracy: 0.6743 - val_top_3_categorical_accuracy: 0.7777 - val_top_4_categorical_accuracy: 0.8433 - val_top_5_categorical_accuracy: 0.8933 - val_top_6_categorical_accuracy: 0.9360 - val_top_7_categorical_accuracy: 0.9603 - val_top_8_categorical_accuracy: 0.9770 - val_top_9_categorical_accuracy: 0.9873 - val_precision_3: 0.6647 - val_recall_3: 0.2300 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "140/140 [==============================] - 7s 52ms/step - loss: 1.4489 - top_1_categorical_accuracy: 0.4841 - top_2_categorical_accuracy: 0.6941 - top_3_categorical_accuracy: 0.7913 - top_4_categorical_accuracy: 0.8587 - top_5_categorical_accuracy: 0.9077 - top_6_categorical_accuracy: 0.9417 - top_7_categorical_accuracy: 0.9616 - top_8_categorical_accuracy: 0.9784 - top_9_categorical_accuracy: 0.9899 - precision_3: 0.7037 - recall_3: 0.2381 - accuracy: 0.0000e+00 - val_loss: 1.5405 - val_top_1_categorical_accuracy: 0.4760 - val_top_2_categorical_accuracy: 0.6873 - val_top_3_categorical_accuracy: 0.7800 - val_top_4_categorical_accuracy: 0.8430 - val_top_5_categorical_accuracy: 0.8837 - val_top_6_categorical_accuracy: 0.9267 - val_top_7_categorical_accuracy: 0.9547 - val_top_8_categorical_accuracy: 0.9743 - val_top_9_categorical_accuracy: 0.9913 - val_precision_3: 0.6445 - val_recall_3: 0.2490 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "140/140 [==============================] - 7s 52ms/step - loss: 1.4567 - top_1_categorical_accuracy: 0.4760 - top_2_categorical_accuracy: 0.6967 - top_3_categorical_accuracy: 0.7917 - top_4_categorical_accuracy: 0.8649 - top_5_categorical_accuracy: 0.9081 - top_6_categorical_accuracy: 0.9421 - top_7_categorical_accuracy: 0.9606 - top_8_categorical_accuracy: 0.9774 - top_9_categorical_accuracy: 0.9893 - precision_3: 0.7037 - recall_3: 0.2497 - accuracy: 0.0000e+00 - val_loss: 1.5232 - val_top_1_categorical_accuracy: 0.4743 - val_top_2_categorical_accuracy: 0.6630 - val_top_3_categorical_accuracy: 0.7727 - val_top_4_categorical_accuracy: 0.8407 - val_top_5_categorical_accuracy: 0.8887 - val_top_6_categorical_accuracy: 0.9370 - val_top_7_categorical_accuracy: 0.9590 - val_top_8_categorical_accuracy: 0.9797 - val_top_9_categorical_accuracy: 0.9913 - val_precision_3: 0.6496 - val_recall_3: 0.2670 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "140/140 [==============================] - 7s 51ms/step - loss: 1.4256 - top_1_categorical_accuracy: 0.4924 - top_2_categorical_accuracy: 0.7080 - top_3_categorical_accuracy: 0.8001 - top_4_categorical_accuracy: 0.8669 - top_5_categorical_accuracy: 0.9110 - top_6_categorical_accuracy: 0.9449 - top_7_categorical_accuracy: 0.9651 - top_8_categorical_accuracy: 0.9799 - top_9_categorical_accuracy: 0.9913 - precision_3: 0.7067 - recall_3: 0.2691 - accuracy: 0.0000e+00 - val_loss: 1.4945 - val_top_1_categorical_accuracy: 0.4860 - val_top_2_categorical_accuracy: 0.6990 - val_top_3_categorical_accuracy: 0.7893 - val_top_4_categorical_accuracy: 0.8523 - val_top_5_categorical_accuracy: 0.9013 - val_top_6_categorical_accuracy: 0.9440 - val_top_7_categorical_accuracy: 0.9643 - val_top_8_categorical_accuracy: 0.9780 - val_top_9_categorical_accuracy: 0.9903 - val_precision_3: 0.6300 - val_recall_3: 0.3247 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "140/140 [==============================] - 7s 50ms/step - loss: 1.3971 - top_1_categorical_accuracy: 0.5036 - top_2_categorical_accuracy: 0.7126 - top_3_categorical_accuracy: 0.8054 - top_4_categorical_accuracy: 0.8719 - top_5_categorical_accuracy: 0.9171 - top_6_categorical_accuracy: 0.9519 - top_7_categorical_accuracy: 0.9697 - top_8_categorical_accuracy: 0.9819 - top_9_categorical_accuracy: 0.9919 - precision_3: 0.7034 - recall_3: 0.2900 - accuracy: 0.0000e+00 - val_loss: 1.4970 - val_top_1_categorical_accuracy: 0.4887 - val_top_2_categorical_accuracy: 0.6960 - val_top_3_categorical_accuracy: 0.7823 - val_top_4_categorical_accuracy: 0.8453 - val_top_5_categorical_accuracy: 0.8950 - val_top_6_categorical_accuracy: 0.9417 - val_top_7_categorical_accuracy: 0.9657 - val_top_8_categorical_accuracy: 0.9793 - val_top_9_categorical_accuracy: 0.9893 - val_precision_3: 0.6223 - val_recall_3: 0.3383 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "140/140 [==============================] - 7s 52ms/step - loss: 1.4089 - top_1_categorical_accuracy: 0.4953 - top_2_categorical_accuracy: 0.7083 - top_3_categorical_accuracy: 0.8047 - top_4_categorical_accuracy: 0.8703 - top_5_categorical_accuracy: 0.9144 - top_6_categorical_accuracy: 0.9470 - top_7_categorical_accuracy: 0.9669 - top_8_categorical_accuracy: 0.9824 - top_9_categorical_accuracy: 0.9919 - precision_3: 0.7003 - recall_3: 0.2891 - accuracy: 0.0000e+00 - val_loss: 1.4542 - val_top_1_categorical_accuracy: 0.4940 - val_top_2_categorical_accuracy: 0.6973 - val_top_3_categorical_accuracy: 0.7860 - val_top_4_categorical_accuracy: 0.8520 - val_top_5_categorical_accuracy: 0.8987 - val_top_6_categorical_accuracy: 0.9387 - val_top_7_categorical_accuracy: 0.9620 - val_top_8_categorical_accuracy: 0.9790 - val_top_9_categorical_accuracy: 0.9933 - val_precision_3: 0.6824 - val_recall_3: 0.3093 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/100\n",
      "140/140 [==============================] - 7s 51ms/step - loss: 1.3841 - top_1_categorical_accuracy: 0.5030 - top_2_categorical_accuracy: 0.7134 - top_3_categorical_accuracy: 0.8031 - top_4_categorical_accuracy: 0.8694 - top_5_categorical_accuracy: 0.9143 - top_6_categorical_accuracy: 0.9471 - top_7_categorical_accuracy: 0.9667 - top_8_categorical_accuracy: 0.9786 - top_9_categorical_accuracy: 0.9906 - precision_3: 0.7109 - recall_3: 0.2997 - accuracy: 0.0000e+00 - val_loss: 1.9156 - val_top_1_categorical_accuracy: 0.3873 - val_top_2_categorical_accuracy: 0.5537 - val_top_3_categorical_accuracy: 0.6333 - val_top_4_categorical_accuracy: 0.7323 - val_top_5_categorical_accuracy: 0.8040 - val_top_6_categorical_accuracy: 0.8763 - val_top_7_categorical_accuracy: 0.9180 - val_top_8_categorical_accuracy: 0.9547 - val_top_9_categorical_accuracy: 0.9827 - val_precision_3: 0.5462 - val_recall_3: 0.2520 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "140/140 [==============================] - 7s 50ms/step - loss: 1.3738 - top_1_categorical_accuracy: 0.5123 - top_2_categorical_accuracy: 0.7207 - top_3_categorical_accuracy: 0.8016 - top_4_categorical_accuracy: 0.8701 - top_5_categorical_accuracy: 0.9129 - top_6_categorical_accuracy: 0.9434 - top_7_categorical_accuracy: 0.9647 - top_8_categorical_accuracy: 0.9803 - top_9_categorical_accuracy: 0.9906 - precision_3: 0.7123 - recall_3: 0.3094 - accuracy: 0.0000e+00 - val_loss: 1.4589 - val_top_1_categorical_accuracy: 0.5013 - val_top_2_categorical_accuracy: 0.7007 - val_top_3_categorical_accuracy: 0.7870 - val_top_4_categorical_accuracy: 0.8637 - val_top_5_categorical_accuracy: 0.9150 - val_top_6_categorical_accuracy: 0.9513 - val_top_7_categorical_accuracy: 0.9677 - val_top_8_categorical_accuracy: 0.9793 - val_top_9_categorical_accuracy: 0.9917 - val_precision_3: 0.6506 - val_recall_3: 0.3700 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "140/140 [==============================] - 7s 53ms/step - loss: 1.3697 - top_1_categorical_accuracy: 0.5124 - top_2_categorical_accuracy: 0.7287 - top_3_categorical_accuracy: 0.8149 - top_4_categorical_accuracy: 0.8719 - top_5_categorical_accuracy: 0.9157 - top_6_categorical_accuracy: 0.9469 - top_7_categorical_accuracy: 0.9669 - top_8_categorical_accuracy: 0.9816 - top_9_categorical_accuracy: 0.9923 - precision_3: 0.7106 - recall_3: 0.3059 - accuracy: 0.0000e+00 - val_loss: 1.5412 - val_top_1_categorical_accuracy: 0.4660 - val_top_2_categorical_accuracy: 0.6810 - val_top_3_categorical_accuracy: 0.7613 - val_top_4_categorical_accuracy: 0.8307 - val_top_5_categorical_accuracy: 0.8790 - val_top_6_categorical_accuracy: 0.9310 - val_top_7_categorical_accuracy: 0.9553 - val_top_8_categorical_accuracy: 0.9717 - val_top_9_categorical_accuracy: 0.9893 - val_precision_3: 0.6156 - val_recall_3: 0.3133 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "140/140 [==============================] - 7s 53ms/step - loss: 1.3503 - top_1_categorical_accuracy: 0.5223 - top_2_categorical_accuracy: 0.7290 - top_3_categorical_accuracy: 0.8159 - top_4_categorical_accuracy: 0.8777 - top_5_categorical_accuracy: 0.9184 - top_6_categorical_accuracy: 0.9506 - top_7_categorical_accuracy: 0.9694 - top_8_categorical_accuracy: 0.9826 - top_9_categorical_accuracy: 0.9929 - precision_3: 0.7232 - recall_3: 0.3173 - accuracy: 0.0000e+00 - val_loss: 1.4961 - val_top_1_categorical_accuracy: 0.4877 - val_top_2_categorical_accuracy: 0.6897 - val_top_3_categorical_accuracy: 0.7787 - val_top_4_categorical_accuracy: 0.8507 - val_top_5_categorical_accuracy: 0.8953 - val_top_6_categorical_accuracy: 0.9343 - val_top_7_categorical_accuracy: 0.9553 - val_top_8_categorical_accuracy: 0.9723 - val_top_9_categorical_accuracy: 0.9893 - val_precision_3: 0.6596 - val_recall_3: 0.3320 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "140/140 [==============================] - 7s 51ms/step - loss: 1.3380 - top_1_categorical_accuracy: 0.5220 - top_2_categorical_accuracy: 0.7291 - top_3_categorical_accuracy: 0.8206 - top_4_categorical_accuracy: 0.8846 - top_5_categorical_accuracy: 0.9251 - top_6_categorical_accuracy: 0.9571 - top_7_categorical_accuracy: 0.9716 - top_8_categorical_accuracy: 0.9841 - top_9_categorical_accuracy: 0.9916 - precision_3: 0.7291 - recall_3: 0.3191 - accuracy: 0.0000e+00 - val_loss: 1.4160 - val_top_1_categorical_accuracy: 0.5100 - val_top_2_categorical_accuracy: 0.7087 - val_top_3_categorical_accuracy: 0.7967 - val_top_4_categorical_accuracy: 0.8607 - val_top_5_categorical_accuracy: 0.9050 - val_top_6_categorical_accuracy: 0.9407 - val_top_7_categorical_accuracy: 0.9620 - val_top_8_categorical_accuracy: 0.9797 - val_top_9_categorical_accuracy: 0.9920 - val_precision_3: 0.6839 - val_recall_3: 0.3613 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "140/140 [==============================] - 7s 51ms/step - loss: 1.3307 - top_1_categorical_accuracy: 0.5244 - top_2_categorical_accuracy: 0.7376 - top_3_categorical_accuracy: 0.8259 - top_4_categorical_accuracy: 0.8850 - top_5_categorical_accuracy: 0.9230 - top_6_categorical_accuracy: 0.9511 - top_7_categorical_accuracy: 0.9674 - top_8_categorical_accuracy: 0.9810 - top_9_categorical_accuracy: 0.9903 - precision_3: 0.7230 - recall_3: 0.3259 - accuracy: 0.0000e+00 - val_loss: 1.5030 - val_top_1_categorical_accuracy: 0.4977 - val_top_2_categorical_accuracy: 0.6907 - val_top_3_categorical_accuracy: 0.7927 - val_top_4_categorical_accuracy: 0.8547 - val_top_5_categorical_accuracy: 0.8973 - val_top_6_categorical_accuracy: 0.9423 - val_top_7_categorical_accuracy: 0.9587 - val_top_8_categorical_accuracy: 0.9750 - val_top_9_categorical_accuracy: 0.9893 - val_precision_3: 0.6333 - val_recall_3: 0.3730 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "140/140 [==============================] - 7s 51ms/step - loss: 1.3094 - top_1_categorical_accuracy: 0.5393 - top_2_categorical_accuracy: 0.7470 - top_3_categorical_accuracy: 0.8270 - top_4_categorical_accuracy: 0.8850 - top_5_categorical_accuracy: 0.9231 - top_6_categorical_accuracy: 0.9563 - top_7_categorical_accuracy: 0.9717 - top_8_categorical_accuracy: 0.9834 - top_9_categorical_accuracy: 0.9927 - precision_3: 0.7195 - recall_3: 0.3390 - accuracy: 0.0000e+00 - val_loss: 1.4132 - val_top_1_categorical_accuracy: 0.5157 - val_top_2_categorical_accuracy: 0.7113 - val_top_3_categorical_accuracy: 0.8007 - val_top_4_categorical_accuracy: 0.8593 - val_top_5_categorical_accuracy: 0.9067 - val_top_6_categorical_accuracy: 0.9400 - val_top_7_categorical_accuracy: 0.9573 - val_top_8_categorical_accuracy: 0.9773 - val_top_9_categorical_accuracy: 0.9893 - val_precision_3: 0.6696 - val_recall_3: 0.3843 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "140/140 [==============================] - 7s 52ms/step - loss: 1.2920 - top_1_categorical_accuracy: 0.5410 - top_2_categorical_accuracy: 0.7500 - top_3_categorical_accuracy: 0.8330 - top_4_categorical_accuracy: 0.8880 - top_5_categorical_accuracy: 0.9257 - top_6_categorical_accuracy: 0.9546 - top_7_categorical_accuracy: 0.9709 - top_8_categorical_accuracy: 0.9833 - top_9_categorical_accuracy: 0.9931 - precision_3: 0.7392 - recall_3: 0.3503 - accuracy: 0.0000e+00 - val_loss: 1.4205 - val_top_1_categorical_accuracy: 0.5203 - val_top_2_categorical_accuracy: 0.7190 - val_top_3_categorical_accuracy: 0.8070 - val_top_4_categorical_accuracy: 0.8693 - val_top_5_categorical_accuracy: 0.9090 - val_top_6_categorical_accuracy: 0.9413 - val_top_7_categorical_accuracy: 0.9593 - val_top_8_categorical_accuracy: 0.9787 - val_top_9_categorical_accuracy: 0.9920 - val_precision_3: 0.6624 - val_recall_3: 0.3990 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "140/140 [==============================] - 7s 54ms/step - loss: 1.3099 - top_1_categorical_accuracy: 0.5410 - top_2_categorical_accuracy: 0.7471 - top_3_categorical_accuracy: 0.8324 - top_4_categorical_accuracy: 0.8837 - top_5_categorical_accuracy: 0.9221 - top_6_categorical_accuracy: 0.9543 - top_7_categorical_accuracy: 0.9693 - top_8_categorical_accuracy: 0.9831 - top_9_categorical_accuracy: 0.9924 - precision_3: 0.7232 - recall_3: 0.3476 - accuracy: 0.0000e+00 - val_loss: 1.3980 - val_top_1_categorical_accuracy: 0.5163 - val_top_2_categorical_accuracy: 0.7087 - val_top_3_categorical_accuracy: 0.8017 - val_top_4_categorical_accuracy: 0.8630 - val_top_5_categorical_accuracy: 0.9093 - val_top_6_categorical_accuracy: 0.9417 - val_top_7_categorical_accuracy: 0.9603 - val_top_8_categorical_accuracy: 0.9747 - val_top_9_categorical_accuracy: 0.9903 - val_precision_3: 0.6863 - val_recall_3: 0.3733 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/100\n",
      "140/140 [==============================] - 7s 52ms/step - loss: 1.2880 - top_1_categorical_accuracy: 0.5386 - top_2_categorical_accuracy: 0.7526 - top_3_categorical_accuracy: 0.8383 - top_4_categorical_accuracy: 0.8930 - top_5_categorical_accuracy: 0.9316 - top_6_categorical_accuracy: 0.9596 - top_7_categorical_accuracy: 0.9747 - top_8_categorical_accuracy: 0.9851 - top_9_categorical_accuracy: 0.9939 - precision_3: 0.7288 - recall_3: 0.3513 - accuracy: 0.0000e+00 - val_loss: 1.4281 - val_top_1_categorical_accuracy: 0.5140 - val_top_2_categorical_accuracy: 0.7183 - val_top_3_categorical_accuracy: 0.8033 - val_top_4_categorical_accuracy: 0.8637 - val_top_5_categorical_accuracy: 0.9047 - val_top_6_categorical_accuracy: 0.9437 - val_top_7_categorical_accuracy: 0.9603 - val_top_8_categorical_accuracy: 0.9763 - val_top_9_categorical_accuracy: 0.9900 - val_precision_3: 0.6571 - val_recall_3: 0.3890 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "140/140 [==============================] - 7s 51ms/step - loss: 1.2863 - top_1_categorical_accuracy: 0.5496 - top_2_categorical_accuracy: 0.7534 - top_3_categorical_accuracy: 0.8356 - top_4_categorical_accuracy: 0.8909 - top_5_categorical_accuracy: 0.9276 - top_6_categorical_accuracy: 0.9567 - top_7_categorical_accuracy: 0.9721 - top_8_categorical_accuracy: 0.9836 - top_9_categorical_accuracy: 0.9939 - precision_3: 0.7232 - recall_3: 0.3560 - accuracy: 0.0000e+00 - val_loss: 1.4317 - val_top_1_categorical_accuracy: 0.5097 - val_top_2_categorical_accuracy: 0.7123 - val_top_3_categorical_accuracy: 0.8063 - val_top_4_categorical_accuracy: 0.8673 - val_top_5_categorical_accuracy: 0.9160 - val_top_6_categorical_accuracy: 0.9433 - val_top_7_categorical_accuracy: 0.9637 - val_top_8_categorical_accuracy: 0.9797 - val_top_9_categorical_accuracy: 0.9913 - val_precision_3: 0.6473 - val_recall_3: 0.3890 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "140/140 [==============================] - 7s 51ms/step - loss: 1.2621 - top_1_categorical_accuracy: 0.5509 - top_2_categorical_accuracy: 0.7646 - top_3_categorical_accuracy: 0.8421 - top_4_categorical_accuracy: 0.8916 - top_5_categorical_accuracy: 0.9277 - top_6_categorical_accuracy: 0.9537 - top_7_categorical_accuracy: 0.9713 - top_8_categorical_accuracy: 0.9816 - top_9_categorical_accuracy: 0.9926 - precision_3: 0.7430 - recall_3: 0.3664 - accuracy: 0.0000e+00 - val_loss: 1.4282 - val_top_1_categorical_accuracy: 0.5333 - val_top_2_categorical_accuracy: 0.7170 - val_top_3_categorical_accuracy: 0.8017 - val_top_4_categorical_accuracy: 0.8640 - val_top_5_categorical_accuracy: 0.9043 - val_top_6_categorical_accuracy: 0.9410 - val_top_7_categorical_accuracy: 0.9620 - val_top_8_categorical_accuracy: 0.9797 - val_top_9_categorical_accuracy: 0.9927 - val_precision_3: 0.6645 - val_recall_3: 0.4087 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "140/140 [==============================] - 7s 52ms/step - loss: 1.2687 - top_1_categorical_accuracy: 0.5546 - top_2_categorical_accuracy: 0.7689 - top_3_categorical_accuracy: 0.8473 - top_4_categorical_accuracy: 0.8943 - top_5_categorical_accuracy: 0.9311 - top_6_categorical_accuracy: 0.9594 - top_7_categorical_accuracy: 0.9744 - top_8_categorical_accuracy: 0.9833 - top_9_categorical_accuracy: 0.9917 - precision_3: 0.7258 - recall_3: 0.3639 - accuracy: 0.0000e+00 - val_loss: 1.3918 - val_top_1_categorical_accuracy: 0.5267 - val_top_2_categorical_accuracy: 0.7293 - val_top_3_categorical_accuracy: 0.8133 - val_top_4_categorical_accuracy: 0.8670 - val_top_5_categorical_accuracy: 0.9060 - val_top_6_categorical_accuracy: 0.9430 - val_top_7_categorical_accuracy: 0.9620 - val_top_8_categorical_accuracy: 0.9770 - val_top_9_categorical_accuracy: 0.9907 - val_precision_3: 0.6994 - val_recall_3: 0.3770 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "140/140 [==============================] - 7s 53ms/step - loss: 1.2588 - top_1_categorical_accuracy: 0.5547 - top_2_categorical_accuracy: 0.7613 - top_3_categorical_accuracy: 0.8477 - top_4_categorical_accuracy: 0.8974 - top_5_categorical_accuracy: 0.9316 - top_6_categorical_accuracy: 0.9597 - top_7_categorical_accuracy: 0.9730 - top_8_categorical_accuracy: 0.9834 - top_9_categorical_accuracy: 0.9936 - precision_3: 0.7397 - recall_3: 0.3637 - accuracy: 0.0000e+00 - val_loss: 1.4767 - val_top_1_categorical_accuracy: 0.5150 - val_top_2_categorical_accuracy: 0.7057 - val_top_3_categorical_accuracy: 0.7990 - val_top_4_categorical_accuracy: 0.8620 - val_top_5_categorical_accuracy: 0.9073 - val_top_6_categorical_accuracy: 0.9433 - val_top_7_categorical_accuracy: 0.9610 - val_top_8_categorical_accuracy: 0.9757 - val_top_9_categorical_accuracy: 0.9887 - val_precision_3: 0.6446 - val_recall_3: 0.3953 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "140/140 [==============================] - 7s 52ms/step - loss: 1.2628 - top_1_categorical_accuracy: 0.5510 - top_2_categorical_accuracy: 0.7587 - top_3_categorical_accuracy: 0.8429 - top_4_categorical_accuracy: 0.8957 - top_5_categorical_accuracy: 0.9343 - top_6_categorical_accuracy: 0.9606 - top_7_categorical_accuracy: 0.9740 - top_8_categorical_accuracy: 0.9850 - top_9_categorical_accuracy: 0.9916 - precision_3: 0.7457 - recall_3: 0.3619 - accuracy: 0.0000e+00 - val_loss: 1.4213 - val_top_1_categorical_accuracy: 0.5253 - val_top_2_categorical_accuracy: 0.7320 - val_top_3_categorical_accuracy: 0.8170 - val_top_4_categorical_accuracy: 0.8710 - val_top_5_categorical_accuracy: 0.9140 - val_top_6_categorical_accuracy: 0.9467 - val_top_7_categorical_accuracy: 0.9660 - val_top_8_categorical_accuracy: 0.9790 - val_top_9_categorical_accuracy: 0.9897 - val_precision_3: 0.6511 - val_recall_3: 0.3943 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "140/140 [==============================] - 7s 50ms/step - loss: 1.2531 - top_1_categorical_accuracy: 0.5663 - top_2_categorical_accuracy: 0.7670 - top_3_categorical_accuracy: 0.8441 - top_4_categorical_accuracy: 0.8926 - top_5_categorical_accuracy: 0.9274 - top_6_categorical_accuracy: 0.9554 - top_7_categorical_accuracy: 0.9689 - top_8_categorical_accuracy: 0.9839 - top_9_categorical_accuracy: 0.9930 - precision_3: 0.7487 - recall_3: 0.3831 - accuracy: 0.0000e+00 - val_loss: 1.3838 - val_top_1_categorical_accuracy: 0.5307 - val_top_2_categorical_accuracy: 0.7257 - val_top_3_categorical_accuracy: 0.8133 - val_top_4_categorical_accuracy: 0.8753 - val_top_5_categorical_accuracy: 0.9137 - val_top_6_categorical_accuracy: 0.9417 - val_top_7_categorical_accuracy: 0.9623 - val_top_8_categorical_accuracy: 0.9810 - val_top_9_categorical_accuracy: 0.9930 - val_precision_3: 0.6939 - val_recall_3: 0.3913 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "140/140 [==============================] - 7s 51ms/step - loss: 1.2441 - top_1_categorical_accuracy: 0.5666 - top_2_categorical_accuracy: 0.7656 - top_3_categorical_accuracy: 0.8527 - top_4_categorical_accuracy: 0.9006 - top_5_categorical_accuracy: 0.9311 - top_6_categorical_accuracy: 0.9573 - top_7_categorical_accuracy: 0.9726 - top_8_categorical_accuracy: 0.9837 - top_9_categorical_accuracy: 0.9924 - precision_3: 0.7511 - recall_3: 0.3814 - accuracy: 0.0000e+00 - val_loss: 1.3827 - val_top_1_categorical_accuracy: 0.5270 - val_top_2_categorical_accuracy: 0.7353 - val_top_3_categorical_accuracy: 0.8120 - val_top_4_categorical_accuracy: 0.8743 - val_top_5_categorical_accuracy: 0.9187 - val_top_6_categorical_accuracy: 0.9440 - val_top_7_categorical_accuracy: 0.9623 - val_top_8_categorical_accuracy: 0.9793 - val_top_9_categorical_accuracy: 0.9887 - val_precision_3: 0.6822 - val_recall_3: 0.3893 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "140/140 [==============================] - 7s 50ms/step - loss: 1.2490 - top_1_categorical_accuracy: 0.5649 - top_2_categorical_accuracy: 0.7649 - top_3_categorical_accuracy: 0.8474 - top_4_categorical_accuracy: 0.9003 - top_5_categorical_accuracy: 0.9340 - top_6_categorical_accuracy: 0.9603 - top_7_categorical_accuracy: 0.9747 - top_8_categorical_accuracy: 0.9856 - top_9_categorical_accuracy: 0.9919 - precision_3: 0.7397 - recall_3: 0.3807 - accuracy: 0.0000e+00 - val_loss: 1.4218 - val_top_1_categorical_accuracy: 0.5270 - val_top_2_categorical_accuracy: 0.7220 - val_top_3_categorical_accuracy: 0.8020 - val_top_4_categorical_accuracy: 0.8657 - val_top_5_categorical_accuracy: 0.9067 - val_top_6_categorical_accuracy: 0.9367 - val_top_7_categorical_accuracy: 0.9547 - val_top_8_categorical_accuracy: 0.9723 - val_top_9_categorical_accuracy: 0.9857 - val_precision_3: 0.6681 - val_recall_3: 0.4013 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/100\n",
      "140/140 [==============================] - 7s 52ms/step - loss: 1.2371 - top_1_categorical_accuracy: 0.5663 - top_2_categorical_accuracy: 0.7740 - top_3_categorical_accuracy: 0.8497 - top_4_categorical_accuracy: 0.8984 - top_5_categorical_accuracy: 0.9317 - top_6_categorical_accuracy: 0.9576 - top_7_categorical_accuracy: 0.9740 - top_8_categorical_accuracy: 0.9854 - top_9_categorical_accuracy: 0.9924 - precision_3: 0.7407 - recall_3: 0.3743 - accuracy: 0.0000e+00 - val_loss: 1.4925 - val_top_1_categorical_accuracy: 0.4920 - val_top_2_categorical_accuracy: 0.7093 - val_top_3_categorical_accuracy: 0.7970 - val_top_4_categorical_accuracy: 0.8683 - val_top_5_categorical_accuracy: 0.9113 - val_top_6_categorical_accuracy: 0.9437 - val_top_7_categorical_accuracy: 0.9640 - val_top_8_categorical_accuracy: 0.9797 - val_top_9_categorical_accuracy: 0.9893 - val_precision_3: 0.6280 - val_recall_3: 0.3827 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "140/140 [==============================] - 7s 53ms/step - loss: 1.2086 - top_1_categorical_accuracy: 0.5719 - top_2_categorical_accuracy: 0.7794 - top_3_categorical_accuracy: 0.8590 - top_4_categorical_accuracy: 0.9066 - top_5_categorical_accuracy: 0.9346 - top_6_categorical_accuracy: 0.9611 - top_7_categorical_accuracy: 0.9750 - top_8_categorical_accuracy: 0.9846 - top_9_categorical_accuracy: 0.9933 - precision_3: 0.7451 - recall_3: 0.3880 - accuracy: 0.0000e+00 - val_loss: 1.3505 - val_top_1_categorical_accuracy: 0.5457 - val_top_2_categorical_accuracy: 0.7330 - val_top_3_categorical_accuracy: 0.8123 - val_top_4_categorical_accuracy: 0.8733 - val_top_5_categorical_accuracy: 0.9160 - val_top_6_categorical_accuracy: 0.9467 - val_top_7_categorical_accuracy: 0.9677 - val_top_8_categorical_accuracy: 0.9833 - val_top_9_categorical_accuracy: 0.9917 - val_precision_3: 0.7051 - val_recall_3: 0.3977 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "140/140 [==============================] - 7s 51ms/step - loss: 1.1931 - top_1_categorical_accuracy: 0.5813 - top_2_categorical_accuracy: 0.7813 - top_3_categorical_accuracy: 0.8604 - top_4_categorical_accuracy: 0.9127 - top_5_categorical_accuracy: 0.9419 - top_6_categorical_accuracy: 0.9629 - top_7_categorical_accuracy: 0.9753 - top_8_categorical_accuracy: 0.9856 - top_9_categorical_accuracy: 0.9933 - precision_3: 0.7552 - recall_3: 0.4020 - accuracy: 0.0000e+00 - val_loss: 1.3801 - val_top_1_categorical_accuracy: 0.5420 - val_top_2_categorical_accuracy: 0.7300 - val_top_3_categorical_accuracy: 0.8203 - val_top_4_categorical_accuracy: 0.8757 - val_top_5_categorical_accuracy: 0.9170 - val_top_6_categorical_accuracy: 0.9503 - val_top_7_categorical_accuracy: 0.9667 - val_top_8_categorical_accuracy: 0.9830 - val_top_9_categorical_accuracy: 0.9930 - val_precision_3: 0.6667 - val_recall_3: 0.4180 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "140/140 [==============================] - 7s 51ms/step - loss: 1.1832 - top_1_categorical_accuracy: 0.5933 - top_2_categorical_accuracy: 0.7899 - top_3_categorical_accuracy: 0.8623 - top_4_categorical_accuracy: 0.9090 - top_5_categorical_accuracy: 0.9396 - top_6_categorical_accuracy: 0.9609 - top_7_categorical_accuracy: 0.9743 - top_8_categorical_accuracy: 0.9856 - top_9_categorical_accuracy: 0.9944 - precision_3: 0.7567 - recall_3: 0.4137 - accuracy: 0.0000e+00 - val_loss: 1.5042 - val_top_1_categorical_accuracy: 0.5200 - val_top_2_categorical_accuracy: 0.7037 - val_top_3_categorical_accuracy: 0.7790 - val_top_4_categorical_accuracy: 0.8437 - val_top_5_categorical_accuracy: 0.8867 - val_top_6_categorical_accuracy: 0.9257 - val_top_7_categorical_accuracy: 0.9503 - val_top_8_categorical_accuracy: 0.9727 - val_top_9_categorical_accuracy: 0.9890 - val_precision_3: 0.6490 - val_recall_3: 0.4037 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "140/140 [==============================] - 7s 50ms/step - loss: 1.1845 - top_1_categorical_accuracy: 0.5877 - top_2_categorical_accuracy: 0.7824 - top_3_categorical_accuracy: 0.8553 - top_4_categorical_accuracy: 0.9076 - top_5_categorical_accuracy: 0.9394 - top_6_categorical_accuracy: 0.9627 - top_7_categorical_accuracy: 0.9756 - top_8_categorical_accuracy: 0.9863 - top_9_categorical_accuracy: 0.9940 - precision_3: 0.7541 - recall_3: 0.4131 - accuracy: 0.0000e+00 - val_loss: 1.3494 - val_top_1_categorical_accuracy: 0.5353 - val_top_2_categorical_accuracy: 0.7273 - val_top_3_categorical_accuracy: 0.8130 - val_top_4_categorical_accuracy: 0.8710 - val_top_5_categorical_accuracy: 0.9123 - val_top_6_categorical_accuracy: 0.9410 - val_top_7_categorical_accuracy: 0.9607 - val_top_8_categorical_accuracy: 0.9800 - val_top_9_categorical_accuracy: 0.9917 - val_precision_3: 0.6984 - val_recall_3: 0.3960 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "140/140 [==============================] - 7s 51ms/step - loss: 1.1852 - top_1_categorical_accuracy: 0.5943 - top_2_categorical_accuracy: 0.7913 - top_3_categorical_accuracy: 0.8597 - top_4_categorical_accuracy: 0.9024 - top_5_categorical_accuracy: 0.9377 - top_6_categorical_accuracy: 0.9629 - top_7_categorical_accuracy: 0.9783 - top_8_categorical_accuracy: 0.9886 - top_9_categorical_accuracy: 0.9951 - precision_3: 0.7540 - recall_3: 0.4200 - accuracy: 0.0000e+00 - val_loss: 1.4745 - val_top_1_categorical_accuracy: 0.5367 - val_top_2_categorical_accuracy: 0.7163 - val_top_3_categorical_accuracy: 0.7913 - val_top_4_categorical_accuracy: 0.8467 - val_top_5_categorical_accuracy: 0.8963 - val_top_6_categorical_accuracy: 0.9313 - val_top_7_categorical_accuracy: 0.9573 - val_top_8_categorical_accuracy: 0.9747 - val_top_9_categorical_accuracy: 0.9883 - val_precision_3: 0.6533 - val_recall_3: 0.4347 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "140/140 [==============================] - 7s 51ms/step - loss: 1.1816 - top_1_categorical_accuracy: 0.5921 - top_2_categorical_accuracy: 0.7874 - top_3_categorical_accuracy: 0.8613 - top_4_categorical_accuracy: 0.9066 - top_5_categorical_accuracy: 0.9376 - top_6_categorical_accuracy: 0.9616 - top_7_categorical_accuracy: 0.9759 - top_8_categorical_accuracy: 0.9864 - top_9_categorical_accuracy: 0.9941 - precision_3: 0.7507 - recall_3: 0.4203 - accuracy: 0.0000e+00 - val_loss: 1.4196 - val_top_1_categorical_accuracy: 0.5317 - val_top_2_categorical_accuracy: 0.7233 - val_top_3_categorical_accuracy: 0.8100 - val_top_4_categorical_accuracy: 0.8707 - val_top_5_categorical_accuracy: 0.9090 - val_top_6_categorical_accuracy: 0.9397 - val_top_7_categorical_accuracy: 0.9570 - val_top_8_categorical_accuracy: 0.9757 - val_top_9_categorical_accuracy: 0.9920 - val_precision_3: 0.6604 - val_recall_3: 0.4220 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "140/140 [==============================] - 8s 54ms/step - loss: 1.1603 - top_1_categorical_accuracy: 0.6071 - top_2_categorical_accuracy: 0.7894 - top_3_categorical_accuracy: 0.8646 - top_4_categorical_accuracy: 0.9139 - top_5_categorical_accuracy: 0.9404 - top_6_categorical_accuracy: 0.9646 - top_7_categorical_accuracy: 0.9756 - top_8_categorical_accuracy: 0.9867 - top_9_categorical_accuracy: 0.9953 - precision_3: 0.7622 - recall_3: 0.4276 - accuracy: 0.0000e+00 - val_loss: 1.3787 - val_top_1_categorical_accuracy: 0.5570 - val_top_2_categorical_accuracy: 0.7400 - val_top_3_categorical_accuracy: 0.8250 - val_top_4_categorical_accuracy: 0.8737 - val_top_5_categorical_accuracy: 0.9190 - val_top_6_categorical_accuracy: 0.9463 - val_top_7_categorical_accuracy: 0.9637 - val_top_8_categorical_accuracy: 0.9807 - val_top_9_categorical_accuracy: 0.9930 - val_precision_3: 0.6776 - val_recall_3: 0.4337 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "140/140 [==============================] - 7s 51ms/step - loss: 1.1479 - top_1_categorical_accuracy: 0.5996 - top_2_categorical_accuracy: 0.7921 - top_3_categorical_accuracy: 0.8656 - top_4_categorical_accuracy: 0.9140 - top_5_categorical_accuracy: 0.9427 - top_6_categorical_accuracy: 0.9627 - top_7_categorical_accuracy: 0.9771 - top_8_categorical_accuracy: 0.9856 - top_9_categorical_accuracy: 0.9936 - precision_3: 0.7688 - recall_3: 0.4366 - accuracy: 0.0000e+00 - val_loss: 1.5012 - val_top_1_categorical_accuracy: 0.5183 - val_top_2_categorical_accuracy: 0.7100 - val_top_3_categorical_accuracy: 0.7957 - val_top_4_categorical_accuracy: 0.8550 - val_top_5_categorical_accuracy: 0.9027 - val_top_6_categorical_accuracy: 0.9343 - val_top_7_categorical_accuracy: 0.9560 - val_top_8_categorical_accuracy: 0.9777 - val_top_9_categorical_accuracy: 0.9897 - val_precision_3: 0.6618 - val_recall_3: 0.3967 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/100\n",
      "140/140 [==============================] - 7s 52ms/step - loss: 1.1745 - top_1_categorical_accuracy: 0.5946 - top_2_categorical_accuracy: 0.7919 - top_3_categorical_accuracy: 0.8647 - top_4_categorical_accuracy: 0.9116 - top_5_categorical_accuracy: 0.9424 - top_6_categorical_accuracy: 0.9659 - top_7_categorical_accuracy: 0.9793 - top_8_categorical_accuracy: 0.9870 - top_9_categorical_accuracy: 0.9943 - precision_3: 0.7473 - recall_3: 0.4220 - accuracy: 0.0000e+00 - val_loss: 1.3838 - val_top_1_categorical_accuracy: 0.5447 - val_top_2_categorical_accuracy: 0.7303 - val_top_3_categorical_accuracy: 0.8120 - val_top_4_categorical_accuracy: 0.8727 - val_top_5_categorical_accuracy: 0.9163 - val_top_6_categorical_accuracy: 0.9517 - val_top_7_categorical_accuracy: 0.9677 - val_top_8_categorical_accuracy: 0.9837 - val_top_9_categorical_accuracy: 0.9940 - val_precision_3: 0.6790 - val_recall_3: 0.4103 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "140/140 [==============================] - 7s 50ms/step - loss: 1.1327 - top_1_categorical_accuracy: 0.6106 - top_2_categorical_accuracy: 0.7956 - top_3_categorical_accuracy: 0.8717 - top_4_categorical_accuracy: 0.9164 - top_5_categorical_accuracy: 0.9460 - top_6_categorical_accuracy: 0.9667 - top_7_categorical_accuracy: 0.9800 - top_8_categorical_accuracy: 0.9877 - top_9_categorical_accuracy: 0.9950 - precision_3: 0.7641 - recall_3: 0.4391 - accuracy: 0.0000e+00 - val_loss: 1.4678 - val_top_1_categorical_accuracy: 0.5337 - val_top_2_categorical_accuracy: 0.7220 - val_top_3_categorical_accuracy: 0.8083 - val_top_4_categorical_accuracy: 0.8687 - val_top_5_categorical_accuracy: 0.9107 - val_top_6_categorical_accuracy: 0.9393 - val_top_7_categorical_accuracy: 0.9567 - val_top_8_categorical_accuracy: 0.9750 - val_top_9_categorical_accuracy: 0.9867 - val_precision_3: 0.6380 - val_recall_3: 0.4283 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "140/140 [==============================] - 7s 51ms/step - loss: 1.1353 - top_1_categorical_accuracy: 0.6029 - top_2_categorical_accuracy: 0.7960 - top_3_categorical_accuracy: 0.8704 - top_4_categorical_accuracy: 0.9153 - top_5_categorical_accuracy: 0.9434 - top_6_categorical_accuracy: 0.9664 - top_7_categorical_accuracy: 0.9784 - top_8_categorical_accuracy: 0.9877 - top_9_categorical_accuracy: 0.9953 - precision_3: 0.7563 - recall_3: 0.4450 - accuracy: 0.0000e+00 - val_loss: 1.4000 - val_top_1_categorical_accuracy: 0.5343 - val_top_2_categorical_accuracy: 0.7253 - val_top_3_categorical_accuracy: 0.8163 - val_top_4_categorical_accuracy: 0.8763 - val_top_5_categorical_accuracy: 0.9160 - val_top_6_categorical_accuracy: 0.9470 - val_top_7_categorical_accuracy: 0.9620 - val_top_8_categorical_accuracy: 0.9787 - val_top_9_categorical_accuracy: 0.9927 - val_precision_3: 0.6629 - val_recall_3: 0.4077 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "140/140 [==============================] - 7s 50ms/step - loss: 1.1260 - top_1_categorical_accuracy: 0.6197 - top_2_categorical_accuracy: 0.8056 - top_3_categorical_accuracy: 0.8750 - top_4_categorical_accuracy: 0.9193 - top_5_categorical_accuracy: 0.9486 - top_6_categorical_accuracy: 0.9659 - top_7_categorical_accuracy: 0.9793 - top_8_categorical_accuracy: 0.9884 - top_9_categorical_accuracy: 0.9943 - precision_3: 0.7634 - recall_3: 0.4546 - accuracy: 0.0000e+00 - val_loss: 1.4319 - val_top_1_categorical_accuracy: 0.5400 - val_top_2_categorical_accuracy: 0.7297 - val_top_3_categorical_accuracy: 0.8127 - val_top_4_categorical_accuracy: 0.8730 - val_top_5_categorical_accuracy: 0.9140 - val_top_6_categorical_accuracy: 0.9447 - val_top_7_categorical_accuracy: 0.9660 - val_top_8_categorical_accuracy: 0.9817 - val_top_9_categorical_accuracy: 0.9920 - val_precision_3: 0.6529 - val_recall_3: 0.4377 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "140/140 [==============================] - 7s 51ms/step - loss: 1.1192 - top_1_categorical_accuracy: 0.6111 - top_2_categorical_accuracy: 0.8031 - top_3_categorical_accuracy: 0.8713 - top_4_categorical_accuracy: 0.9156 - top_5_categorical_accuracy: 0.9451 - top_6_categorical_accuracy: 0.9671 - top_7_categorical_accuracy: 0.9804 - top_8_categorical_accuracy: 0.9881 - top_9_categorical_accuracy: 0.9946 - precision_3: 0.7654 - recall_3: 0.4536 - accuracy: 0.0000e+00 - val_loss: 1.4200 - val_top_1_categorical_accuracy: 0.5473 - val_top_2_categorical_accuracy: 0.7330 - val_top_3_categorical_accuracy: 0.8013 - val_top_4_categorical_accuracy: 0.8683 - val_top_5_categorical_accuracy: 0.9117 - val_top_6_categorical_accuracy: 0.9413 - val_top_7_categorical_accuracy: 0.9597 - val_top_8_categorical_accuracy: 0.9743 - val_top_9_categorical_accuracy: 0.9897 - val_precision_3: 0.6782 - val_recall_3: 0.4363 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "140/140 [==============================] - 7s 49ms/step - loss: 1.0925 - top_1_categorical_accuracy: 0.6227 - top_2_categorical_accuracy: 0.8107 - top_3_categorical_accuracy: 0.8816 - top_4_categorical_accuracy: 0.9254 - top_5_categorical_accuracy: 0.9529 - top_6_categorical_accuracy: 0.9717 - top_7_categorical_accuracy: 0.9819 - top_8_categorical_accuracy: 0.9893 - top_9_categorical_accuracy: 0.9953 - precision_3: 0.7705 - recall_3: 0.4677 - accuracy: 0.0000e+00 - val_loss: 1.4232 - val_top_1_categorical_accuracy: 0.5463 - val_top_2_categorical_accuracy: 0.7243 - val_top_3_categorical_accuracy: 0.8067 - val_top_4_categorical_accuracy: 0.8683 - val_top_5_categorical_accuracy: 0.9130 - val_top_6_categorical_accuracy: 0.9480 - val_top_7_categorical_accuracy: 0.9650 - val_top_8_categorical_accuracy: 0.9803 - val_top_9_categorical_accuracy: 0.9923 - val_precision_3: 0.6784 - val_recall_3: 0.4480 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "140/140 [==============================] - 7s 51ms/step - loss: 1.1184 - top_1_categorical_accuracy: 0.6160 - top_2_categorical_accuracy: 0.8013 - top_3_categorical_accuracy: 0.8739 - top_4_categorical_accuracy: 0.9170 - top_5_categorical_accuracy: 0.9460 - top_6_categorical_accuracy: 0.9663 - top_7_categorical_accuracy: 0.9771 - top_8_categorical_accuracy: 0.9879 - top_9_categorical_accuracy: 0.9946 - precision_3: 0.7594 - recall_3: 0.4604 - accuracy: 0.0000e+00 - val_loss: 1.4095 - val_top_1_categorical_accuracy: 0.5293 - val_top_2_categorical_accuracy: 0.7190 - val_top_3_categorical_accuracy: 0.8013 - val_top_4_categorical_accuracy: 0.8693 - val_top_5_categorical_accuracy: 0.9100 - val_top_6_categorical_accuracy: 0.9447 - val_top_7_categorical_accuracy: 0.9633 - val_top_8_categorical_accuracy: 0.9783 - val_top_9_categorical_accuracy: 0.9897 - val_precision_3: 0.6735 - val_recall_3: 0.4077 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "140/140 [==============================] - 7s 50ms/step - loss: 1.1213 - top_1_categorical_accuracy: 0.6169 - top_2_categorical_accuracy: 0.8000 - top_3_categorical_accuracy: 0.8740 - top_4_categorical_accuracy: 0.9183 - top_5_categorical_accuracy: 0.9480 - top_6_categorical_accuracy: 0.9660 - top_7_categorical_accuracy: 0.9787 - top_8_categorical_accuracy: 0.9860 - top_9_categorical_accuracy: 0.9941 - precision_3: 0.7689 - recall_3: 0.4643 - accuracy: 0.0000e+00 - val_loss: 1.4312 - val_top_1_categorical_accuracy: 0.5393 - val_top_2_categorical_accuracy: 0.7267 - val_top_3_categorical_accuracy: 0.8040 - val_top_4_categorical_accuracy: 0.8697 - val_top_5_categorical_accuracy: 0.9080 - val_top_6_categorical_accuracy: 0.9393 - val_top_7_categorical_accuracy: 0.9617 - val_top_8_categorical_accuracy: 0.9767 - val_top_9_categorical_accuracy: 0.9903 - val_precision_3: 0.6578 - val_recall_3: 0.4293 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "140/140 [==============================] - 7s 49ms/step - loss: 1.0945 - top_1_categorical_accuracy: 0.6251 - top_2_categorical_accuracy: 0.8120 - top_3_categorical_accuracy: 0.8807 - top_4_categorical_accuracy: 0.9243 - top_5_categorical_accuracy: 0.9496 - top_6_categorical_accuracy: 0.9691 - top_7_categorical_accuracy: 0.9804 - top_8_categorical_accuracy: 0.9886 - top_9_categorical_accuracy: 0.9949 - precision_3: 0.7789 - recall_3: 0.4644 - accuracy: 0.0000e+00 - val_loss: 1.4309 - val_top_1_categorical_accuracy: 0.5487 - val_top_2_categorical_accuracy: 0.7397 - val_top_3_categorical_accuracy: 0.8183 - val_top_4_categorical_accuracy: 0.8780 - val_top_5_categorical_accuracy: 0.9170 - val_top_6_categorical_accuracy: 0.9447 - val_top_7_categorical_accuracy: 0.9643 - val_top_8_categorical_accuracy: 0.9783 - val_top_9_categorical_accuracy: 0.9920 - val_precision_3: 0.6609 - val_recall_3: 0.4620 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/100\n",
      "140/140 [==============================] - 7s 51ms/step - loss: 1.1004 - top_1_categorical_accuracy: 0.6257 - top_2_categorical_accuracy: 0.8051 - top_3_categorical_accuracy: 0.8764 - top_4_categorical_accuracy: 0.9219 - top_5_categorical_accuracy: 0.9490 - top_6_categorical_accuracy: 0.9673 - top_7_categorical_accuracy: 0.9807 - top_8_categorical_accuracy: 0.9903 - top_9_categorical_accuracy: 0.9966 - precision_3: 0.7708 - recall_3: 0.4689 - accuracy: 0.0000e+00 - val_loss: 1.3665 - val_top_1_categorical_accuracy: 0.5603 - val_top_2_categorical_accuracy: 0.7310 - val_top_3_categorical_accuracy: 0.8177 - val_top_4_categorical_accuracy: 0.8770 - val_top_5_categorical_accuracy: 0.9227 - val_top_6_categorical_accuracy: 0.9480 - val_top_7_categorical_accuracy: 0.9637 - val_top_8_categorical_accuracy: 0.9787 - val_top_9_categorical_accuracy: 0.9897 - val_precision_3: 0.6894 - val_recall_3: 0.4490 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "140/140 [==============================] - 7s 50ms/step - loss: 1.0905 - top_1_categorical_accuracy: 0.6270 - top_2_categorical_accuracy: 0.8093 - top_3_categorical_accuracy: 0.8794 - top_4_categorical_accuracy: 0.9257 - top_5_categorical_accuracy: 0.9510 - top_6_categorical_accuracy: 0.9703 - top_7_categorical_accuracy: 0.9811 - top_8_categorical_accuracy: 0.9890 - top_9_categorical_accuracy: 0.9941 - precision_3: 0.7660 - recall_3: 0.4776 - accuracy: 0.0000e+00 - val_loss: 1.3587 - val_top_1_categorical_accuracy: 0.5603 - val_top_2_categorical_accuracy: 0.7467 - val_top_3_categorical_accuracy: 0.8267 - val_top_4_categorical_accuracy: 0.8863 - val_top_5_categorical_accuracy: 0.9187 - val_top_6_categorical_accuracy: 0.9463 - val_top_7_categorical_accuracy: 0.9630 - val_top_8_categorical_accuracy: 0.9797 - val_top_9_categorical_accuracy: 0.9927 - val_precision_3: 0.6808 - val_recall_3: 0.4430 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "140/140 [==============================] - 7s 53ms/step - loss: 1.0760 - top_1_categorical_accuracy: 0.6313 - top_2_categorical_accuracy: 0.8110 - top_3_categorical_accuracy: 0.8834 - top_4_categorical_accuracy: 0.9231 - top_5_categorical_accuracy: 0.9501 - top_6_categorical_accuracy: 0.9679 - top_7_categorical_accuracy: 0.9781 - top_8_categorical_accuracy: 0.9873 - top_9_categorical_accuracy: 0.9940 - precision_3: 0.7757 - recall_3: 0.4826 - accuracy: 0.0000e+00 - val_loss: 1.3619 - val_top_1_categorical_accuracy: 0.5543 - val_top_2_categorical_accuracy: 0.7430 - val_top_3_categorical_accuracy: 0.8250 - val_top_4_categorical_accuracy: 0.8803 - val_top_5_categorical_accuracy: 0.9207 - val_top_6_categorical_accuracy: 0.9460 - val_top_7_categorical_accuracy: 0.9627 - val_top_8_categorical_accuracy: 0.9770 - val_top_9_categorical_accuracy: 0.9917 - val_precision_3: 0.6841 - val_recall_3: 0.4570 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "140/140 [==============================] - 7s 51ms/step - loss: 1.0712 - top_1_categorical_accuracy: 0.6283 - top_2_categorical_accuracy: 0.8099 - top_3_categorical_accuracy: 0.8774 - top_4_categorical_accuracy: 0.9230 - top_5_categorical_accuracy: 0.9509 - top_6_categorical_accuracy: 0.9690 - top_7_categorical_accuracy: 0.9801 - top_8_categorical_accuracy: 0.9891 - top_9_categorical_accuracy: 0.9941 - precision_3: 0.7709 - recall_3: 0.4850 - accuracy: 0.0000e+00 - val_loss: 1.4070 - val_top_1_categorical_accuracy: 0.5633 - val_top_2_categorical_accuracy: 0.7377 - val_top_3_categorical_accuracy: 0.8197 - val_top_4_categorical_accuracy: 0.8773 - val_top_5_categorical_accuracy: 0.9220 - val_top_6_categorical_accuracy: 0.9473 - val_top_7_categorical_accuracy: 0.9673 - val_top_8_categorical_accuracy: 0.9830 - val_top_9_categorical_accuracy: 0.9923 - val_precision_3: 0.6719 - val_recall_3: 0.4813 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "140/140 [==============================] - 7s 49ms/step - loss: 1.0480 - top_1_categorical_accuracy: 0.6423 - top_2_categorical_accuracy: 0.8170 - top_3_categorical_accuracy: 0.8849 - top_4_categorical_accuracy: 0.9266 - top_5_categorical_accuracy: 0.9517 - top_6_categorical_accuracy: 0.9723 - top_7_categorical_accuracy: 0.9840 - top_8_categorical_accuracy: 0.9907 - top_9_categorical_accuracy: 0.9963 - precision_3: 0.7926 - recall_3: 0.5016 - accuracy: 0.0000e+00 - val_loss: 1.4737 - val_top_1_categorical_accuracy: 0.5160 - val_top_2_categorical_accuracy: 0.7157 - val_top_3_categorical_accuracy: 0.8053 - val_top_4_categorical_accuracy: 0.8667 - val_top_5_categorical_accuracy: 0.9097 - val_top_6_categorical_accuracy: 0.9410 - val_top_7_categorical_accuracy: 0.9607 - val_top_8_categorical_accuracy: 0.9750 - val_top_9_categorical_accuracy: 0.9883 - val_precision_3: 0.6205 - val_recall_3: 0.4213 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "140/140 [==============================] - 7s 50ms/step - loss: 1.0363 - top_1_categorical_accuracy: 0.6507 - top_2_categorical_accuracy: 0.8234 - top_3_categorical_accuracy: 0.8897 - top_4_categorical_accuracy: 0.9319 - top_5_categorical_accuracy: 0.9577 - top_6_categorical_accuracy: 0.9736 - top_7_categorical_accuracy: 0.9839 - top_8_categorical_accuracy: 0.9906 - top_9_categorical_accuracy: 0.9947 - precision_3: 0.7811 - recall_3: 0.5073 - accuracy: 0.0000e+00 - val_loss: 1.4066 - val_top_1_categorical_accuracy: 0.5377 - val_top_2_categorical_accuracy: 0.7357 - val_top_3_categorical_accuracy: 0.8220 - val_top_4_categorical_accuracy: 0.8730 - val_top_5_categorical_accuracy: 0.9120 - val_top_6_categorical_accuracy: 0.9473 - val_top_7_categorical_accuracy: 0.9653 - val_top_8_categorical_accuracy: 0.9807 - val_top_9_categorical_accuracy: 0.9923 - val_precision_3: 0.6420 - val_recall_3: 0.4363 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "140/140 [==============================] - 7s 48ms/step - loss: 1.0563 - top_1_categorical_accuracy: 0.6487 - top_2_categorical_accuracy: 0.8237 - top_3_categorical_accuracy: 0.8886 - top_4_categorical_accuracy: 0.9291 - top_5_categorical_accuracy: 0.9546 - top_6_categorical_accuracy: 0.9701 - top_7_categorical_accuracy: 0.9796 - top_8_categorical_accuracy: 0.9884 - top_9_categorical_accuracy: 0.9949 - precision_3: 0.7753 - recall_3: 0.5067 - accuracy: 0.0000e+00 - val_loss: 1.3715 - val_top_1_categorical_accuracy: 0.5510 - val_top_2_categorical_accuracy: 0.7457 - val_top_3_categorical_accuracy: 0.8290 - val_top_4_categorical_accuracy: 0.8887 - val_top_5_categorical_accuracy: 0.9247 - val_top_6_categorical_accuracy: 0.9533 - val_top_7_categorical_accuracy: 0.9667 - val_top_8_categorical_accuracy: 0.9817 - val_top_9_categorical_accuracy: 0.9923 - val_precision_3: 0.6545 - val_recall_3: 0.4470 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "140/140 [==============================] - 7s 49ms/step - loss: 1.0306 - top_1_categorical_accuracy: 0.6500 - top_2_categorical_accuracy: 0.8231 - top_3_categorical_accuracy: 0.8906 - top_4_categorical_accuracy: 0.9306 - top_5_categorical_accuracy: 0.9579 - top_6_categorical_accuracy: 0.9723 - top_7_categorical_accuracy: 0.9823 - top_8_categorical_accuracy: 0.9886 - top_9_categorical_accuracy: 0.9956 - precision_3: 0.7823 - recall_3: 0.5031 - accuracy: 0.0000e+00 - val_loss: 1.3854 - val_top_1_categorical_accuracy: 0.5370 - val_top_2_categorical_accuracy: 0.7373 - val_top_3_categorical_accuracy: 0.8227 - val_top_4_categorical_accuracy: 0.8883 - val_top_5_categorical_accuracy: 0.9263 - val_top_6_categorical_accuracy: 0.9513 - val_top_7_categorical_accuracy: 0.9667 - val_top_8_categorical_accuracy: 0.9813 - val_top_9_categorical_accuracy: 0.9930 - val_precision_3: 0.6473 - val_recall_3: 0.4270 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "140/140 [==============================] - 7s 50ms/step - loss: 1.0309 - top_1_categorical_accuracy: 0.6553 - top_2_categorical_accuracy: 0.8284 - top_3_categorical_accuracy: 0.8944 - top_4_categorical_accuracy: 0.9347 - top_5_categorical_accuracy: 0.9587 - top_6_categorical_accuracy: 0.9736 - top_7_categorical_accuracy: 0.9840 - top_8_categorical_accuracy: 0.9906 - top_9_categorical_accuracy: 0.9964 - precision_3: 0.7806 - recall_3: 0.5129 - accuracy: 0.0000e+00 - val_loss: 1.3284 - val_top_1_categorical_accuracy: 0.5760 - val_top_2_categorical_accuracy: 0.7517 - val_top_3_categorical_accuracy: 0.8317 - val_top_4_categorical_accuracy: 0.8843 - val_top_5_categorical_accuracy: 0.9223 - val_top_6_categorical_accuracy: 0.9470 - val_top_7_categorical_accuracy: 0.9650 - val_top_8_categorical_accuracy: 0.9817 - val_top_9_categorical_accuracy: 0.9933 - val_precision_3: 0.6832 - val_recall_3: 0.4673 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/100\n",
      "140/140 [==============================] - 7s 49ms/step - loss: 1.0360 - top_1_categorical_accuracy: 0.6527 - top_2_categorical_accuracy: 0.8251 - top_3_categorical_accuracy: 0.8931 - top_4_categorical_accuracy: 0.9291 - top_5_categorical_accuracy: 0.9554 - top_6_categorical_accuracy: 0.9721 - top_7_categorical_accuracy: 0.9827 - top_8_categorical_accuracy: 0.9910 - top_9_categorical_accuracy: 0.9956 - precision_3: 0.7835 - recall_3: 0.5184 - accuracy: 0.0000e+00 - val_loss: 1.4400 - val_top_1_categorical_accuracy: 0.5613 - val_top_2_categorical_accuracy: 0.7337 - val_top_3_categorical_accuracy: 0.8157 - val_top_4_categorical_accuracy: 0.8733 - val_top_5_categorical_accuracy: 0.9120 - val_top_6_categorical_accuracy: 0.9407 - val_top_7_categorical_accuracy: 0.9620 - val_top_8_categorical_accuracy: 0.9740 - val_top_9_categorical_accuracy: 0.9877 - val_precision_3: 0.6602 - val_recall_3: 0.4753 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "140/140 [==============================] - 7s 54ms/step - loss: 1.0369 - top_1_categorical_accuracy: 0.6476 - top_2_categorical_accuracy: 0.8197 - top_3_categorical_accuracy: 0.8879 - top_4_categorical_accuracy: 0.9304 - top_5_categorical_accuracy: 0.9557 - top_6_categorical_accuracy: 0.9729 - top_7_categorical_accuracy: 0.9813 - top_8_categorical_accuracy: 0.9884 - top_9_categorical_accuracy: 0.9940 - precision_3: 0.7931 - recall_3: 0.5060 - accuracy: 0.0000e+00 - val_loss: 1.3370 - val_top_1_categorical_accuracy: 0.5563 - val_top_2_categorical_accuracy: 0.7373 - val_top_3_categorical_accuracy: 0.8223 - val_top_4_categorical_accuracy: 0.8817 - val_top_5_categorical_accuracy: 0.9197 - val_top_6_categorical_accuracy: 0.9463 - val_top_7_categorical_accuracy: 0.9683 - val_top_8_categorical_accuracy: 0.9810 - val_top_9_categorical_accuracy: 0.9910 - val_precision_3: 0.7028 - val_recall_3: 0.4407 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "140/140 [==============================] - 7s 49ms/step - loss: 1.0271 - top_1_categorical_accuracy: 0.6469 - top_2_categorical_accuracy: 0.8211 - top_3_categorical_accuracy: 0.8861 - top_4_categorical_accuracy: 0.9256 - top_5_categorical_accuracy: 0.9514 - top_6_categorical_accuracy: 0.9683 - top_7_categorical_accuracy: 0.9791 - top_8_categorical_accuracy: 0.9874 - top_9_categorical_accuracy: 0.9950 - precision_3: 0.7831 - recall_3: 0.5131 - accuracy: 0.0000e+00 - val_loss: 1.3303 - val_top_1_categorical_accuracy: 0.5613 - val_top_2_categorical_accuracy: 0.7430 - val_top_3_categorical_accuracy: 0.8187 - val_top_4_categorical_accuracy: 0.8730 - val_top_5_categorical_accuracy: 0.9193 - val_top_6_categorical_accuracy: 0.9473 - val_top_7_categorical_accuracy: 0.9660 - val_top_8_categorical_accuracy: 0.9810 - val_top_9_categorical_accuracy: 0.9927 - val_precision_3: 0.7026 - val_recall_3: 0.4363 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "140/140 [==============================] - 7s 50ms/step - loss: 1.0219 - top_1_categorical_accuracy: 0.6519 - top_2_categorical_accuracy: 0.8253 - top_3_categorical_accuracy: 0.8907 - top_4_categorical_accuracy: 0.9319 - top_5_categorical_accuracy: 0.9560 - top_6_categorical_accuracy: 0.9729 - top_7_categorical_accuracy: 0.9834 - top_8_categorical_accuracy: 0.9914 - top_9_categorical_accuracy: 0.9960 - precision_3: 0.7869 - recall_3: 0.5111 - accuracy: 0.0000e+00 - val_loss: 1.4161 - val_top_1_categorical_accuracy: 0.5523 - val_top_2_categorical_accuracy: 0.7263 - val_top_3_categorical_accuracy: 0.8097 - val_top_4_categorical_accuracy: 0.8713 - val_top_5_categorical_accuracy: 0.9167 - val_top_6_categorical_accuracy: 0.9453 - val_top_7_categorical_accuracy: 0.9627 - val_top_8_categorical_accuracy: 0.9797 - val_top_9_categorical_accuracy: 0.9927 - val_precision_3: 0.6708 - val_recall_3: 0.4483 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "140/140 [==============================] - 7s 53ms/step - loss: 1.0114 - top_1_categorical_accuracy: 0.6679 - top_2_categorical_accuracy: 0.8296 - top_3_categorical_accuracy: 0.8947 - top_4_categorical_accuracy: 0.9309 - top_5_categorical_accuracy: 0.9560 - top_6_categorical_accuracy: 0.9743 - top_7_categorical_accuracy: 0.9847 - top_8_categorical_accuracy: 0.9914 - top_9_categorical_accuracy: 0.9964 - precision_3: 0.7964 - recall_3: 0.5293 - accuracy: 0.0000e+00 - val_loss: 1.3916 - val_top_1_categorical_accuracy: 0.5517 - val_top_2_categorical_accuracy: 0.7403 - val_top_3_categorical_accuracy: 0.8177 - val_top_4_categorical_accuracy: 0.8820 - val_top_5_categorical_accuracy: 0.9217 - val_top_6_categorical_accuracy: 0.9440 - val_top_7_categorical_accuracy: 0.9663 - val_top_8_categorical_accuracy: 0.9817 - val_top_9_categorical_accuracy: 0.9920 - val_precision_3: 0.6562 - val_recall_3: 0.4663 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "140/140 [==============================] - 7s 50ms/step - loss: 1.0060 - top_1_categorical_accuracy: 0.6671 - top_2_categorical_accuracy: 0.8307 - top_3_categorical_accuracy: 0.8919 - top_4_categorical_accuracy: 0.9309 - top_5_categorical_accuracy: 0.9571 - top_6_categorical_accuracy: 0.9753 - top_7_categorical_accuracy: 0.9849 - top_8_categorical_accuracy: 0.9900 - top_9_categorical_accuracy: 0.9961 - precision_3: 0.7929 - recall_3: 0.5267 - accuracy: 0.0000e+00 - val_loss: 1.4033 - val_top_1_categorical_accuracy: 0.5457 - val_top_2_categorical_accuracy: 0.7463 - val_top_3_categorical_accuracy: 0.8273 - val_top_4_categorical_accuracy: 0.8820 - val_top_5_categorical_accuracy: 0.9173 - val_top_6_categorical_accuracy: 0.9457 - val_top_7_categorical_accuracy: 0.9660 - val_top_8_categorical_accuracy: 0.9803 - val_top_9_categorical_accuracy: 0.9933 - val_precision_3: 0.6435 - val_recall_3: 0.4543 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "140/140 [==============================] - 7s 51ms/step - loss: 0.9857 - top_1_categorical_accuracy: 0.6670 - top_2_categorical_accuracy: 0.8397 - top_3_categorical_accuracy: 0.8993 - top_4_categorical_accuracy: 0.9340 - top_5_categorical_accuracy: 0.9570 - top_6_categorical_accuracy: 0.9724 - top_7_categorical_accuracy: 0.9821 - top_8_categorical_accuracy: 0.9899 - top_9_categorical_accuracy: 0.9947 - precision_3: 0.7865 - recall_3: 0.5310 - accuracy: 0.0000e+00 - val_loss: 1.3823 - val_top_1_categorical_accuracy: 0.5667 - val_top_2_categorical_accuracy: 0.7390 - val_top_3_categorical_accuracy: 0.8257 - val_top_4_categorical_accuracy: 0.8853 - val_top_5_categorical_accuracy: 0.9193 - val_top_6_categorical_accuracy: 0.9480 - val_top_7_categorical_accuracy: 0.9683 - val_top_8_categorical_accuracy: 0.9817 - val_top_9_categorical_accuracy: 0.9913 - val_precision_3: 0.6741 - val_recall_3: 0.4743 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "140/140 [==============================] - 7s 51ms/step - loss: 0.9943 - top_1_categorical_accuracy: 0.6634 - top_2_categorical_accuracy: 0.8284 - top_3_categorical_accuracy: 0.8939 - top_4_categorical_accuracy: 0.9329 - top_5_categorical_accuracy: 0.9576 - top_6_categorical_accuracy: 0.9734 - top_7_categorical_accuracy: 0.9831 - top_8_categorical_accuracy: 0.9917 - top_9_categorical_accuracy: 0.9966 - precision_3: 0.7911 - recall_3: 0.5329 - accuracy: 0.0000e+00 - val_loss: 1.3691 - val_top_1_categorical_accuracy: 0.5497 - val_top_2_categorical_accuracy: 0.7390 - val_top_3_categorical_accuracy: 0.8240 - val_top_4_categorical_accuracy: 0.8813 - val_top_5_categorical_accuracy: 0.9263 - val_top_6_categorical_accuracy: 0.9470 - val_top_7_categorical_accuracy: 0.9653 - val_top_8_categorical_accuracy: 0.9783 - val_top_9_categorical_accuracy: 0.9900 - val_precision_3: 0.6723 - val_recall_3: 0.4383 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "140/140 [==============================] - 8s 54ms/step - loss: 1.0061 - top_1_categorical_accuracy: 0.6637 - top_2_categorical_accuracy: 0.8329 - top_3_categorical_accuracy: 0.8981 - top_4_categorical_accuracy: 0.9363 - top_5_categorical_accuracy: 0.9580 - top_6_categorical_accuracy: 0.9740 - top_7_categorical_accuracy: 0.9844 - top_8_categorical_accuracy: 0.9904 - top_9_categorical_accuracy: 0.9956 - precision_3: 0.7877 - recall_3: 0.5284 - accuracy: 0.0000e+00 - val_loss: 1.3832 - val_top_1_categorical_accuracy: 0.5493 - val_top_2_categorical_accuracy: 0.7403 - val_top_3_categorical_accuracy: 0.8257 - val_top_4_categorical_accuracy: 0.8817 - val_top_5_categorical_accuracy: 0.9167 - val_top_6_categorical_accuracy: 0.9473 - val_top_7_categorical_accuracy: 0.9650 - val_top_8_categorical_accuracy: 0.9777 - val_top_9_categorical_accuracy: 0.9883 - val_precision_3: 0.6726 - val_recall_3: 0.4527 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/100\n",
      "140/140 [==============================] - 7s 53ms/step - loss: 0.9865 - top_1_categorical_accuracy: 0.6737 - top_2_categorical_accuracy: 0.8354 - top_3_categorical_accuracy: 0.8919 - top_4_categorical_accuracy: 0.9324 - top_5_categorical_accuracy: 0.9549 - top_6_categorical_accuracy: 0.9717 - top_7_categorical_accuracy: 0.9823 - top_8_categorical_accuracy: 0.9891 - top_9_categorical_accuracy: 0.9946 - precision_3: 0.7906 - recall_3: 0.5393 - accuracy: 0.0000e+00 - val_loss: 1.3932 - val_top_1_categorical_accuracy: 0.5590 - val_top_2_categorical_accuracy: 0.7410 - val_top_3_categorical_accuracy: 0.8247 - val_top_4_categorical_accuracy: 0.8837 - val_top_5_categorical_accuracy: 0.9260 - val_top_6_categorical_accuracy: 0.9520 - val_top_7_categorical_accuracy: 0.9670 - val_top_8_categorical_accuracy: 0.9817 - val_top_9_categorical_accuracy: 0.9917 - val_precision_3: 0.6636 - val_recall_3: 0.4827 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "140/140 [==============================] - 7s 49ms/step - loss: 1.0020 - top_1_categorical_accuracy: 0.6639 - top_2_categorical_accuracy: 0.8344 - top_3_categorical_accuracy: 0.8947 - top_4_categorical_accuracy: 0.9344 - top_5_categorical_accuracy: 0.9573 - top_6_categorical_accuracy: 0.9740 - top_7_categorical_accuracy: 0.9841 - top_8_categorical_accuracy: 0.9901 - top_9_categorical_accuracy: 0.9953 - precision_3: 0.7899 - recall_3: 0.5274 - accuracy: 0.0000e+00 - val_loss: 1.3581 - val_top_1_categorical_accuracy: 0.5773 - val_top_2_categorical_accuracy: 0.7427 - val_top_3_categorical_accuracy: 0.8243 - val_top_4_categorical_accuracy: 0.8850 - val_top_5_categorical_accuracy: 0.9237 - val_top_6_categorical_accuracy: 0.9480 - val_top_7_categorical_accuracy: 0.9670 - val_top_8_categorical_accuracy: 0.9820 - val_top_9_categorical_accuracy: 0.9897 - val_precision_3: 0.6952 - val_recall_3: 0.4827 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "140/140 [==============================] - 7s 50ms/step - loss: 0.9584 - top_1_categorical_accuracy: 0.6781 - top_2_categorical_accuracy: 0.8383 - top_3_categorical_accuracy: 0.8967 - top_4_categorical_accuracy: 0.9350 - top_5_categorical_accuracy: 0.9590 - top_6_categorical_accuracy: 0.9759 - top_7_categorical_accuracy: 0.9843 - top_8_categorical_accuracy: 0.9904 - top_9_categorical_accuracy: 0.9964 - precision_3: 0.8087 - recall_3: 0.5500 - accuracy: 0.0000e+00 - val_loss: 1.4972 - val_top_1_categorical_accuracy: 0.5543 - val_top_2_categorical_accuracy: 0.7287 - val_top_3_categorical_accuracy: 0.8093 - val_top_4_categorical_accuracy: 0.8700 - val_top_5_categorical_accuracy: 0.9110 - val_top_6_categorical_accuracy: 0.9403 - val_top_7_categorical_accuracy: 0.9637 - val_top_8_categorical_accuracy: 0.9797 - val_top_9_categorical_accuracy: 0.9920 - val_precision_3: 0.6529 - val_recall_3: 0.4810 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "140/140 [==============================] - 8s 55ms/step - loss: 0.9694 - top_1_categorical_accuracy: 0.6796 - top_2_categorical_accuracy: 0.8367 - top_3_categorical_accuracy: 0.9021 - top_4_categorical_accuracy: 0.9354 - top_5_categorical_accuracy: 0.9591 - top_6_categorical_accuracy: 0.9744 - top_7_categorical_accuracy: 0.9840 - top_8_categorical_accuracy: 0.9913 - top_9_categorical_accuracy: 0.9960 - precision_3: 0.7997 - recall_3: 0.5537 - accuracy: 0.0000e+00 - val_loss: 1.4242 - val_top_1_categorical_accuracy: 0.5380 - val_top_2_categorical_accuracy: 0.7287 - val_top_3_categorical_accuracy: 0.8177 - val_top_4_categorical_accuracy: 0.8753 - val_top_5_categorical_accuracy: 0.9203 - val_top_6_categorical_accuracy: 0.9463 - val_top_7_categorical_accuracy: 0.9657 - val_top_8_categorical_accuracy: 0.9800 - val_top_9_categorical_accuracy: 0.9930 - val_precision_3: 0.6583 - val_recall_3: 0.4437 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "140/140 [==============================] - 7s 52ms/step - loss: 0.9630 - top_1_categorical_accuracy: 0.6806 - top_2_categorical_accuracy: 0.8414 - top_3_categorical_accuracy: 0.9004 - top_4_categorical_accuracy: 0.9383 - top_5_categorical_accuracy: 0.9599 - top_6_categorical_accuracy: 0.9740 - top_7_categorical_accuracy: 0.9827 - top_8_categorical_accuracy: 0.9899 - top_9_categorical_accuracy: 0.9941 - precision_3: 0.7993 - recall_3: 0.5580 - accuracy: 0.0000e+00 - val_loss: 1.4177 - val_top_1_categorical_accuracy: 0.5677 - val_top_2_categorical_accuracy: 0.7360 - val_top_3_categorical_accuracy: 0.8190 - val_top_4_categorical_accuracy: 0.8767 - val_top_5_categorical_accuracy: 0.9247 - val_top_6_categorical_accuracy: 0.9480 - val_top_7_categorical_accuracy: 0.9633 - val_top_8_categorical_accuracy: 0.9773 - val_top_9_categorical_accuracy: 0.9903 - val_precision_3: 0.6612 - val_recall_3: 0.4853 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "140/140 [==============================] - 7s 53ms/step - loss: 0.9636 - top_1_categorical_accuracy: 0.6804 - top_2_categorical_accuracy: 0.8450 - top_3_categorical_accuracy: 0.8996 - top_4_categorical_accuracy: 0.9356 - top_5_categorical_accuracy: 0.9554 - top_6_categorical_accuracy: 0.9737 - top_7_categorical_accuracy: 0.9851 - top_8_categorical_accuracy: 0.9916 - top_9_categorical_accuracy: 0.9970 - precision_3: 0.7925 - recall_3: 0.5553 - accuracy: 0.0000e+00 - val_loss: 1.4523 - val_top_1_categorical_accuracy: 0.5603 - val_top_2_categorical_accuracy: 0.7303 - val_top_3_categorical_accuracy: 0.8173 - val_top_4_categorical_accuracy: 0.8783 - val_top_5_categorical_accuracy: 0.9193 - val_top_6_categorical_accuracy: 0.9510 - val_top_7_categorical_accuracy: 0.9700 - val_top_8_categorical_accuracy: 0.9830 - val_top_9_categorical_accuracy: 0.9940 - val_precision_3: 0.6576 - val_recall_3: 0.4890 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "140/140 [==============================] - 7s 50ms/step - loss: 0.9453 - top_1_categorical_accuracy: 0.6863 - top_2_categorical_accuracy: 0.8437 - top_3_categorical_accuracy: 0.9041 - top_4_categorical_accuracy: 0.9384 - top_5_categorical_accuracy: 0.9599 - top_6_categorical_accuracy: 0.9761 - top_7_categorical_accuracy: 0.9860 - top_8_categorical_accuracy: 0.9914 - top_9_categorical_accuracy: 0.9961 - precision_3: 0.8070 - recall_3: 0.5591 - accuracy: 0.0000e+00 - val_loss: 1.4443 - val_top_1_categorical_accuracy: 0.5670 - val_top_2_categorical_accuracy: 0.7330 - val_top_3_categorical_accuracy: 0.8157 - val_top_4_categorical_accuracy: 0.8790 - val_top_5_categorical_accuracy: 0.9140 - val_top_6_categorical_accuracy: 0.9407 - val_top_7_categorical_accuracy: 0.9660 - val_top_8_categorical_accuracy: 0.9813 - val_top_9_categorical_accuracy: 0.9937 - val_precision_3: 0.6667 - val_recall_3: 0.4700 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "140/140 [==============================] - 7s 52ms/step - loss: 0.9311 - top_1_categorical_accuracy: 0.6896 - top_2_categorical_accuracy: 0.8496 - top_3_categorical_accuracy: 0.9090 - top_4_categorical_accuracy: 0.9404 - top_5_categorical_accuracy: 0.9637 - top_6_categorical_accuracy: 0.9773 - top_7_categorical_accuracy: 0.9859 - top_8_categorical_accuracy: 0.9904 - top_9_categorical_accuracy: 0.9960 - precision_3: 0.8001 - recall_3: 0.5696 - accuracy: 0.0000e+00 - val_loss: 1.4459 - val_top_1_categorical_accuracy: 0.5503 - val_top_2_categorical_accuracy: 0.7280 - val_top_3_categorical_accuracy: 0.8103 - val_top_4_categorical_accuracy: 0.8770 - val_top_5_categorical_accuracy: 0.9140 - val_top_6_categorical_accuracy: 0.9443 - val_top_7_categorical_accuracy: 0.9633 - val_top_8_categorical_accuracy: 0.9787 - val_top_9_categorical_accuracy: 0.9910 - val_precision_3: 0.6510 - val_recall_3: 0.4720 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140/140 [==============================] - 7s 50ms/step - loss: 0.9672 - top_1_categorical_accuracy: 0.6759 - top_2_categorical_accuracy: 0.8397 - top_3_categorical_accuracy: 0.8987 - top_4_categorical_accuracy: 0.9350 - top_5_categorical_accuracy: 0.9583 - top_6_categorical_accuracy: 0.9730 - top_7_categorical_accuracy: 0.9837 - top_8_categorical_accuracy: 0.9909 - top_9_categorical_accuracy: 0.9976 - precision_3: 0.8023 - recall_3: 0.5570 - accuracy: 0.0000e+00 - val_loss: 1.4521 - val_top_1_categorical_accuracy: 0.5497 - val_top_2_categorical_accuracy: 0.7307 - val_top_3_categorical_accuracy: 0.8183 - val_top_4_categorical_accuracy: 0.8720 - val_top_5_categorical_accuracy: 0.9173 - val_top_6_categorical_accuracy: 0.9410 - val_top_7_categorical_accuracy: 0.9600 - val_top_8_categorical_accuracy: 0.9787 - val_top_9_categorical_accuracy: 0.9913 - val_precision_3: 0.6592 - val_recall_3: 0.4527 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "140/140 [==============================] - 7s 50ms/step - loss: 0.9594 - top_1_categorical_accuracy: 0.6823 - top_2_categorical_accuracy: 0.8394 - top_3_categorical_accuracy: 0.9023 - top_4_categorical_accuracy: 0.9383 - top_5_categorical_accuracy: 0.9593 - top_6_categorical_accuracy: 0.9747 - top_7_categorical_accuracy: 0.9851 - top_8_categorical_accuracy: 0.9919 - top_9_categorical_accuracy: 0.9964 - precision_3: 0.7992 - recall_3: 0.5566 - accuracy: 0.0000e+00 - val_loss: 1.4023 - val_top_1_categorical_accuracy: 0.5737 - val_top_2_categorical_accuracy: 0.7430 - val_top_3_categorical_accuracy: 0.8227 - val_top_4_categorical_accuracy: 0.8817 - val_top_5_categorical_accuracy: 0.9227 - val_top_6_categorical_accuracy: 0.9487 - val_top_7_categorical_accuracy: 0.9657 - val_top_8_categorical_accuracy: 0.9810 - val_top_9_categorical_accuracy: 0.9910 - val_precision_3: 0.6732 - val_recall_3: 0.4930 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "140/140 [==============================] - 7s 50ms/step - loss: 0.9201 - top_1_categorical_accuracy: 0.6949 - top_2_categorical_accuracy: 0.8549 - top_3_categorical_accuracy: 0.9104 - top_4_categorical_accuracy: 0.9444 - top_5_categorical_accuracy: 0.9647 - top_6_categorical_accuracy: 0.9763 - top_7_categorical_accuracy: 0.9839 - top_8_categorical_accuracy: 0.9911 - top_9_categorical_accuracy: 0.9954 - precision_3: 0.8027 - recall_3: 0.5667 - accuracy: 0.0000e+00 - val_loss: 1.4224 - val_top_1_categorical_accuracy: 0.5660 - val_top_2_categorical_accuracy: 0.7413 - val_top_3_categorical_accuracy: 0.8203 - val_top_4_categorical_accuracy: 0.8783 - val_top_5_categorical_accuracy: 0.9187 - val_top_6_categorical_accuracy: 0.9483 - val_top_7_categorical_accuracy: 0.9667 - val_top_8_categorical_accuracy: 0.9817 - val_top_9_categorical_accuracy: 0.9907 - val_precision_3: 0.6585 - val_recall_3: 0.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "140/140 [==============================] - 7s 52ms/step - loss: 0.9104 - top_1_categorical_accuracy: 0.6949 - top_2_categorical_accuracy: 0.8483 - top_3_categorical_accuracy: 0.9077 - top_4_categorical_accuracy: 0.9406 - top_5_categorical_accuracy: 0.9627 - top_6_categorical_accuracy: 0.9767 - top_7_categorical_accuracy: 0.9857 - top_8_categorical_accuracy: 0.9917 - top_9_categorical_accuracy: 0.9964 - precision_3: 0.8066 - recall_3: 0.5801 - accuracy: 0.0000e+00 - val_loss: 1.4663 - val_top_1_categorical_accuracy: 0.5457 - val_top_2_categorical_accuracy: 0.7337 - val_top_3_categorical_accuracy: 0.8150 - val_top_4_categorical_accuracy: 0.8750 - val_top_5_categorical_accuracy: 0.9193 - val_top_6_categorical_accuracy: 0.9450 - val_top_7_categorical_accuracy: 0.9623 - val_top_8_categorical_accuracy: 0.9750 - val_top_9_categorical_accuracy: 0.9913 - val_precision_3: 0.6437 - val_recall_3: 0.4547 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "140/140 [==============================] - 7s 53ms/step - loss: 0.9237 - top_1_categorical_accuracy: 0.6956 - top_2_categorical_accuracy: 0.8474 - top_3_categorical_accuracy: 0.9086 - top_4_categorical_accuracy: 0.9434 - top_5_categorical_accuracy: 0.9616 - top_6_categorical_accuracy: 0.9771 - top_7_categorical_accuracy: 0.9850 - top_8_categorical_accuracy: 0.9914 - top_9_categorical_accuracy: 0.9960 - precision_3: 0.8091 - recall_3: 0.5769 - accuracy: 0.0000e+00 - val_loss: 1.4448 - val_top_1_categorical_accuracy: 0.5620 - val_top_2_categorical_accuracy: 0.7373 - val_top_3_categorical_accuracy: 0.8233 - val_top_4_categorical_accuracy: 0.8773 - val_top_5_categorical_accuracy: 0.9203 - val_top_6_categorical_accuracy: 0.9473 - val_top_7_categorical_accuracy: 0.9683 - val_top_8_categorical_accuracy: 0.9823 - val_top_9_categorical_accuracy: 0.9930 - val_precision_3: 0.6641 - val_recall_3: 0.4950 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "140/140 [==============================] - 7s 50ms/step - loss: 0.8909 - top_1_categorical_accuracy: 0.7066 - top_2_categorical_accuracy: 0.8596 - top_3_categorical_accuracy: 0.9140 - top_4_categorical_accuracy: 0.9441 - top_5_categorical_accuracy: 0.9663 - top_6_categorical_accuracy: 0.9804 - top_7_categorical_accuracy: 0.9867 - top_8_categorical_accuracy: 0.9910 - top_9_categorical_accuracy: 0.9963 - precision_3: 0.8148 - recall_3: 0.5877 - accuracy: 0.0000e+00 - val_loss: 1.3739 - val_top_1_categorical_accuracy: 0.5673 - val_top_2_categorical_accuracy: 0.7517 - val_top_3_categorical_accuracy: 0.8310 - val_top_4_categorical_accuracy: 0.8877 - val_top_5_categorical_accuracy: 0.9283 - val_top_6_categorical_accuracy: 0.9527 - val_top_7_categorical_accuracy: 0.9687 - val_top_8_categorical_accuracy: 0.9837 - val_top_9_categorical_accuracy: 0.9913 - val_precision_3: 0.6805 - val_recall_3: 0.4877 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "140/140 [==============================] - 7s 51ms/step - loss: 0.9138 - top_1_categorical_accuracy: 0.6963 - top_2_categorical_accuracy: 0.8537 - top_3_categorical_accuracy: 0.9099 - top_4_categorical_accuracy: 0.9477 - top_5_categorical_accuracy: 0.9649 - top_6_categorical_accuracy: 0.9777 - top_7_categorical_accuracy: 0.9864 - top_8_categorical_accuracy: 0.9917 - top_9_categorical_accuracy: 0.9966 - precision_3: 0.8075 - recall_3: 0.5807 - accuracy: 0.0000e+00 - val_loss: 1.4918 - val_top_1_categorical_accuracy: 0.5493 - val_top_2_categorical_accuracy: 0.7270 - val_top_3_categorical_accuracy: 0.8180 - val_top_4_categorical_accuracy: 0.8763 - val_top_5_categorical_accuracy: 0.9187 - val_top_6_categorical_accuracy: 0.9463 - val_top_7_categorical_accuracy: 0.9677 - val_top_8_categorical_accuracy: 0.9810 - val_top_9_categorical_accuracy: 0.9913 - val_precision_3: 0.6353 - val_recall_3: 0.4843 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "140/140 [==============================] - 7s 51ms/step - loss: 0.9049 - top_1_categorical_accuracy: 0.6991 - top_2_categorical_accuracy: 0.8499 - top_3_categorical_accuracy: 0.9070 - top_4_categorical_accuracy: 0.9437 - top_5_categorical_accuracy: 0.9621 - top_6_categorical_accuracy: 0.9747 - top_7_categorical_accuracy: 0.9839 - top_8_categorical_accuracy: 0.9914 - top_9_categorical_accuracy: 0.9953 - precision_3: 0.8071 - recall_3: 0.5851 - accuracy: 0.0000e+00 - val_loss: 1.4582 - val_top_1_categorical_accuracy: 0.5570 - val_top_2_categorical_accuracy: 0.7337 - val_top_3_categorical_accuracy: 0.8210 - val_top_4_categorical_accuracy: 0.8750 - val_top_5_categorical_accuracy: 0.9147 - val_top_6_categorical_accuracy: 0.9433 - val_top_7_categorical_accuracy: 0.9597 - val_top_8_categorical_accuracy: 0.9770 - val_top_9_categorical_accuracy: 0.9900 - val_precision_3: 0.6543 - val_recall_3: 0.4763 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "\n",
    "date = pendulum.now().__str__()[:16].replace(\"T\",\"_\").replace(\":\",\"_\")\n",
    "\n",
    "RESULTS_DIR = f'vit-ResidualMLP-image-classifier_{date}'\n",
    "PATIENCE = 25\n",
    "PATIENCE_MIN_DELTA = 0.00001\n",
    "BATCH_SIZE = 50\n",
    "EPOCHS = 100\n",
    "\n",
    "logdir = os.path.join(\"logs\", RESULTS_DIR + \"_TB\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "\n",
    "history = final_residual_mlp.fit(\n",
    "    x=selected_x_train,\n",
    "    y=selected_y_train_ohe,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    verbose=\"auto\",\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor=\"val_loss\",\n",
    "            patience=PATIENCE,\n",
    "            min_delta=PATIENCE_MIN_DELTA,\n",
    "            restore_best_weights=True,\n",
    "        ),\n",
    "        tensorboard_callback,\n",
    "    ],\n",
    "    validation_split=0.3,\n",
    "    validation_data=None,\n",
    "    shuffle=True,\n",
    "    class_weight=None,\n",
    "    sample_weight=None,\n",
    "    initial_epoch=0,\n",
    "    steps_per_epoch=None,\n",
    "    validation_steps=None,\n",
    "    validation_batch_size=10,\n",
    "    validation_freq=1,\n",
    "    max_queue_size=10,\n",
    "    workers=5,\n",
    "    use_multiprocessing=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6bc273a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hy = pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ab5378db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>top_1_categorical_accuracy</th>\n",
       "      <th>top_2_categorical_accuracy</th>\n",
       "      <th>top_3_categorical_accuracy</th>\n",
       "      <th>top_4_categorical_accuracy</th>\n",
       "      <th>top_5_categorical_accuracy</th>\n",
       "      <th>top_6_categorical_accuracy</th>\n",
       "      <th>top_7_categorical_accuracy</th>\n",
       "      <th>top_8_categorical_accuracy</th>\n",
       "      <th>top_9_categorical_accuracy</th>\n",
       "      <th>...</th>\n",
       "      <th>val_top_3_categorical_accuracy</th>\n",
       "      <th>val_top_4_categorical_accuracy</th>\n",
       "      <th>val_top_5_categorical_accuracy</th>\n",
       "      <th>val_top_6_categorical_accuracy</th>\n",
       "      <th>val_top_7_categorical_accuracy</th>\n",
       "      <th>val_top_8_categorical_accuracy</th>\n",
       "      <th>val_top_9_categorical_accuracy</th>\n",
       "      <th>val_precision_3</th>\n",
       "      <th>val_recall_3</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.434435</td>\n",
       "      <td>0.113571</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.313857</td>\n",
       "      <td>0.413571</td>\n",
       "      <td>0.514143</td>\n",
       "      <td>0.612286</td>\n",
       "      <td>0.712429</td>\n",
       "      <td>0.809286</td>\n",
       "      <td>0.908857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.274000</td>\n",
       "      <td>0.375667</td>\n",
       "      <td>0.486333</td>\n",
       "      <td>0.593333</td>\n",
       "      <td>0.692000</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>0.915333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.349118</td>\n",
       "      <td>0.104571</td>\n",
       "      <td>0.202857</td>\n",
       "      <td>0.303571</td>\n",
       "      <td>0.405286</td>\n",
       "      <td>0.508000</td>\n",
       "      <td>0.604143</td>\n",
       "      <td>0.702714</td>\n",
       "      <td>0.801571</td>\n",
       "      <td>0.900429</td>\n",
       "      <td>...</td>\n",
       "      <td>0.348000</td>\n",
       "      <td>0.461333</td>\n",
       "      <td>0.559667</td>\n",
       "      <td>0.651667</td>\n",
       "      <td>0.741000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.921667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.305942</td>\n",
       "      <td>0.113143</td>\n",
       "      <td>0.216429</td>\n",
       "      <td>0.332000</td>\n",
       "      <td>0.430000</td>\n",
       "      <td>0.528429</td>\n",
       "      <td>0.625714</td>\n",
       "      <td>0.724571</td>\n",
       "      <td>0.819286</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>...</td>\n",
       "      <td>0.327667</td>\n",
       "      <td>0.433000</td>\n",
       "      <td>0.547667</td>\n",
       "      <td>0.642000</td>\n",
       "      <td>0.738000</td>\n",
       "      <td>0.824000</td>\n",
       "      <td>0.915667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.262347</td>\n",
       "      <td>0.136571</td>\n",
       "      <td>0.255857</td>\n",
       "      <td>0.367429</td>\n",
       "      <td>0.472143</td>\n",
       "      <td>0.566571</td>\n",
       "      <td>0.664571</td>\n",
       "      <td>0.760143</td>\n",
       "      <td>0.851000</td>\n",
       "      <td>0.926286</td>\n",
       "      <td>...</td>\n",
       "      <td>0.309333</td>\n",
       "      <td>0.386000</td>\n",
       "      <td>0.458667</td>\n",
       "      <td>0.576667</td>\n",
       "      <td>0.672333</td>\n",
       "      <td>0.794667</td>\n",
       "      <td>0.906333</td>\n",
       "      <td>0.002907</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.196239</td>\n",
       "      <td>0.158429</td>\n",
       "      <td>0.300429</td>\n",
       "      <td>0.421286</td>\n",
       "      <td>0.532714</td>\n",
       "      <td>0.633286</td>\n",
       "      <td>0.726571</td>\n",
       "      <td>0.809286</td>\n",
       "      <td>0.884714</td>\n",
       "      <td>0.943857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.572000</td>\n",
       "      <td>0.687333</td>\n",
       "      <td>0.790333</td>\n",
       "      <td>0.841667</td>\n",
       "      <td>0.901667</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.910374</td>\n",
       "      <td>0.694857</td>\n",
       "      <td>0.848286</td>\n",
       "      <td>0.907714</td>\n",
       "      <td>0.940571</td>\n",
       "      <td>0.962714</td>\n",
       "      <td>0.976714</td>\n",
       "      <td>0.985714</td>\n",
       "      <td>0.991714</td>\n",
       "      <td>0.996429</td>\n",
       "      <td>...</td>\n",
       "      <td>0.815000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.919333</td>\n",
       "      <td>0.945000</td>\n",
       "      <td>0.962333</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.991333</td>\n",
       "      <td>0.643700</td>\n",
       "      <td>0.454667</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.923665</td>\n",
       "      <td>0.695571</td>\n",
       "      <td>0.847429</td>\n",
       "      <td>0.908571</td>\n",
       "      <td>0.943429</td>\n",
       "      <td>0.961571</td>\n",
       "      <td>0.977143</td>\n",
       "      <td>0.985000</td>\n",
       "      <td>0.991429</td>\n",
       "      <td>0.996000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.823333</td>\n",
       "      <td>0.877333</td>\n",
       "      <td>0.920333</td>\n",
       "      <td>0.947333</td>\n",
       "      <td>0.968333</td>\n",
       "      <td>0.982333</td>\n",
       "      <td>0.993000</td>\n",
       "      <td>0.664132</td>\n",
       "      <td>0.495000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.890936</td>\n",
       "      <td>0.706571</td>\n",
       "      <td>0.859571</td>\n",
       "      <td>0.914000</td>\n",
       "      <td>0.944143</td>\n",
       "      <td>0.966286</td>\n",
       "      <td>0.980429</td>\n",
       "      <td>0.986714</td>\n",
       "      <td>0.991000</td>\n",
       "      <td>0.996286</td>\n",
       "      <td>...</td>\n",
       "      <td>0.831000</td>\n",
       "      <td>0.887667</td>\n",
       "      <td>0.928333</td>\n",
       "      <td>0.952667</td>\n",
       "      <td>0.968667</td>\n",
       "      <td>0.983667</td>\n",
       "      <td>0.991333</td>\n",
       "      <td>0.680465</td>\n",
       "      <td>0.487667</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.913805</td>\n",
       "      <td>0.696286</td>\n",
       "      <td>0.853714</td>\n",
       "      <td>0.909857</td>\n",
       "      <td>0.947714</td>\n",
       "      <td>0.964857</td>\n",
       "      <td>0.977714</td>\n",
       "      <td>0.986429</td>\n",
       "      <td>0.991714</td>\n",
       "      <td>0.996571</td>\n",
       "      <td>...</td>\n",
       "      <td>0.818000</td>\n",
       "      <td>0.876333</td>\n",
       "      <td>0.918667</td>\n",
       "      <td>0.946333</td>\n",
       "      <td>0.967667</td>\n",
       "      <td>0.981000</td>\n",
       "      <td>0.991333</td>\n",
       "      <td>0.635330</td>\n",
       "      <td>0.484333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.904884</td>\n",
       "      <td>0.699143</td>\n",
       "      <td>0.849857</td>\n",
       "      <td>0.907000</td>\n",
       "      <td>0.943714</td>\n",
       "      <td>0.962143</td>\n",
       "      <td>0.974714</td>\n",
       "      <td>0.983857</td>\n",
       "      <td>0.991429</td>\n",
       "      <td>0.995286</td>\n",
       "      <td>...</td>\n",
       "      <td>0.821000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.914667</td>\n",
       "      <td>0.943333</td>\n",
       "      <td>0.959667</td>\n",
       "      <td>0.977000</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.654304</td>\n",
       "      <td>0.476333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>97 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss  top_1_categorical_accuracy  top_2_categorical_accuracy  \\\n",
       "0   2.434435                    0.113571                    0.214286   \n",
       "1   2.349118                    0.104571                    0.202857   \n",
       "2   2.305942                    0.113143                    0.216429   \n",
       "3   2.262347                    0.136571                    0.255857   \n",
       "4   2.196239                    0.158429                    0.300429   \n",
       "..       ...                         ...                         ...   \n",
       "92  0.910374                    0.694857                    0.848286   \n",
       "93  0.923665                    0.695571                    0.847429   \n",
       "94  0.890936                    0.706571                    0.859571   \n",
       "95  0.913805                    0.696286                    0.853714   \n",
       "96  0.904884                    0.699143                    0.849857   \n",
       "\n",
       "    top_3_categorical_accuracy  top_4_categorical_accuracy  \\\n",
       "0                     0.313857                    0.413571   \n",
       "1                     0.303571                    0.405286   \n",
       "2                     0.332000                    0.430000   \n",
       "3                     0.367429                    0.472143   \n",
       "4                     0.421286                    0.532714   \n",
       "..                         ...                         ...   \n",
       "92                    0.907714                    0.940571   \n",
       "93                    0.908571                    0.943429   \n",
       "94                    0.914000                    0.944143   \n",
       "95                    0.909857                    0.947714   \n",
       "96                    0.907000                    0.943714   \n",
       "\n",
       "    top_5_categorical_accuracy  top_6_categorical_accuracy  \\\n",
       "0                     0.514143                    0.612286   \n",
       "1                     0.508000                    0.604143   \n",
       "2                     0.528429                    0.625714   \n",
       "3                     0.566571                    0.664571   \n",
       "4                     0.633286                    0.726571   \n",
       "..                         ...                         ...   \n",
       "92                    0.962714                    0.976714   \n",
       "93                    0.961571                    0.977143   \n",
       "94                    0.966286                    0.980429   \n",
       "95                    0.964857                    0.977714   \n",
       "96                    0.962143                    0.974714   \n",
       "\n",
       "    top_7_categorical_accuracy  top_8_categorical_accuracy  \\\n",
       "0                     0.712429                    0.809286   \n",
       "1                     0.702714                    0.801571   \n",
       "2                     0.724571                    0.819286   \n",
       "3                     0.760143                    0.851000   \n",
       "4                     0.809286                    0.884714   \n",
       "..                         ...                         ...   \n",
       "92                    0.985714                    0.991714   \n",
       "93                    0.985000                    0.991429   \n",
       "94                    0.986714                    0.991000   \n",
       "95                    0.986429                    0.991714   \n",
       "96                    0.983857                    0.991429   \n",
       "\n",
       "    top_9_categorical_accuracy  ...  val_top_3_categorical_accuracy  \\\n",
       "0                     0.908857  ...                        0.274000   \n",
       "1                     0.900429  ...                        0.348000   \n",
       "2                     0.914286  ...                        0.327667   \n",
       "3                     0.926286  ...                        0.309333   \n",
       "4                     0.943857  ...                        0.458333   \n",
       "..                         ...  ...                             ...   \n",
       "92                    0.996429  ...                        0.815000   \n",
       "93                    0.996000  ...                        0.823333   \n",
       "94                    0.996286  ...                        0.831000   \n",
       "95                    0.996571  ...                        0.818000   \n",
       "96                    0.995286  ...                        0.821000   \n",
       "\n",
       "    val_top_4_categorical_accuracy  val_top_5_categorical_accuracy  \\\n",
       "0                         0.375667                        0.486333   \n",
       "1                         0.461333                        0.559667   \n",
       "2                         0.433000                        0.547667   \n",
       "3                         0.386000                        0.458667   \n",
       "4                         0.572000                        0.687333   \n",
       "..                             ...                             ...   \n",
       "92                        0.875000                        0.919333   \n",
       "93                        0.877333                        0.920333   \n",
       "94                        0.887667                        0.928333   \n",
       "95                        0.876333                        0.918667   \n",
       "96                        0.875000                        0.914667   \n",
       "\n",
       "    val_top_6_categorical_accuracy  val_top_7_categorical_accuracy  \\\n",
       "0                         0.593333                        0.692000   \n",
       "1                         0.651667                        0.741000   \n",
       "2                         0.642000                        0.738000   \n",
       "3                         0.576667                        0.672333   \n",
       "4                         0.790333                        0.841667   \n",
       "..                             ...                             ...   \n",
       "92                        0.945000                        0.962333   \n",
       "93                        0.947333                        0.968333   \n",
       "94                        0.952667                        0.968667   \n",
       "95                        0.946333                        0.967667   \n",
       "96                        0.943333                        0.959667   \n",
       "\n",
       "    val_top_8_categorical_accuracy  val_top_9_categorical_accuracy  \\\n",
       "0                         0.825000                        0.915333   \n",
       "1                         0.833333                        0.921667   \n",
       "2                         0.824000                        0.915667   \n",
       "3                         0.794667                        0.906333   \n",
       "4                         0.901667                        0.958333   \n",
       "..                             ...                             ...   \n",
       "92                        0.975000                        0.991333   \n",
       "93                        0.982333                        0.993000   \n",
       "94                        0.983667                        0.991333   \n",
       "95                        0.981000                        0.991333   \n",
       "96                        0.977000                        0.990000   \n",
       "\n",
       "    val_precision_3  val_recall_3  val_accuracy  \n",
       "0          0.000000      0.000000           0.0  \n",
       "1          0.000000      0.000000           0.0  \n",
       "2          0.000000      0.000000           0.0  \n",
       "3          0.002907      0.000333           0.0  \n",
       "4          0.750000      0.002000           0.0  \n",
       "..              ...           ...           ...  \n",
       "92         0.643700      0.454667           0.0  \n",
       "93         0.664132      0.495000           0.0  \n",
       "94         0.680465      0.487667           0.0  \n",
       "95         0.635330      0.484333           0.0  \n",
       "96         0.654304      0.476333           0.0  \n",
       "\n",
       "[97 rows x 26 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f3746a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "hy.to_csv(f'{date}_test_history.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a9cdd6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "hy.to_json(f'{date}_test_history.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f62440fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['loss', 'top_1_categorical_accuracy', 'top_2_categorical_accuracy',\n",
       "       'top_3_categorical_accuracy', 'top_4_categorical_accuracy',\n",
       "       'top_5_categorical_accuracy', 'top_6_categorical_accuracy',\n",
       "       'top_7_categorical_accuracy', 'top_8_categorical_accuracy',\n",
       "       'top_9_categorical_accuracy', 'precision_3', 'recall_3', 'accuracy',\n",
       "       'val_loss', 'val_top_1_categorical_accuracy',\n",
       "       'val_top_2_categorical_accuracy', 'val_top_3_categorical_accuracy',\n",
       "       'val_top_4_categorical_accuracy', 'val_top_5_categorical_accuracy',\n",
       "       'val_top_6_categorical_accuracy', 'val_top_7_categorical_accuracy',\n",
       "       'val_top_8_categorical_accuracy', 'val_top_9_categorical_accuracy',\n",
       "       'val_precision_3', 'val_recall_3', 'val_accuracy'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hy.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d61afa80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABFh0lEQVR4nO3deVxU9frA8c+XHUFRETdAwX0DXBD3JZeupallZmZl5q0s7bbcW1m21+12q9/t2p6l2WJZmZZ5LUvT3Bc0c99FBRcQENmZYb6/P76AgICggwPD8369fMmcOefMc2b04TvP+Z7nKK01QgghnJeLowMQQghRuSTRCyGEk5NEL4QQTk4SvRBCODlJ9EII4eTcHPXCDRo00CEhIY56eSGEqJa2bt16VmsdUJFtHJboQ0JCiI6OdtTLCyFEtaSUOlbRbaR0I4QQTk4SvRBCODlJ9EII4eQk0QshhJOTRC+EEE5OEr0QQjg5SfRCCOHkypXolVLDlFL7lVKHlFLTS3j+TaXU9rw/B5RS5+weqRBCVBOnUjL5ZssJcm1Vow38JS+YUkq5Au8CQ4FYYItSarHWek/+OlrrRwqt/yDQpRJiFUKIKu9sWjbjZ20kJjGDrceS+ddNYbi4KIfGVJ4RfRRwSGt9RGudA8wHRpWx/njgK3sEJ4QQ1UlqloW7PtnM6fNZjOkaxNfRJ3h28S7yb/CkteZIQhrnMnKualzlaYEQCJwo9DgW6FHSikqp5kAo8Fspz98L3AvQrFmzCgUqhBBVWbY1l/s+38reU6l8fGckA9sGEFDbkw9+P0yWxUYtD1dW7U/geFIGL43uxB09m1+12Ozd6+ZWYIHWOrekJ7XWs4BZAJGRkVWjeCWEEOWUbc1l+nc72X86FQANZFtyOZdpISXTQq5N859bIrimXUMAnhjWFkuujdlrj+Lt7krvlv7c0y+UIe0bXtW4y5Po44DgQo+D8paV5FZg6pUGJYQQV1uuTZOWbcXP273UdZ5fvJtFf8QxsG0Abi6m8u3l7kK9Wh7UreVO12b1CpI8gFKKp4e3585ezWlUxwsvd9dKP46SlCfRbwFaK6VCMQn+VuC24isppdoB9YANdo1QCCEqiTXXxsYjSSzddYpfdp8mPTuXRVN7065xnYvWnbfpGF9tPsG0a1rxj7+0LfdrKKVo7u9jz7Ar7JInY7XWVmAasAzYC3yjtd6tlHpRKTWy0Kq3AvN1/lkHIYSowlYfSGDYzDXcPnsTi7bF0aOFPz6ebkz78g8yc4pWn7ceS+L5xbsZ2DaAR4a2cVDEl085Ki9HRkZq6UcvhKgsWmvOZVg4k5pFQmo21lyNq4tCA59vOMbyvWdo7l+Lv1/blqHtG+Ht4crag2e5Y84mbu0ezL9uCgdg/aGz/G3+dnw8XVk8tS9+tUov7VwNSqmtWuvIimzjsBuPCCGEPaVkWpi1+jAHzqQRczad40kZZFttJa5by8OVJ4a14+6+IXi6Xaib923dgCkDWvL+qsOEBdZl+4lkvomOpbl/LT6+M9LhSf5ySaIXQlQruTaNJddW5MSm1ponFuzglz2nadXQl9AGPgxsG0BjP28a1fEkwNcTDzcXcm2aXJumZUNfGvh6lrj/R4e2YeORRJ5atBNXF8X9A1vy0ODWDjuRag+S6IUQ1UZKpoWJczZzOiWLeff0oGWALwALtsby8+7TPHldO+4b0PKKXsPd1YV3buvKO78d5PaezenY1M8eoTuU1OiFEFeVJdfGtmPJ+Hi64eftTh1vd9xdFa4uCjcXF1xLaReQkmnhztmb2HPqPLW93HFRiq/u6YGnmyvXzVxNWJAf8/7as9TtnYXU6IUQVd4jX29nyY5TJT7noqBXS39Gdw5kWKfG1PYyNfHCSf79Cd0IaVCL8R9t4tZZG2ns54WLi+L/buns9En+csmIXghx1azcF8+kuVuY1CeEXi38OZdp4XymBWte7fx8poWfd5/mWGIGHm4u+Hm7k23JJctiTqq+f3tXBrdvBMCRhDTGf7SRM+ezmXlrZ0Z1DnTkoV01lzOil0QvhLgqMnKsDP3Parw9XFn6t354uJV8GY/Wmu0nzvHTrtOkZlnxdHPB082FIR0a0T2kfpF1Y5Mz2BGbwvVhTa7GIVQJUroRQlS6zJxc/ow9R/smdcpsF1Dcf5cfJO5cJt9O6VVqkgdzJWmXZvXo0qzeJfcZVK8WQfVqlTuGmkoSvRCiXHKsNr7ecpy3fjtEQmo2Lgo6NvWjdyt/JkQ1p5l/6Ql398kUZq89yvio4ItG5aLySaIXQgCQlJ7DjEU7OZuWTadAP8IC/ajj5c6J5AxOJGWyfO8ZjidlEBVSn+du6MCh+DTWH05kztqjzF5zlLGRQUwb1JrAut4F+0xMy2bWmiN8vuEY9Wq588Swdg48wppLavRCCA7Fp3L33GhOn8+iY9M67D11vuAEKJgOjR2b+jFtUCsGtglAqQuzW86cz+K9lYf4arO5bUWLAB/8vN3x9XRj/eFEsqy53BDelEeGtiG0gWObezkDORkrhKiw1QcSmPrlNjzdXJl1Zze6NquHNdfG4YR0MnKsBNWrRQNfjyLJvSRx5zKZu+4oxxIzTH/2DAsdmtZh6jUtadWw9lU6GucnJ2OFEBWyI/Yckz/dQssAX2bf1b2g7OLm6kLbxhVLzoF1vZkxvENlhCmukCR6IWqo9GwrD83fTgNfT+bf25O6tTwcHZKoJJLohaihXvhxNzGJ6Xx1jyR5ZyeJXggnl5pl4butsWyJSSYypB5D2jdiR2wK30THMvWalvRs4e/oEEUlk0QvhJPJyLESm5xJbHIGqw+cZcHWWNKyrTTw9eR/O0/xwo97cHVRRATX5eEh1e9uSaLiJNELUYVprcuc7XI+y8Lzi3ezMzaFtGwrqVlW0rKtBc97uLowIrwJE3uHEBFcl5iz6azYF8+fJ87xj2vb4u56ybuJCicgiV4IB8u1aVwUFyX0OWuP8vZvB/n7tW2Z0KPZRc/HnE3nr59FE3M2nUHtGpq5615uNPD1JKieN8H1a9EywLdIm4KQBj5M7ht6VY5LVB2S6IVwIK01d32ymYTUbD66M5Lg+qaNwNKdp3hxyR4a+Hrw9Pe7+GnXKf49Jpymft6kZFrYdjyZR7/5E6Xg88k96NVS6uyidJLohXCg77fHsebgWdxdFaPfXcesO811MI98vZ2uzeoy7689WfRHHP/83x4Gvr4KjfkGANCmkS8f39m9zB4zQoBcGSvEVZOYlk29Wh645N0cIzXLwqD/+52mfl783y0RTP40mlMpWdTycMXP252F9/fGP+++pieSMvh84zE8XF3w9/UgoLYn17RtiI+njNVqGrkyVggHsNk0Vpsus/XuztgUbnp/HVGh9Zl5axca+Hoyc/lBzqZl8/GdkbRqWJtFD/Thvs+jOZyQzid3dS9I8gDB9Wvx1PXtr8bhCCdUrlPuSqlhSqn9SqlDSqnppaxzi1Jqj1Jqt1LqS/uGKUTV9Y8Ff9LjleWs3Bdf4vPWXBtPLtqBj6cb0THJjHhrLd9En+CT9TGMiwwmIrguAPV9PPj63l6se2IQLfJuei2EPVwy0SulXIF3geuADsB4pVSHYuu0Bp4E+mitOwIP2z9UIaqen3aeYuG2ODQwae4WXv1pH9ZcW5F1Pt1wjF1x53l5dCcWPtAbT3cXHl+wA19PNx4v1rbXxUXh7eF6FY9A1ATlGdFHAYe01ke01jnAfGBUsXXuAd7VWicDaK1LHtoI4UQS07J5+vtddAqsw9onBjE+qhkf/H6YcbM2svVYMmA6Ov7fL/u5pm0Aw8Oa0LGpH4un9eX2ns147eZw6vtI6wFR+cpTow8EThR6HAv0KLZOGwCl1DrAFXhea/1z8R0ppe4F7gVo1qzZ5cQrhMPkT1zIn8/+7OLdnM+yMG9sD3w93fjXTWH0CK3Pi0v2MOb99fRr3QBLrg2t4cVRnQq28/N25+XRYQ47DlHz2OtkrBvQGhgIBAGrlVJhWutzhVfSWs8CZoGZdWOn1xbCbmLOpvPm8gPc3C2Ifq0DAJPgl+48zfM/7sZm00QE16VRHS/+t+MU/7i2De0a1ynYfnSXQIZ2aMQXG48xa/UREtNzeOr6dgXz44VwhPIk+jgguNDjoLxlhcUCm7TWFuCoUuoAJvFvsUuUQlwFKRkW7p67hSNn0/lh+0kGtg3gvv4t+XR9DD/vPk1YoB/tGtdm+4lzrNwfT0RwXaYMaHnRfnw83bhvQEvu6NWcLTHJ9G3VwAFHI8QF5Un0W4DWSqlQTIK/Fbit2DrfA+OBT5RSDTClnCN2jFOISmXJtTH1y22cSM7gi8k92HvqPG//dpDxH23Ew82F6de14699Q3HL6w2TmmXB3dWl4HFJanm4MaBNwNU6BCFKdclEr7W2KqWmAcsw9fc5WuvdSqkXgWit9eK8565VSu0BcoHHtNaJlRm4EPb00pI9rD10ltdvDqdv6wb0bd2Am7sFsWBrLIPaN6RlsemOtb3cS9mTEFWPXBkrarx3Vx7i9WX7ua9/C56Ui5JEFXc5V8ZKj1JRY2mt+ffP+3h92X5GdW560Zx2UQpbLsTvc3QURtxW+OVpsNkuvW4NJole1Eg2m+bp73fx/qrDTOjRjP/c0hlXl9L7votCdnwD7/WAvT86Ng5bLvzwIKx/Gw7/VomvY4OtcyE5pvJeo5JJohc1zr7T57lzzmbmbTrOfQNa8PLoTpLkK+LwCvP3jw9DWoLj4vhzPsTvBlcP2PR+5b3OwWXw40PwQX/Yt7TyXqcSSaIXTuFQfBpbYpJYd+gsq/bHcyg+rUgrAkuujYNnUnliwQ6un7mGnXEpvDS6E09e177MOziJYrSGo6shMBKyU00CtOd5vvi95SvDWDLht5ehaVfo/xgcWg4J+0tff+P7cHB5ya93fFPZr7X5I/BtDPVDYf54+PVZyLWWvU3cNoj+xL7vzRWQ7pWi2vt84zGe+X7XRcs9XF1oEeBDpiWX2ORMcm0ad1fF3X1CmTaoFXVr1dD2A1pD0hHwv/gagEs6ewDSzsA1MyD7vKmP//kVdC4+4/oyHFoOX4yBAU/ANU+Vve7G9yD1JIz5CALaweo3YNMHMOLNEmI+BD/n9WLscT8MfQFQsOYNWPN/oFxh6kao3+LibRMPm28wA5+CPg/Bsqdg3UyT6Ie9cvH6CQfgt5dg72Lz2LsudLyxIu9CpZBEL6q1E0kZ/GvpXnq39Of+gS3xcHXBxUVxPDGDA2dSORSfhreHKzeENyWkgQ89Qus791Wq509BbKHrFP0CIbDbhce2XPjf32HrJzDhO2g9pGL7P7ra/B3aD+o2N6WMn56A2k2gxUDI/3aUnghbPoaANuVPdKv/z/y99r/mF0e9kJLXSz8La96ENtdBSF+zLHysKeUMegZq1S+6/u5F5u/Ot5sSz7F1oG1wZhd0vAkO/mKO4bZvLsSfb8tscHGDbhPB3QtG/Adys82x9fkb1G58Yd1NH5pfKO61YMB0cw7j1+eg7fXg5okjSaIX1ZbWmqcW7UQBr90cTlC9Cwm8e0j90je0t+xUyDwHdYMvuWqlOnccPh5iRtyFtR8Jf3kFfBrAgsmw/39m+bF1l5Hofwe/YKgXapLije/DJ8Ph89EQ3BP6PgwnNsGmWWBJN9skHYW+j1ycRAs7th6Orzej5s0fw7IZcOu8i9ez5ZqkbEnPG5nn6XE//PEFbPvMxFDY7kUmttHvQvsR8P0D4OoOt34F7a6H9e/ALzNg/1JoN/zCdjkZsP0L8/4VTuj9/gHbvzIj+2H/MssSD8Mvz0DLQXDjh+a9Do6CL24ypZ/e0y5sv28ptLwG3L3L8YbbhyR6UWWdz7Lw887TnEjOwGrT2GyagNqejIxoSsM6XnwbHcuag2d5aXSnIkn+qlvyCBz5Hf6+D1wc1GI4KwXm3QKWLLjzB6iV13bhwE9mpHzwVzNCTtgH170O2+dBXAWvY7HZIGatGaHmJ+16IfDgVvjjc1jzH/jqVkBBpzEmaa+bCStegNRTMOzV0t+fNf9nYh4wHbzqmm0OrYBWgy+sk2uBRVNg1wIY9DQEtL3wXONOENrfJNVe08A1L7Ul7DcnbK97zTxuex08tN2M0j18zLIe95lfEj9NhxbXgEfev6Wd35r3NeqeorHWD4WIWyF6DvR5GHwbwtJ/mJPCI98xSR5M7K2GwOrXzDcUDx/4+UmIng2Dn4N+j1bs/b8CkuhFlZGebeVEcgZHE9JZuus0v+w+TbbVhlLg7uKCiwtkWWy8snQv/VoHsO14Mj1C6zMhyoGdUNPPwu7vwWaB0zuhaeerH0OuBb6ZCIkH4fbvTAklX+NOED7O1JYPLoexn5hSSsI+M03SZgOXUuZknDthTnoGtDGPz+yCzGSTUAtz9zLJsOudcOBnUzPPT8I3fWRGwxveMb8k/IJMIvdvBT2ngJcfnNxu6vODnzVJttdU84vjpyfg/vXg5gHWHFgwCfYtKT1J9poGX95iEmmP+8yy3YsABR0KdVb38iu6nas7DP8/mHs9rHoFev/NxLjlI2jYEZr1uvi1+v3dnJtY/5YpjR3+zfwyqdOk6HpDX4IP+phjSTwIJ/+A3g+aP1eRJHrhcHtOnufez6OJTc4sWObn7c4tkcGM6RZERJBfwcyYIwlpLNwWx6I/4rDZNP8eE15wD1aH2P6lSfJgyhpXmugtmeZEqU+AGeGWloTz2Wyw5GE4shJGvVs0yeer2wzGfWF+IbjmtW4I7GYSYuLBoiPjfGkJpgxkyYApa8zIPb8+H9Kv5FjcPIsmVDDx/+Wf5sTv7u9NWSlhvxktb/kYrn0J9v0PPP2g+18v7GfYqyZpv97S1Lx1LqQnwLB/m18QJWl9LbQcDCteulBu2bUQmvcpWnopSUgf8wtx/dvmT74Rb5ZccvJvCWG3mBr+zgXQJOJC/IU16gBd7oBtn5pjHDfPlI+uMmmBIBzqeGIGYz5Yj5uL4s5eIQTV8ya4fi3aN6mNp1vpZRCbTZNhycX3cm+OfXilqcl2GG1GbJdKqCXRGt6JNAk5M9nU6G//rujzx9ZDcI8LpYSynPzD1NCTDpvHLm7QqCPcvvBCOaCwXIupN+/8pnwzVQpL2A/vRsGo96DLhKLP2Wymtnx8gylHNGwPdy2F+beZ2B7cWv7XKU3cNlj62IXyUb9/wOBniq6z7XPzLcmaCdZsaPMXUxIqS+JheK+XqbX3/we839uM1ktKwsVZssy/iYxEc84FbUb37l4lr3/2ILzT3fx8z4qiJ70LS0+Etf+B7pNLntlTQXJzcFGl2GyauHOZnE3LLljm6+lGywBfXFwUCanZ3DFnE5ZcG1/+tRetG9Uu975dXNTlJ3mADe/CoV9h8ywz4u3+V/OfuiJz6o+tg8RD5mt83DZT97bmmFIDwK7v4LvJEHEbjH6v9H1rbaYL/vqcqfeOfAesWXA+zowuV7wAI98uuo0l05RrDi4zJY++Faz3+rcGj9qmhUDxRL/m/8w3hBveMnXl7ybDqn+Z4w2/pWKvU5rArjD5V/Oe7fufKdcU1/WOiu/Xv6X5PFa9Yr49KBdoX/yGeKVw94JON5X/tRq0Nu+9m2fpSR7Ax998q3EgSfTC7uasPcoP2+M4GJ9GRk7uRc/X8XIjKrQ+J5IyiT+fzRd/7VGhJG8Xp3ea0Xzb681MjV+fhSadocWA8u9ja97X8Q6jwbO2qenGbYXmeTXdbZ+ZEfGfX5oR+bUvXbyPM7vNlLyjq6HtcBj1TtHpgbkW80up2ySTHMHM8vlynPm2MDxvpFhRLi4Q2MXEW9jR1SZJht1iau5Kmfr5mjfM88Xr81fCxcUk88tJ6GXp+7D5lnNsHYQOAN9KbBV9FU+oXglJ9MKuVu2P58UlewgP8uOWyGDaNq5N4zpekDeYTUzLITomic1Hk0hIy+a927vSrXm9qxtkWjyknTYllYhxpq783zBzYq1wotcadi80o/XkGEg5Ya7E7PcoePjCnh9MMvSoZerAKFOnb94Lko+Znwc+ZWrL698ydfc+fzNliNRTsPZN88vAs45J2JF3XzzqH/CEOWm69DEzArakwxc3m7nyYz6GsJsv/30I7Ga+MVgyzVQ/a44pBdVvWbQ2ff3rpoyTHFN6fb4qcfM05ZrPRtnvG0g1J4le2E1KpoXp3+2kdUNfvrmvF17uJdfYb+4WBJh58Be1H7DZ4Me/mROEPR+onOmKp3eavxvn3bfV3Qt63GsuqT+z29TFwVyA8/0UcPMyJyN9G5lSwx9fQJNwc+FMt4lm3Vr1zQm5o6th4HQzIwMFncdDnUDIOAu/PgMrXzE1ZzA1+B5TzCX8xS/yyedVB4a+aOLY8pEpB8VGw81zoOPoK3sfAiPBZjXvR3CU2XfKCZiwADwL9d/3rG0uJoqNLvlcQVXUYiD8bbu5qEtIohf288KPu0lIy2bWnd1KTfKFldhj5vBvZmodmKlxo96DhmW0D85IMjXlvYvNaDPiVmjet+yTqwWJvtOFZZGTzTzw9W/DjR9A6hlTUgnuCZOWXviFkxKXNxL/1HwjyP9lAaassfF9yE6DP+aZZFM3b+rnjR9Cww5mXrZ3XTN9r+Wg8rUhCB9n5mz/9Lj55TD2k4tnt1yO/Lpy3FaT9NfNNNMJW5VwEVVA25Jn51Rl9UMdHUGVIYle2MWve86wcFscDw5qRXhQ3cvf0eZZpsRx7T9Nov2wn5mfHDmp6Ho5GaZ2vf4tyEkzSXbPYjPirt0UajfKW1HBgMfNhTL5Tu8Ev2bgXahkVKu+mQYXPdtcRv/T46akMeqdot8q/AJh+Btm1O5S7L9P6AATz+rXIeU4DHnuwnNuniaOy+HiYkoRCyaZOeQdRl7efoqr08S8V3FbTRuAhL1w46yKnZAW1YIkelFullwbm44kkas1Hq4uaDR/nkhh89FENh5Jon2TOjw4qPXlv0DSEZNw+j9mauctB5mSxZJHTMmg/Q1mvZwMM8c6Zg20G2ESc8N2Zvn+peaimpy8y+9jo02zq+KJvvBoPl+vB0x55Ovb4eQ2GPKCmVlRkpJKGM17meS//m1zUU7hy+mvVJNw+0xrLC6om3mPUuJMa4OKzDoR1YYkelEu2dZcps7bxvK98Rc91zLAh9FdAnlgYEs83AqVTDKSzAUlmUkQMd4kq7JsmW1Gz5F3m8e+AeZCn7kj4Lt74K7/mfr5/NvMVZY3fVT0ZJtHLXNysvAJymUzzLeE7DRTd87JMBcJlVTfrhdiZtDsXghNu5grLSvCwweCupsTl2Fjr2ovk8sW2M0030o+ai5Syr+gSjgVSfTikrIsuUz5Yiur9icw4/r2dG1el2yrDZsN2jauTUDtYp35UuJMCWPbZ+bKSlcPM0+8aVfT8yO0PzRoU7REkJNuavPtRxa9jNzdG8bPh48Hw1fjTKI/ssrU7sszo6L1UHP5/dHVpoFV/F7TubBwbb2wAY+b+esj/lu+i5yKazHQJPrOEy65apWQX6f3qmtKV8IpSaIXF8mx2jielEGuTWO12Xj1p32sPXSWV28K49ZL9ZXJyYDZ15rpi2G3mJ4etRubKYJb55rmTwDe9aF5b5NcWl8LO77OayB178X79A2ACd/C7KEmyY/478UX+ZSmWS9w9zEXR7W7Hk7vMMtLS/QN28PkX8q375L0vB8ah1+Y817VNe1ipor2mlp0po1wKpLoRRGnU7K4c84mDpxJK1imFLw2JpyxkYXa8Gptugs2732h2x+YE6TnY2HiEtOzPF/PKabRVOIhOL4RTmw02+9bYlre5lpM8m3Ws+TAAtqa0s35k+ZS+PJy8zSj7IPLTcynd5p565U17c7Lz/xCqS48a8NDO4qemBZOp1yJXik1DJgJuAIfa61fLfb8XcDrQFzeone01h/bMU5xFRw9m87tH28iJdPCy6M7Ua+WB64uiuD63nRsWqzj354f4NuJ5mToLZ+bmSGpZ8zUw3Yjiib5fEqZk5sNWpurIXMtZlrkpg9ND/PBz5Q946NxWOkj8bK0HmJ6sCfsNx0YG4fJzJLCfPwdHYGoZJdM9EopV+BdYCgQC2xRSi3WWu8pturXWusKnr0SV1OuTbNqfzy9WzbA26PoPPfdJ1OYOGczNg1f3dOTsCC/UvaSZ8M74OZtRuS//xuuedJcOp+bbS7wKQ9Xd9OkqtMY80vCt+FlHtkltBpq/j64DE7vsv8l90JUceUZ0UcBh7TWRwCUUvOBUUDxRC+qMK01z/ywiy83HadTYB0+ujOSJn5mVsgP2+N4cuFO6nq789nkHrRKXgtbz1y46rO445vMJfjXvW46Lv7+qjlxue0zU2O/nHuRFsx7rwR1gyGgvZnVY0m/vG8FQlRj5enNGgicKPQ4Nm9ZcWOUUjuUUguUUiXeU00pda9SKlopFZ2QkHAZ4YrL9daKQ3y56TjXhzUm5mwGN7y9jk1HEnn2h108NH87HZrUYeEDfWjV0NfMO1/2lOl9UpINb+fN0phgeqIERpr2AZ61TW+Wqqj1UDh3zPwsiV7UMJfRhLtEPwIhWutw4Ffg05JW0lrP0lpHaq0jAwIqsaOcKOKrzcd5c/kBbuoayLu3dWXhA73xcVe8+fEcvtuwj7/2DeWre3vS2C+v73Z6grna9MTGi3eWdAT2LjFz3T18TJ+YW+eZmSbX/rP0ni2O1jqvfOPiZu6AJEQNUp7STRxQeIQexIWTrgBorRMLPfwYeO3KQxP2sP7QWWYs2snAtgH8e0w4CmiTsp4Vvi/glrmb/Z3+TtsRxTogpud92zr468VtaTe8Z5Jl4WmQtRubuxBVZcE9Tf/1us3MTBwhapDyjOi3AK2VUqFKKQ/gVmBx4RWUUoVvlDgS2Gu/EMXlyrLk8tSinTSr5837Q71x3/wBzPkLfHkLbtYMcPOmrXdK0Y1sNnMfVDB9yAvLSDK9ZMLGXnxvzKrOzQMGzSj5BhdCOLlLjui11lal1DRgGWZ65Ryt9W6l1ItAtNZ6MfA3pdRIwAokAXdVYsyiBCkZFqw2G/6+F0arH/5+hKDkTcz2m4Pnx2fMQv9Wpvd51zvhg77mLjyFZSab+3P6BUP8HkiJNTd0BtPwy5JRfZNlz/sdHYEQDlGuefRa66XA0mLLni3085PAk/YNTVTE/fO2siM2hf+O68yQDo04lpjO8lUr+MZrJp6+zWDoM3ltcwtV4XwbmptwFJae9zhiPKx+zVzU1G2i6eS48QMzVbGkhmBCiCrLXidjhQPFJmew/nAiWmvu+Tyat1cc5D/f/c5Hrq/h4V3H3Fy66x1FkzyYG2mkni66LL8+H9rP3DDj0K/m8fYvzc0z+jxU+QckhLAraYHgBH7YfpIRLhv4Z4d4fk+qx/crtvGI2wL83TNwvf0X00O9JL6NzIhe6wtXiuaP8H0amhtQ7F4ElizTejewG4T0vToHJYSwG0n01ZzWmmNbljLT411cj9RiZE4aIz3Ahgt67Jdltwb2bWhua5edam5ZBxdG9L55iX7bp+YWeMlHYegL0jpAiGpIEn01d+DQAR5Pf51U3xDq/m0N2CyQsB8XzzrQqEPZG/vmXY2aFl800StXc0FUi4FmKuXmWeaG0e1GVOahCCEqidToqzNrDj4/TMaLHNS4L0ybWe96pgPkpZI8FEr0hWbepMWbW/m5uJjkH5zXTbL3g5Vzo24hRKWTEX11lHkOYrdg++MLgtJ28kHDp5nSrGPF91NSok8/axJ9vi4TzFWyEeOvKGQhhONIoq9GtDWbMx+OplHCBhQapVx5yzqa0L6XeTejwqWbfOnx5kYf+TrfZv4IIaotSfTVyI41i4lIWM9c67Vs8uxNnE9HjqRotrS/zM6P3vVMDb7IiD4B/K/gBt9CiCpHavTVhM2mObNhPqnUouGY17E278feRCujOje9qLd8ubm4mGmU+SN6rSEtAXwa2C9wIYTDyYi+mliy/Rj9szdwrtkQru8SwvVdQsjMycXd9QqnO/o2vDCiz0k30y0r6wYgQgiHkBF9NZBjtbF62XfUVekE9r5wUtTbwxU31yv8CH0bXUj0+e0PfKSFtBDORBJ9NfD1luN0T1+N1d0Xl9aD7bvzwv1u0vIulvKREb0QzkRKN1VRWjwJWxawq9FIjp+z8t6KfSx334pr++vt30vdt5EZydtyL1wVKzV6IZyKJPqqxpbLmdnjaJS8jfTc73nRMo1rvfdTW6dCh9H2fz3fRqBtkJF4oXQjNXohnIok+ioma9UbNErexmbP3ozIXs+QTkF4enrDntrQ0s5lG7hwU+60MxduOFJLRvRCOBNJ9FXJiS14rP43P+T2psXtX0HMbLxWvGieCxtr7s9qb4Wvjk2LNz1u3Dzs/zpCCIeRk7FVRdZ5chdM5pSux9q2TxEWXBf6/R0GPGGeDx9XOa+bX6ZJizc1einbCOF0ZERfFZzcDj/+DZVygkdzn+W167peeG7gk9DtLqjTtHJeO3+GTdoZk+hlaqUQTkdG9I6UnQbLZsBH12A9d5KplodpH3Utzf19LqyjVOUleTAdLz18L4zoJdEL4XRkRO9Ii6fB7kXorncx9cwNrE238vugVlc/jvyrY9PiIXTA1X99IUSlkhG9o2gNR1ZB5wksDHyMZYezeXxYOxr42nmefHn4NoKUWMg6JzV6IZyQJHpHST4KmcmkBnThpf/toVvzetzRs7ljYvFtCGf2mJ/lYikhnI4kekeJ2wbAu/vrkJGdy6s3heHi4qD7sfo2gpxU87O0PxDC6ZQr0Sulhiml9iulDimlppex3hillFZKRdovRCcVt41cV08+PuDF1Gta0bpRbcfFUrhcI6UbIZzOJRO9UsoVeBe4DugAjFdKXXRDUqVUbeAhYJO9g3RGGTGb2ZnbnFaN63H/wJaODca38YWfpXQjhNMpz4g+CjiktT6itc4B5gOjSljvJeDfQJYd43NKJ86ex+X0n+xzac1Hd0bi4ebgCppvoTtUSelGCKdTngwTCJwo9Dg2b1kBpVRXIFhr/b+ydqSUulcpFa2Uik5ISKhwsM4gPjWL5z5egBc59B/4F4Lr13J0SBfKNW7e4OFT9rpCiGrnioeSSikX4D/A3y+1rtZ6ltY6UmsdGRBQ8y7MseTamDw3msCMvQA07djXwRHlyR/R+waYC7SEEE6lPIk+Dggu9Dgob1m+2kAnYJVSKgboCSyWE7IXm7X6CDvjUri3ZTJ4+UH9Fo4OyfBpACi5KlYIJ1WeRL8FaK2UClVKeQC3Aovzn9Rap2itG2itQ7TWIcBGYKTWOrpSIq6mjiSkMXPFQa4Pa0xw5j5o2rXqjJ5d3aGWv9TnhXBSl0z0WmsrMA1YBuwFvtFa71ZKvaiUGlnZAToDm03z5MKdeLq58PywUHNxUmA3R4dVVPfJ0GmMo6MQQlSCcvW60VovBZYWW/ZsKesOvPKwnEhOBsfnTsbvWFtmjL6bhukHQedCYNdLb3s1XfOUoyMQQlQSaWpWydJWvEbIyaV84PETSjeFOKt5oqqN6IUQTksSfSXSiUfw3PQOP9l60r9lHXx+esyc8KzdFGo3vvQOhBDCDqTXTSU69c0jZGtXzg14EZ/bv4KuE03P96pWthFCODUZ0dtLTgbErIWgSKhVn6TtS2h6ZhVf1J7MbddEgYuCG2ZCSD9oHOboaIUQNYgkenuJng2/PA3KBR3cA1vcYY7qJvS945kLXSmVgvCxjo1TCFHjSOnGXo6tB79gdN9HOXM2kbrWsxzo9gwhjeo5OjIhRA0nI3p70BqOb0S3vY6XMsYwJ6krd0U15dkRnR0dmRBCSKK3i7MHITOJxUnBzDlwlEl9Qnh2RAdUVbnyVQhRo0mit4cTGwF466A/9/QL5anr20uSF0JUGZLo7UAf38B5VRufpu0lyQshqhw5GWsHWYfXs9nahom9QyXJCyGqHEn0VyotAe/UGPa4tWd4eBNHRyOEEBeRRH+FEvetBsC/wwC83F0dHI0QQlxMEv0VOrx1OdnanYEDhzo6FCGEKJEk+iuQZcnF+9QWTni1JShALowSQlRNkuivwE9/HKWtPoJXqz6ODkUIIUolif4y5do0a1Ytw0PlEhg20NHhCCFEqSTRX6YlO07SOGU7AKpZT8cGI4QQZZBEfxlybZq3VhxkkPchdEA7qFXf0SEJIUSpJNFfhh//PMmxhBQ6632okH6ODkcIIcokib6CrLk2Zq44yA0NTuOWmwEhfR0dkhBClEkSfQX9sP0kR8+mc3/zU2aBjOiFEFVcuRK9UmqYUmq/UuqQUmp6Cc9PUUrtVEptV0qtVUp1sH+ojpeSaeH1Zfvp2LQOrTP/gIYdwcff0WEJIUSZLpnolVKuwLvAdUAHYHwJifxLrXWY1roz8BrwH3sHWhW8sHg3CWnZvDqqDer4JgiV0bwQouorz4g+CjiktT6itc4B5gOjCq+gtT5f6KEPoO0XYtXw867TLPwjjqnXtCKMw2DNlPq8EKJaKE8/+kDgRKHHsUCP4isppaYCjwIewCC7RFdFZC7+B7//4UPHpkN4cFArWPs9oKC5XBErhKj67HYyVmv9rta6JfAE8HRJ6yil7lVKRSulohMSEuz10pUrKwXvbR/xrO093r62Du6uLnB0NTTuJPPnhRDVQnkSfRwQXOhxUN6y0swHRpf0hNZ6ltY6UmsdGRAQUO4gHenozg0AeCkLLdb+HXLS4cRmCOnv4MiEEKJ8ypPotwCtlVKhSikP4FZgceEVlFKtCz0cDhy0X4iO9efmVQBkDX4ZYrfAt5MgN1tOxAohqo1L1ui11lal1DRgGeAKzNFa71ZKvQhEa60XA9OUUkMAC5AMTKzMoK+W2OQMXE7/SYpXQ/z6ToVTW2DP96BcoFkvR4cnhBDlUq6bg2utlwJLiy17ttDPD9k5riphztoYbnc5ikdwV1AKhv8Hjq2HusHgXdfR4QkhRLmUK9HXRCkZFn7cso9nXU5B87vNQh9/mPyLGdELIUQ1IYm+FF9sOkYLyxHwBJp0vvBE/VBHhSSEEJdFhqYlyLHamLs+hpGNzpgFTTs7NB4hhLgSMqIvwY7YcySkZnNN45NgCwTfho4OSQghLpuM6Euw6WgSAI3S9xUt2wghRDUkib4EW2KSCA9wwTXpsJRthBDVniT6YnJtmq0xyYxoeBbQMqIXQlR7kuiL2XvqPKnZVnp55/VxkxG9EKKak0RfzOa8+nxL6yGo3VROxAohqj1J9MVsPppEUD1vap3dKaN5IYRTkERfiNaaLTFJ9G/mDmcPSn1eCOEUZB59IYcT0klMz+Fml82AhjbXOjokIYS4YjKiL2Tz0SRcsBEW9zUE94CmXRwdkhBCXDFJ9IVsiUliZK1duJ8/Bj2mODocIYSwCyndFLL5aBIfe/4Kbk2h/Q2ODkcIIexCRvR54s5l4p1ykPaZW6H7ZHB1d3RIQghhF5Lo8/y6+zR3uS7D5uoJ3e5ydDhCCGE3kujz/By9j5vd1uISNhZ8Gjg6HCGEsBtJ9MCBM6m0if8JL7Ih6h5HhyOEEHYliR74blssY11XYwnoJFfDCiGcTo1P9Lk2zc6t6wlzOYp7t9sdHY4QQthdjU/06w6d5Zqs5diUO4Td4uhwhBDC7mp8ol+0NYab3Nah2/wFfPwdHY4QQthduRK9UmqYUmq/UuqQUmp6Cc8/qpTao5TaoZRaoZRqbv9Q7S81y0LWnmX4k4JrVynbCCGc0yUTvVLKFXgXuA7oAIxXSnUottofQKTWOhxYALxm70Arw087TzOSVVi8GkCrIY4ORwghKkV5RvRRwCGt9RGtdQ4wHxhVeAWt9UqtdUbew41AkH3DrBw/bd7FENc/cOs8Tq6EFUI4rfIk+kDgRKHHsXnLSjMZ+KmkJ5RS9yqlopVS0QkJCeWPshIcTkijxckluGNFdZng0FiEEKIy2fVkrFLqdiASeL2k57XWs7TWkVrryICAAHu+dIV9s+UYd7gtJ6dpd2jU0aGxCCFEZSpP98o4ILjQ46C8ZUUopYYAM4ABWuts+4RXOSy5Nk5F/48QdRp6/dPR4QghRKUqz4h+C9BaKRWqlPIAbgUWF15BKdUF+BAYqbWOt3+Y9vX7/gRutCwh2ysA2o90dDhCCFGpLpnotdZWYBqwDNgLfKO13q2UelEplZ8lXwd8gW+VUtuVUotL2V2V8NuGjVzj+iduUZPBzcPR4QghRKUq141HtNZLgaXFlj1b6OdqMzcxPjWLVjFfkevmimv3SY4ORwghKl2NuzL2x80HudnldzJa3QC1Gzs6HCGEqHQ16laCWZZcEtfNpY7KgP5THR2OEEJcFTUq0S9ZtY4pufM43yiSOkHdHR2OKIPFYiE2NpasrCxHhyKEQ3h5eREUFIS7+5VfzFljEn1WZjqd1v0NFxdXfG/7BJRydEiiDLGxsdSuXZuQkBCUfFaihtFak5iYSGxsLKGhoVe8vxpToz867yHacZTYAW9C3WaODkdcQlZWFv7+/pLkRY2klMLf399u32hrRKLP+fNb2sd+y48+Y2g3UHrOVxeS5EVNZs9//zWidJP26785ZWtOwxtfcXQoQghx1Tn9iD4nK4M6aYfZX6cXPVrJdEohRM3j9In+97WrccNG2859HB2KqEbOnTvHe++9Z9d9zpgxg+DgYHx9fe26X4BXXrk631YXL17Mq6++elnbhoSEcPbsWTtHJMrDqUs3NptmZ/QahgIduvR1dDjiMr3w4272nDxv1312aFqH524ovWtpfqJ/4IEH7PaaN9xwA9OmTaN169Z222e+V155haeeesru+y3MarUycuRIRo6s3v2hrFYrbm5Onfou4tQj+pX74/FP24/FzQdVL8TR4YhqZPr06Rw+fJjOnTvz2GOP8dhjj9GpUyfCwsL4+uuvAVi1ahX9+/dn+PDhtG3blilTpmCz2UrdZ8+ePWnSpEm5Xv/MmTPceOONREREEBERwfr16wEYPXo03bp1o2PHjsyaNasg1szMTDp37syECebeCl988QVRUVF07tyZ++67j9zcXABmz55NmzZtiIqK4p577mHatGkAxMTEMGjQIMLDwxk8eDDHjx8H4K677mLKlCn06NGDxx9/nLlz5xZsU5EYy6O07X7++We6du1KREQEgwcPBiAtLY1JkyYRFhZGeHg43333HUCRb0sLFizgrrvuKvE4Nm/eTK9evejSpQu9e/dm//79AOTm5vKPf/yDTp06ER4ezttvv81vv/3G6NGjC/b766+/cuONN5b7uKoErbVD/nTr1k1XtrHvr9d/Pt9d587+S6W/lrCvPXv2OPT1jx49qjt27Ki11nrBggV6yJAh2mq16tOnT+vg4GB98uRJvXLlSu3p6akPHz6srVarHjJkiP72228vuW8fH59LrnPLLbfoN998U2uttdVq1efOndNaa52YmKi11jojI0N37NhRnz179qJ97tmzR48YMULn5ORorbW+//779aeffqrj4uJ08+bNdWJios7JydF9+/bVU6dO1VprPWLECD137lyttdazZ8/Wo0aN0lprPXHiRD18+HBttVq11lp/8sknBdtUNMbmzZvrhISEUo+5pO3i4+N1UFCQPnLkSJF1Hn/8cf3QQw8VbJuUlHTR+/Dtt9/qiRMnlngcKSkp2mKxaK21/vXXX/VNN92ktdb6vffe02PGjCl4LjExUdtsNt22bVsdHx+vtdZ6/PjxevHixaUehz2V9P8AiNYVzLdO+/1l2/FktsScpb3PcVwaD3R0OKIaW7t2LePHj8fV1ZVGjRoxYMAAtmzZQp06dYiKiqJFixYAjB8/nrVr13LzzTdf8Wv+9ttvfPbZZwC4urri5+cHwFtvvcWiRYsAOHHiBAcPHsTf37/ItitWrGDr1q10726u/s7MzKRhw4Zs3ryZAQMGUL9+fQDGjh3LgQMHANiwYQMLFy4E4I477uDxxx8v2N/YsWNxdXW1a4wlKWm7hIQE+vfvX3DRUH7sy5cvZ/78+QXb1qtX75L7L3wcKSkpTJw4kYMHD6KUwmKxFOx3ypQpBaWd/Ne74447+OKLL5g0aRIbNmwoOO7qwmkT/azfjxDmlYh7biY0DnN0OMJJFZ/rXJlz/1etWsXy5cvZsGEDtWrVYuDAgSVeUKO1ZuLEifzrX/8qsvz777+/rNf18fGxe4z22q64wu9/8e0LH8czzzzDNddcw6JFi4iJiWHgwIFl7nfSpEnccMMNeHl5MXbs2GpX43fKGv2JpAyW7TnN5NZpZkGTcMcGJKqd2rVrk5qaCkC/fv34+uuvyc3NJSEhgdWrVxMVFQXA5s2bOXr0KDabja+//pq+fe1z0n/w4MG8//77gKkbp6SkkJKSQr169ahVqxb79u1j48aNBeu7u7sXjEoHDx7MggULiI839wBKSkri2LFjdO/end9//53k5GSsVmtBXRugd+/eBSPkefPm0a9fP7vHWJbStuvZsyerV6/m6NGjBccCMHToUN59992C7ZOTkwFo1KgRe/fuxWazFXw7KO31AgPNra/nzp1bsHzo0KF8+OGHWK3WIq/XtGlTmjZtyssvv8ykSdWvvblTJvrPNsTgohSD654GFzcIaOfokEQ14+/vT58+fejUqRMbNmwgPDyciIgIBg0axGuvvUbjxuaajO7duzNt2jTat29PaGhomSfpHn/8cYKCgsjIyCAoKIjnn3++1HVnzpzJypUrCQsLo1u3buzZs4dhw4ZhtVpp374906dPp2fPngXr33vvvYSHhzNhwgQ6dOjAyy+/zLXXXkt4eDhDhw7l1KlTBAYG8tRTTxEVFUWfPn0ICQkpKLe8/fbbfPLJJ4SHh/P5558zc+bMS75HFY2xLKVtFxAQwKxZs7jpppuIiIhg3LhxADz99NMkJyfTqVMnIiIiWLlyJQCvvvoqI0aMoHfv3mWe+H788cd58skn6dKlS0FSB/jrX/9Ks2bNCj7vL7/8suC5CRMmEBwcTPv27ct1TFWJMrX9qy8yMlJHR0fbfb8ZOVZ6vrKCfm0CeNf2T0g9A/evtfvriMq1d+/eKv8fatWqVbzxxhssWbLE0aGUW1paGr6+vlitVm688Ubuvvvu6jeDxEGmTZtGly5dmDx58lV7zZL+HyiltmqtIyuyH6cb0S/6I47zWVYm9Q6BUzukPi9EIc8//zydO3emU6dOhIaGFpk2KErXrVs3duzYwe233+7oUC5L9TqjUFxaAvzyNLi6gVddtE9DFm5qScemfnTzz4H0eKnPi0ozcODAEk/i9ejRg+zs7CLLPv/8c8LCLh50/POf/+Tbb78tsmzs2LHMmDHDrrHme+ONNyplv+WVmJhYMBe+sBUrVpRrZo6jbN261dEhXJHqnej3fA875oNvY8hKQVkzedLWhmPD56NO7zTryIheXGWbNm0q97ozZsyotKReFfn7+7N9+3ZHh1HjVLvSTZYll/WH8vplxKyFOoHw933w9Gk+bPgMkS4HGB37Gpz606wjiV4IUcNVu0T/9m8HuX32JuZtjIFj6yCkLyjFwm2x/PtEe9YG3YPrzvmw/m2o2xy8/BwdshBCOFS1S/RTr2nFgDYBzPnhF0hPwNasD//5ZT+PfvMnPUL9iZjwCnQaA1nnpD4vhBCUM9ErpYYppfYrpQ4ppaaX8Hx/pdQ2pZRVKXXl13+XoZaHGx/dGcnU0NMATFzpzlu/HeKWyCA+vTuK2t4eMOpdk+zDb63MUIQQolq4ZKJXSrkC7wLXAR2A8UqpDsVWOw7cBXzJVeDm6sKN9WNIc2/AuqQ6PDGsHf8eE46HW97huHvDzXOg/YirEY4QZfaYj4mJKXLhjb3cfffdNGzYkE6dOtl1v5XRi780H3zwwWX3jamMvv7OqjyzbqKAQ1rrIwBKqfnAKGBP/gpa65i850rv0WpPWqNi1uHbdiC7R16Ht8fFDZeEE/lpOuTPorKXxmFw3eXdQKOi8hP9bbfdZtf93nXXXUybNo0777zTrvutjF78JbFarUyZMqVSX+NqqA797ctTugkEThR6HJu3rMKUUvcqpaKVUtEJCQmXswsj6QiknYaQPpLkRaWYPn16kV4qzz//PC+//DKDBw+ma9euhIWF8cMPP5R7X2vWrKFz5868+eabZGVlFfRS79KlS8Hl+3PnzmXUqFEMHDiQ1q1b88ILL5S53/79+xd0V7yUQ4cOMWTIECIiIujatSuHDx8mLS2txOMp3osf4PXXX6d79+6Eh4fz3HPPFez3pZdeom3btvTt25fx48cXzNPfvn07PXv2JDw8nBtvvLGgF83AgQN5+OGHiYyMZObMmTz//PMF21Qkxkspa7vPPvusoMXBHXfcAZTcWz8mJqbIt6U33nijoG1F8eP48ccf6dGjB126dGHIkCGcOXOmII7iffPnzJnDww8/XLDfjz76iEceeaRcx3XZLtXHGLgZ+LjQ4zuAd0pZdy5wc3n6I19RP/rouVo/V0fr+P2Xvw9RpTm6H/22bdt0//79Cx63b99eHz9+XKekpGittU5ISNAtW7bUNptNa112j/mVK1fq4cOHFzx+44039KRJk7TWWu/du1cHBwfrzMxM/cknn+jGjRvrs2fPFvRk37JlS5lxFu6bX5aoqCi9cOFCrbXWmZmZOj09XVsslhKPp/g+ly1bpu+55x5ts9l0bm6uHj58uP7999/15s2bdUREhM7MzNTnz5/XrVq10q+//rrWWuuwsDC9atUqrbXWzzzzTEHv+AEDBuj777+/YN/PPfdcwTYViVHrst/z0rbbtWuXbt26dUFf/Pz+9iX11i/+Prz++uv6ueeeK/E4kpKSCuL66KOP9KOPPqq1Lrlvfmpqqm7RokXB/QJ69eqld+zYUeJxXM1+9HFAcKHHQXnLHCdmLfg0hAb2vyWbEABdunQhPj6ekydPkpCQQL169WjcuDGPPPIIq1evxsXFhbi4OM6cOVPQ4Ky81q5dy4MPPghAu3btaN68eUFf+KFDhxZcIXrTTTexdu1aIiMr1NbkIqmpqcTFxRX0tPHy8gLAYrHw1FNPXXQ8xf3yyy/88ssvdOnSBTCj1IMHD5KamsqoUaPw8vLCy8uLG264ATCdIc+dO8eAAQMAmDhxImPHji3YX35jsiuJ8VLvuda6xO1+++03xo4dS4MGDYAL/eZL6q2f/y2kNIWPIzY2lnHjxnHq1ClycnIK+ueX1jd/0KBBLFmyhPbt22OxWEq8atqeypPotwCtlVKhmAR/K2DfYmNFaJ03f74PVGLvbyHGjh3LggULOH36NOPGjWPevHkkJCSwdetW3N3dCQkJuaye6WW5mv3ty3s8WmuefPJJ7rvvviLL//vf/17W61akv/3lvuf2+Kzc3NyK3BqyrP72Dz74II8++igjR45k1apVZXYmBdMl85VXXqFdu3ZXpe3xJWv0WmsrMA1YBuwFvtFa71ZKvaiUGgmglOqulIoFxgIfKqV2V1rEyTFwPg6a96m0lxACzIht/vz5LFiwgLFjx5KSkkLDhg1xd3dn5cqVHDt2rFz7KdzbHkx/+3nz5gFw4MABjh8/Ttu2bQFzP9KkpCQyMzP5/vvv6dPnyv+d165dm6CgoIIbj2RnZ5ORkVHq8RSP9y9/+Qtz5swhLc3c3yEuLo74+Hj69OnDjz/+SFZWFmlpaQVdPP38/KhXrx5r1qwBTJ+f/NG9vWK8lNK2GzRoEN9++y2JiYnAhX7zJfXWb9SoEfHx8SQmJpKdnV1ml9LC/e0//fTTguWl9c3v0aMHJ06c4Msvv2T8+PHlOqYrUa559FrrpVrrNlrrllrrf+Yte1ZrvTjv5y1a6yCttY/W2l9r3bHSIj62zvwdYp8bPAhRmo4dO5KamkpgYCBNmjRhwoQJREdHExYWxmeffUa7duW7z0F4eDiurq5ERETw5ptv8sADD2Cz2QgLC2PcuHHMnTsXT09PAKKiohgzZgzh4eGMGTOmzLLN+PHj6dWrF/v37ycoKIjZs2eXuu7nn3/OW2+9RXh4OL179+b06dOlHk/hXvyPPfYY1157Lbfddhu9evUiLCyMm2++mdTUVLp3787IkSMJDw/nuuuuIywsrKC//aeffspjjz1GeHg427dv59lnn73k+1SRGC+ltO06duzIjBkzGDBgABERETz66KNAyb313d3defbZZ4mKimLo0KFlvvbzzz/P2LFj6datW0FZCErvmw9wyy230KdPn3LdBvGKVbSob68/l30ydu//tP7qNq3zTnwI5+Tok7GOUPjG29VFamqq1lrr9PR03a1bN71161YHR1R9DB8+XC9fvrzMdWruzcHbXW/+CCEc7t5772XPnj1kZWUxceJEunbt6uiQqrxz584RFRVFREREiS2bK4PT3WFKOIfqcIep4nbu3FkwLzufp6dnhdoWF1fR/u1Tp05l3bp1RZY99NBD1fI+p+VRGe95VWKvO0xJohdV0t69e2nXrl2lzjoRoirTWrNv3z65laBwXl5eXiQmJuKogYgQjqS1JjExseB6gitV/Wr0okYICgoiNjaWK2qVIUQ15uXlRVBQkF32JYleVEnu7u4FVxcKIa6MlG6EEMLJSaIXQggnJ4leCCGcnMOmVyqlEoDyNa64WAPgrB3DqW5q8vHX5GOHmn38cuxGc611QEU2dliivxJKqeiKziN1JjX5+GvysUPNPn459ss/dindCCGEk5NEL4QQTq66JvpZjg7AwWry8dfkY4eaffxy7JepWtbohRBClF91HdELIYQoJ0n0Qgjh5KpdoldKDVNK7VdKHVJKTXd0PJVJKRWslFqplNqjlNqtlHoob3l9pdSvSqmDeX9fhXuROYZSylUp9YdSakne41Cl1Ka8z/9rpZSHo2OsLEqpukqpBUqpfUqpvUqpXjXls1dKPZL3b36XUuorpZSXM3/2Sqk5Sql4pdSuQstK/KyV8Vbe+7BDKXXJu71Uq0SvlHIF3gWuAzoA45VSHRwbVaWyAn/XWncAegJT8453OrBCa90aWJH32Fk9hLkpfb5/A29qrVsBycBkh0R1dcwEftZatwMiMO+D03/2SqlA4G9ApNa6E+AK3Ipzf/ZzgWHFlpX2WV8HtM77cy/w/qV2Xq0SPRAFHNJaH9Fa5wDzgVEOjqnSaK1Paa235f2civmPHog55vxbzX8KjHZIgJVMKRUEDAc+znusgEHAgrxVnPnY/YD+wGwArXWO1vocNeSzx3TW9VZKuQG1gFM48WevtV4NJBVbXNpnPQr4LO8WshuBukqpJmXtv7ol+kDgRKHHsXnLnJ5SKgToAmwCGmmtT+U9dRpo5Ki4Ktl/gccBW95jf+Cc1tqa99iZP/9QIAH4JK909bFSyoca8NlrreOAN4DjmASfAmyl5nz2+Ur7rCucB6tboq+RlFK+wHfAw1rr84Wfy7srvNPNkVVKjQDitdZbHR2Lg7gBXYH3tdZdgHSKlWmc+LOvhxm1hgJNAR8uLmvUKFf6WVe3RB8HBBd6HJS3zGkppdwxSX6e1nph3uIz+V/V8v6Od1R8lagPMFIpFYMp0Q3C1Kzr5n2dB+f+/GOBWK11/l2uF2ASf0347IcAR7XWCVprC7AQ8++hpnz2+Ur7rCucB6tbot8CtM47++6BOUGz2MExVZq8mvRsYK/W+j+FnloMTMz7eSLww9WOrbJprZ/UWgdprUMwn/NvWusJwErg5rzVnPLYAbTWp4ETSqm2eYsGA3uoAZ89pmTTUylVK+//QP6x14jPvpDSPuvFwJ15s296AimFSjwl01pXqz/A9cAB4DAww9HxVPKx9sV8XdsBbM/7cz2mVr0COAgsB+o7OtZKfh8GAkvyfm4BbAYOAd8Cno6OrxKPuzMQnff5fw/UqymfPfACsA/YBXwOeDrzZw98hTkfYcF8m5tc2mcNKMzsw8PATszspDL3Ly0QhBDCyVW30o0QQogKkkQvhBBOThK9EEI4OUn0Qgjh5CTRCyGEk5NEL4QQTk4SvRBCOLn/B09Ykl39Py5qAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hy[['top_1_categorical_accuracy','val_top_1_categorical_accuracy']].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3b0e3a",
   "metadata": {},
   "source": [
    "# A little better, but still was not a great run. Things to try:\n",
    "1. Continue optimizing transformer_layers. \n",
    "2. First try bnorm in the main block of Dense layers. The diminishing gradient over epochs may be a sign of internal covariate shift.\n",
    "3. Try a less complex model:\n",
    "    1. Try fewer layers per block \n",
    "    2. Smaller layers in blocks\n",
    "    3. Less Dense units on residual bypass\n",
    "4. Optimize learning rate \n",
    "5. Start with a suitable pre-trained vision transformer as a base model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fbada6de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "top_1_categorical_accuracy        0.706571\n",
       "val_top_1_categorical_accuracy    0.577333\n",
       "dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hy[['top_1_categorical_accuracy','val_top_1_categorical_accuracy']].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5aa08628",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as dense_layer_call_fn, dense_layer_call_and_return_conditional_losses, embedding_layer_call_fn, embedding_layer_call_and_return_conditional_losses, query_layer_call_fn while saving (showing 5 of 160). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 2022-01-15_20_44_exported_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 2022-01-15_20_44_exported_model/assets\n",
      "/usr/local/lib/python3.8/dist-packages/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    }
   ],
   "source": [
    "model_name = f\"{date}_exported_model\"\n",
    "final_residual_mlp.save(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91faad58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a quick test for Flatten = True:\n",
    "test_flatten_res_mlp = ResidualMLP(problem_type = 'classification', #\n",
    "                      learning_rate = .0007, #\n",
    "                      input_shape = (32, 32, 3), #(32,32,3), #\n",
    "                      bw_images = False, #\n",
    "                      base_model = '',\n",
    "                      base_model_input_shape = (32, 32, 3),  # (600,600,3), #\n",
    "                      flatten_after_base_model = True, #\n",
    "                      blocks = [[7, 75, 8], [5, 75, 10]], #\n",
    "                      residual_bypass_dense_layers = [[5],[5]], #\n",
    "                      b_norm_or_dropout_residual_bypass_layers = 'dropout', #\n",
    "                      dropout_rate_for_bypass_layers = .7, #\n",
    "                      inter_block_layers_per_block = [10],\n",
    "                      b_norm_or_dropout_last_layers = 'dropout', # | 'bnorm'\n",
    "                      dropout_rate = .18, #\n",
    "                      activation = tf.keras.activations.relu, #\n",
    "                      final_dense_layers = [15], #\n",
    "                      number_of_classes = 10, # 1 if a regression problem\n",
    "                      # final_activation = tf.keras.activations.softmax, #\n",
    "                      #loss = tf.keras.losses.CategoricalCrossentropy(\n",
    "                      #    from_logits=False)\n",
    "                     )\n",
    "test_flatten_model = test_flatten_res_mlp.make_tandem_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "073702dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "resizing_6 (Resizing)           (None, 32, 32, 3)    0           input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model (Functional)              (None, 1600)         424711      resizing_6[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_106 (Dense)               (None, 75)           120075      model[5][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 75)           300         dense_106[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_108 (Dense)               (None, 75)           5700        batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 75)           300         dense_108[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_109 (Dense)               (None, 67)           5092        batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 67)           268         dense_109[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_110 (Dense)               (None, 59)           4012        batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 59)           236         dense_110[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_111 (Dense)               (None, 51)           3060        batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 51)           204         dense_111[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_112 (Dense)               (None, 43)           2236        batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 43)           172         dense_112[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_113 (Dense)               (None, 35)           1540        batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 35)           140         dense_113[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_35 (Dropout)            (None, 75)           0           dense_106[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_114 (Dense)               (None, 27)           972         batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_107 (Dense)               (None, 5)            380         dropout_35[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 27)           108         dense_114[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_36 (Dropout)            (None, 5)            0           dense_107[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 32)           0           batch_normalization_82[0][0]     \n",
      "                                                                 dropout_36[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_115 (Dense)               (None, 10)           330         concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 10)           40          dense_115[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_116 (Dense)               (None, 75)           825         batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 75)           300         dense_116[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_118 (Dense)               (None, 75)           5700        batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 75)           300         dense_118[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_119 (Dense)               (None, 65)           4940        batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 65)           260         dense_119[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_120 (Dense)               (None, 55)           3630        batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 55)           220         dense_120[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_121 (Dense)               (None, 45)           2520        batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 45)           180         dense_121[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)            (None, 75)           0           dense_116[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_122 (Dense)               (None, 35)           1610        batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_117 (Dense)               (None, 5)            380         dropout_37[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 35)           140         dense_122[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_38 (Dropout)            (None, 5)            0           dense_117[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 40)           0           batch_normalization_89[0][0]     \n",
      "                                                                 dropout_38[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_123 (Dense)               (None, 15)           615         concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_39 (Dropout)            (None, 15)           0           dense_123[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_124 (Dense)               (None, 10)           160         dropout_39[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 591,656\n",
      "Trainable params: 590,065\n",
      "Non-trainable params: 1,591\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "test_flatten_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e17984b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
