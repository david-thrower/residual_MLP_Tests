{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c264891b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-1.4.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.7 MB 10.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.8/dist-packages (from pandas) (1.19.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.8/dist-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.8.1->pandas) (1.15.0)\n",
      "Installing collected packages: pandas\n",
      "Successfully installed pandas-1.4.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 22.0.3 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting pendulum\n",
      "  Downloading pendulum-2.1.2-cp38-cp38-manylinux1_x86_64.whl (155 kB)\n",
      "\u001b[K     |████████████████████████████████| 155 kB 28.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil<3.0,>=2.6 in /usr/local/lib/python3.8/dist-packages (from pendulum) (2.8.2)\n",
      "Collecting pytzdata>=2020.1\n",
      "  Downloading pytzdata-2020.1-py2.py3-none-any.whl (489 kB)\n",
      "\u001b[K     |████████████████████████████████| 489 kB 39.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil<3.0,>=2.6->pendulum) (1.15.0)\n",
      "Installing collected packages: pytzdata, pendulum\n",
      "Successfully installed pendulum-2.1.2 pytzdata-2020.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 22.0.3 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting keras_tuner\n",
      "  Downloading keras_tuner-1.1.0-py3-none-any.whl (98 kB)\n",
      "\u001b[K     |████████████████████████████████| 98 kB 8.3 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: ipython in /usr/local/lib/python3.8/dist-packages (from keras_tuner) (7.27.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from keras_tuner) (21.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from keras_tuner) (2.26.0)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from keras_tuner) (1.4.1)\n",
      "Collecting kt-legacy\n",
      "  Downloading kt_legacy-1.0.4-py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from keras_tuner) (1.19.4)\n",
      "Requirement already satisfied: tensorboard in /usr/local/lib/python3.8/dist-packages (from keras_tuner) (2.6.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.8/dist-packages (from ipython->keras_tuner) (4.7.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from ipython->keras_tuner) (3.0.20)\n",
      "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.8/dist-packages (from ipython->keras_tuner) (5.1.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.8/dist-packages (from ipython->keras_tuner) (0.18.0)\n",
      "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.8/dist-packages (from ipython->keras_tuner) (0.1.3)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from ipython->keras_tuner) (5.1.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.8/dist-packages (from ipython->keras_tuner) (58.1.0)\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.8/dist-packages (from ipython->keras_tuner) (2.10.0)\n",
      "Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from ipython->keras_tuner) (0.2.0)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from ipython->keras_tuner) (0.7.5)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.16->ipython->keras_tuner) (0.8.2)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.8/dist-packages (from pexpect>4.3->ipython->keras_tuner) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->keras_tuner) (0.2.5)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->keras_tuner) (2.4.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->keras_tuner) (2021.5.30)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->keras_tuner) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->keras_tuner) (3.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.8/dist-packages (from requests->keras_tuner) (2.0.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard->keras_tuner) (0.6.1)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard->keras_tuner) (3.17.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard->keras_tuner) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard->keras_tuner) (3.3.4)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.8/dist-packages (from tensorboard->keras_tuner) (0.37.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.8/dist-packages (from tensorboard->keras_tuner) (0.12.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard->keras_tuner) (1.8.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.8/dist-packages (from tensorboard->keras_tuner) (2.0.1)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard->keras_tuner) (1.39.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard->keras_tuner) (1.35.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from absl-py>=0.4->tensorboard->keras_tuner) (1.15.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<2,>=1.6.3->tensorboard->keras_tuner) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<2,>=1.6.3->tensorboard->keras_tuner) (4.7.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<2,>=1.6.3->tensorboard->keras_tuner) (4.2.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras_tuner) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard->keras_tuner) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras_tuner) (3.1.1)\n",
      "Installing collected packages: kt-legacy, keras-tuner\n",
      "Successfully installed keras-tuner-1.1.0 kt-legacy-1.0.4\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 22.0.3 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pandas\n",
    "!pip3 install pendulum\n",
    "!pip3 install keras_tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fac14ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ff71cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 12s 0us/step\n",
      "170508288/170498071 [==============================] - 12s 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-18 05:02:16.371637: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-18 05:02:16.516974: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-18 05:02:16.517673: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-18 05:02:16.520417: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-18 05:02:16.521077: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-18 05:02:16.521622: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-18 05:02:18.437046: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-18 05:02:18.437698: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-18 05:02:18.438232: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-18 05:02:18.439188: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14029 MB memory:  -> device: 0, name: RTX A4000, pci bus id: 0000:00:05.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb7.h5\n",
      "268328960/268326632 [==============================] - 11s 0us/step\n",
      "268337152/268326632 [==============================] - 11s 0us/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "BASE_MODEL_INPUT_SHAPE = (600,600,3)\n",
    "\n",
    "cifar = tf.keras.datasets.cifar10.load_data()\n",
    "(x_train, y_train), (x_test, y_test) = cifar\n",
    "\n",
    "\n",
    "mod_with_fc_raw = tf.keras.applications.efficientnet.EfficientNetB7(\n",
    "    include_top=True, weights='imagenet', input_tensor=None,\n",
    "    input_shape = BASE_MODEL_INPUT_SHAPE, pooling='max', classes=1000\n",
    ")\n",
    "\n",
    "# Make the deepest conv2d layer trainable, leave everything else\n",
    "# as not trainable\n",
    "for layer in mod_with_fc_raw.layers:\n",
    "    layer.trainable = False\n",
    "# Last conv2d layer. This we want to train .\n",
    "mod_with_fc_raw.layers[-6].trainable = True\n",
    "\n",
    "# Create the final base model\n",
    "# (remove the final Dense and BatchNormalization layers ...) \n",
    "efficient_net_b_7_transferable_base_model =\\\n",
    "    tf.keras.Model(inputs=mod_with_fc_raw.layers[0].input, \n",
    "                    outputs=mod_with_fc_raw.layers[-3].output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e2fefe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_SET_SIZE = 1000\n",
    "\n",
    "y_train_ohe = tf.one_hot([i[0] for i in  y_train],10)\n",
    "indexes_for_rows = tf.range(0,y_train.shape[0])\n",
    "shuffled_indexes = tf.random.shuffle(indexes_for_rows)\n",
    "selected_indexes = shuffled_indexes[:TRAINING_SET_SIZE]\n",
    "selected_x_train = x_train[selected_indexes,:,:,:]\n",
    "selected_y_train_ohe = y_train_ohe.numpy()[selected_indexes,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80d43ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from residualmlp.residual_mlp import ResidualMLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad584cf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FullArgSpec(args=['self', 'problem_type', 'learning_rate', 'minimum_learning_rate', 'maximum_learning_rate', 'number_of_learning_rates_to_try', 'input_shape', 'bw_images', 'base_model', 'base_model_input_shape', 'base_model_hyperparameters', 'flatten_after_base_model', 'blocks', 'minimum_number_of_blocks', 'maximum_number_of_blocks', 'minimum_number_of_layers_per_block', 'maximum_number_of_layers_per_block', 'minimum_neurons_per_block_layer', 'maximum_neurons_per_block_layer', 'n_options_of_neurons_per_layer_to_try', 'minimum_neurons_per_block_layer_decay', 'maximum_neurons_per_block_layer_decay', 'residual_bypass_dense_layers', 'b_norm_or_dropout_residual_bypass_layers', 'dropout_rate_for_bypass_layers', 'minimum_dropout_rate_for_bypass_layers', 'maximim_dropout_rate_for_bypass_layers', 'n_options_dropout_rate_for_bypass_layers', 'inter_block_layers_per_block', 'minimum_inter_block_layers_per_block', 'maximum_inter_block_layers_per_block', 'n_options_inter_block_layers_per_block', 'b_norm_or_dropout_last_layers', 'dropout_rate', 'minimum_dropout_rate', 'maximum_dropout_rate', 'n_options_dropout_rate', 'activation', 'final_dense_layers', 'minimum_final_dense_layers', 'maximum_final_dense_layers', 'n_options_final_dense_layers', 'number_of_classes', 'final_activation', 'loss'], varargs=None, varkw=None, defaults=('classification', 0.0007, 7e-05, 0.7, 5, (32, 32, 3), False, '', (600, 600, 3), {}, True, [[5, 400, 50]], 1, 7, 1, 7, 3, 30, 7, 1, 7, [], 'dropout', 0.35, 0.01, 0.7, 7, [], 3, 30, 7, 'dropout', 0.2, 0.01, 0.7, 7, <function relu at 0x7f3f44435ca0>, [75, 35], 0, 30, 2, 10, <function softmax at 0x7f3f651e0430>, <keras.losses.CategoricalCrossentropy object at 0x7f3fec2951c0>), kwonlyargs=[], kwonlydefaults=None, annotations={})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from inspect import getfullargspec\n",
    "getfullargspec(ResidualMLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fea060dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 200), dtype=float32, numpy=\n",
       "array([[0.        , 0.20556308, 0.10319729, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.23095171, 0.        , 0.20087379,\n",
       "        0.22799511, 0.        , 0.        , 0.        , 0.11601258,\n",
       "        0.        , 0.        , 0.12606584, 0.15618055, 0.        ,\n",
       "        0.08006047, 0.        , 0.        , 0.        , 0.04185324,\n",
       "        0.        , 0.06248565, 0.24495897, 0.1633819 , 0.18569756,\n",
       "        0.09699996, 0.16946535, 0.28391987, 0.        , 0.05864558,\n",
       "        0.10620824, 0.        , 0.0805537 , 0.        , 0.24124733,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.03514363,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.18335459,\n",
       "        0.28679764, 0.26123786, 0.        , 0.1726978 , 0.38940158,\n",
       "        0.08559008, 0.15339065, 0.0581256 , 0.09198355, 0.32420203,\n",
       "        0.        , 0.15500632, 0.        , 0.41381875, 0.13975704,\n",
       "        0.26075855, 0.        , 0.18362373, 0.        , 0.5047065 ,\n",
       "        0.49857372, 0.        , 0.        , 0.08606067, 0.        ,\n",
       "        0.        , 0.        , 0.08253267, 0.        , 0.07296568,\n",
       "        0.        , 0.        , 0.20220551, 0.        , 0.24736576,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.06656472,\n",
       "        0.        , 0.0969515 , 0.        , 0.16622216, 0.00692164,\n",
       "        0.5610864 , 0.24157473, 0.5990472 , 0.        , 0.34556958,\n",
       "        0.31452236, 0.15323894, 0.        , 0.0749166 , 0.        ,\n",
       "        0.        , 0.0843992 , 0.        , 0.04635039, 0.5112548 ,\n",
       "        0.        , 0.530963  , 0.        , 0.11322676, 0.        ,\n",
       "        0.        , 0.        , 0.13671453, 0.6547575 , 0.        ,\n",
       "        0.06270687, 0.15966925, 0.06778772, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.3318339 , 0.14146307, 0.        ,\n",
       "        0.        , 0.08126612, 0.015574  , 0.        , 0.        ,\n",
       "        0.        , 0.5813007 , 0.        , 0.        , 0.35321227,\n",
       "        0.09341977, 0.35953894, 0.13495964, 0.2988643 , 0.        ,\n",
       "        0.43378907, 0.27165088, 0.49119118, 0.34966478, 0.        ,\n",
       "        0.        , 0.        , 0.2611553 , 0.14136943, 0.1528048 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.20490472, 0.        ,\n",
       "        0.09218726, 0.        , 0.03931253, 0.        , 0.0851225 ,\n",
       "        0.        , 0.61999124, 0.        , 0.74774504, 0.        ,\n",
       "        0.        , 0.26326132, 0.09437995, 0.        , 0.7881851 ,\n",
       "        0.        , 0.        , 0.        , 0.5081482 , 0.        ,\n",
       "        0.879796  , 0.27830338, 0.02926144, 0.2191946 , 0.31620523,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.19541946, 0.17610031, 0.        , 0.05966584, 0.        ],\n",
       "       [0.06175916, 0.11909151, 0.        , 0.05762853, 0.08302382,\n",
       "        0.        , 0.06593381, 0.12291935, 0.        , 0.        ,\n",
       "        0.2059981 , 0.        , 0.        , 0.        , 0.04302969,\n",
       "        0.        , 0.01675676, 0.313177  , 0.3963876 , 0.06127135,\n",
       "        0.04657683, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.13457245, 0.08528296, 0.08810905, 0.        ,\n",
       "        0.        , 0.        , 0.018718  , 0.        , 0.19233339,\n",
       "        0.32610545, 0.        , 0.        , 0.05552795, 0.        ,\n",
       "        0.        , 0.12121218, 0.        , 0.        , 0.22986214,\n",
       "        0.        , 0.        , 0.        , 0.05539731, 0.06595838,\n",
       "        0.        , 0.        , 0.12195691, 0.        , 0.15390629,\n",
       "        0.        , 0.18699375, 0.40565896, 0.25674617, 0.01408368,\n",
       "        0.27111387, 0.        , 0.        , 0.04010397, 0.        ,\n",
       "        0.13472345, 0.        , 0.        , 0.02771867, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.07169208, 0.28336936,\n",
       "        0.        , 0.        , 0.42902604, 0.        , 0.        ,\n",
       "        0.18861306, 0.        , 0.07427016, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.10433814, 0.        , 0.30730236,\n",
       "        0.01580818, 0.        , 0.01770685, 0.        , 0.        ,\n",
       "        0.18836075, 0.06989472, 0.34303063, 0.        , 0.12296404,\n",
       "        0.14331362, 0.3295924 , 0.        , 0.1217092 , 0.        ,\n",
       "        0.        , 0.06897946, 0.        , 0.01134276, 0.        ,\n",
       "        0.        , 0.24872436, 0.        , 0.        , 0.02441547,\n",
       "        0.2523175 , 0.        , 0.        , 0.33911687, 0.        ,\n",
       "        0.17962806, 0.17891514, 0.15419903, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.30162057, 0.07353779, 0.        ,\n",
       "        0.41297507, 0.        , 0.20676282, 0.        , 0.        ,\n",
       "        0.        , 0.09013697, 0.        , 0.        , 0.21114442,\n",
       "        0.15578258, 0.2521847 , 0.        , 0.24972397, 0.        ,\n",
       "        0.73901224, 0.3555221 , 0.35197532, 0.38779867, 0.        ,\n",
       "        0.        , 0.        , 1.0455953 , 0.72395116, 0.49167565,\n",
       "        0.        , 0.5071149 , 0.        , 0.07018232, 0.        ,\n",
       "        0.22144842, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.16030699, 0.        , 0.00759919, 0.5022981 , 0.03989495,\n",
       "        0.        , 0.10845394, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.7811477 , 0.48968118, 0.21233621, 0.8155242 ,\n",
       "        0.43945444, 0.        , 0.        , 0.10507621, 0.        ,\n",
       "        0.8198262 , 0.23000586, 0.        , 0.41648716, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.29737118,\n",
       "        0.        , 0.21536249, 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.13891283, 0.        , 0.37012967, 0.09803302,\n",
       "        0.        , 0.20738587, 0.        , 0.        , 0.        ,\n",
       "        0.3614064 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.07705804, 0.23461966, 0.00557619, 0.10167155,\n",
       "        0.4163312 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.25794268, 0.3542912 , 0.36154628, 0.        ,\n",
       "        0.        , 0.        , 0.0155826 , 0.        , 0.        ,\n",
       "        0.5587105 , 0.        , 0.        , 0.        , 0.05379827,\n",
       "        0.        , 0.08499226, 0.        , 0.        , 0.27941948,\n",
       "        0.07831234, 0.        , 0.        , 0.16323999, 0.        ,\n",
       "        0.        , 0.23735937, 0.        , 0.11606978, 0.        ,\n",
       "        0.05891773, 0.26711753, 0.        , 0.        , 0.0464048 ,\n",
       "        0.40692005, 0.        , 0.        , 0.04359858, 0.        ,\n",
       "        0.13416374, 0.07104892, 0.32759076, 0.        , 0.04689636,\n",
       "        0.        , 0.        , 0.        , 0.21959162, 0.16344745,\n",
       "        0.        , 0.        , 0.23805101, 0.        , 0.        ,\n",
       "        0.07478428, 0.        , 0.19439337, 0.        , 0.        ,\n",
       "        0.86020917, 0.        , 0.        , 0.25731212, 0.49312422,\n",
       "        0.        , 0.09652166, 0.01780976, 0.27749377, 0.5529211 ,\n",
       "        0.4216692 , 0.        , 0.11773926, 0.07547633, 0.06770518,\n",
       "        0.13055772, 0.22788224, 0.        , 0.23784019, 0.        ,\n",
       "        0.18707033, 0.07706214, 0.        , 0.08850662, 0.5853759 ,\n",
       "        0.        , 0.2813982 , 0.        , 0.07599912, 0.        ,\n",
       "        0.11086865, 0.        , 0.182616  , 0.7119921 , 0.07336   ,\n",
       "        0.06473658, 0.2860774 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.401251  , 0.        , 0.        ,\n",
       "        0.        , 0.12208545, 0.2678293 , 0.18426019, 0.        ,\n",
       "        0.        , 0.5021679 , 0.        , 0.        , 0.18143032,\n",
       "        0.05082843, 0.45022246, 0.        , 0.33642596, 0.        ,\n",
       "        0.5119395 , 0.09007131, 0.49490678, 0.5071165 , 0.        ,\n",
       "        0.        , 0.        , 0.5571523 , 0.        , 0.        ,\n",
       "        0.        , 0.17149052, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.20031539, 0.01401347, 0.        ,\n",
       "        0.32293582, 0.        , 0.25435004, 0.        , 0.        ,\n",
       "        0.        , 0.644524  , 0.        , 0.35370263, 0.        ,\n",
       "        0.08100648, 0.17830756, 0.4336034 , 0.04987231, 0.8759063 ,\n",
       "        0.        , 0.        , 0.        , 0.61962   , 0.        ,\n",
       "        1.071468  , 0.5387805 , 0.        , 0.        , 0.44754392,\n",
       "        0.        , 0.19204418, 0.        , 0.        , 0.3555581 ,\n",
       "        0.        , 0.44782597, 0.        , 0.1355077 , 0.        ],\n",
       "       [0.        , 0.0166043 , 0.03400589, 0.        , 0.05796429,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.15088786,\n",
       "        0.2312984 , 0.        , 0.        , 0.03504591, 0.19223318,\n",
       "        0.        , 0.12002073, 0.30686373, 0.37352917, 0.07676047,\n",
       "        0.        , 0.        , 0.02559854, 0.        , 0.        ,\n",
       "        0.10584754, 0.        , 0.2203229 , 0.0905917 , 0.        ,\n",
       "        0.05889038, 0.02400129, 0.10291954, 0.        , 0.        ,\n",
       "        0.03515227, 0.        , 0.02471882, 0.        , 0.        ,\n",
       "        0.        , 0.08307229, 0.16636615, 0.14790079, 0.03026539,\n",
       "        0.        , 0.        , 0.        , 0.03303171, 0.        ,\n",
       "        0.        , 0.10424723, 0.        , 0.        , 0.09654186,\n",
       "        0.2918127 , 0.40140757, 0.3978375 , 0.4062856 , 0.16584498,\n",
       "        0.        , 0.        , 0.11088453, 0.00568903, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.15064883,\n",
       "        0.6579424 , 0.        , 0.36318126, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.03065595, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.02278683, 0.        , 0.36683577,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.15548527, 0.        , 0.01451216, 0.        ,\n",
       "        0.3989862 , 0.        , 0.3680911 , 0.        , 0.        ,\n",
       "        0.13937044, 0.        , 0.1898283 , 0.09672175, 0.        ,\n",
       "        0.09639471, 0.        , 0.        , 0.19199693, 0.23881584,\n",
       "        0.        , 0.2522266 , 0.        , 0.07760008, 0.        ,\n",
       "        0.        , 0.        , 0.12148304, 0.67002606, 0.11129366,\n",
       "        0.06923601, 0.36253387, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.4358057 , 0.1593743 , 0.        ,\n",
       "        0.        , 0.        , 0.3110181 , 0.19151707, 0.        ,\n",
       "        0.        , 0.6316705 , 0.        , 0.        , 0.22078143,\n",
       "        0.01914478, 0.543836  , 0.10652642, 0.10994381, 0.        ,\n",
       "        0.53328586, 0.06393203, 0.61112094, 0.30895534, 0.        ,\n",
       "        0.        , 0.        , 0.48675692, 0.13717942, 0.38258326,\n",
       "        0.        , 0.27865666, 0.        , 0.        , 0.        ,\n",
       "        0.32776555, 0.10547671, 0.27524745, 0.20267232, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.1946225 ,\n",
       "        0.        , 0.5827693 , 0.        , 0.15765002, 0.        ,\n",
       "        0.21922928, 0.20319   , 0.01911649, 0.26219538, 0.56592184,\n",
       "        0.        , 0.        , 0.        , 0.5051348 , 0.        ,\n",
       "        1.0505565 , 0.5582027 , 0.        , 0.        , 0.33298236,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.40519103,\n",
       "        0.        , 0.6212988 , 0.        , 0.        , 0.        ],\n",
       "       [0.30460417, 0.1396837 , 0.        , 0.07911557, 0.        ,\n",
       "        0.        , 0.09630351, 0.21417154, 0.        , 0.03411226,\n",
       "        0.20306513, 0.        , 0.        , 0.        , 0.12397383,\n",
       "        0.        , 0.        , 0.23121408, 0.29773653, 0.06336125,\n",
       "        0.21275896, 0.0776569 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.1330166 , 0.19287914, 0.2788971 , 0.        ,\n",
       "        0.        , 0.        , 0.14160061, 0.        , 0.14512861,\n",
       "        0.33632082, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.04393505, 0.        , 0.        , 0.11592998,\n",
       "        0.        , 0.08114402, 0.        , 0.02190673, 0.14819118,\n",
       "        0.        , 0.15214233, 0.        , 0.27224082, 0.39460853,\n",
       "        0.        , 0.        , 0.28650317, 0.367021  , 0.        ,\n",
       "        0.13400641, 0.        , 0.        , 0.17758283, 0.        ,\n",
       "        0.08790116, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.12865525, 0.19444345, 0.34606102,\n",
       "        0.        , 0.        , 0.4495705 , 0.08161788, 0.        ,\n",
       "        0.05956655, 0.        , 0.10512556, 0.        , 0.        ,\n",
       "        0.05877005, 0.        , 0.17138824, 0.08381747, 0.4449604 ,\n",
       "        0.        , 0.        , 0.        , 0.35884774, 0.        ,\n",
       "        0.3186031 , 0.13256988, 0.47657138, 0.25398892, 0.19620761,\n",
       "        0.23304711, 0.        , 0.37868443, 0.08093816, 0.19533965,\n",
       "        0.        , 0.        , 0.        , 0.16755381, 0.37316322,\n",
       "        0.        , 0.14247699, 0.        , 0.        , 0.        ,\n",
       "        0.04021148, 0.        , 0.29084632, 0.7139655 , 0.07044666,\n",
       "        0.        , 0.03210248, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.25810233, 0.0251046 , 0.        ,\n",
       "        0.08491039, 0.        , 0.17377603, 0.        , 0.10425416,\n",
       "        0.10945234, 0.67870474, 0.        , 0.        , 0.66649467,\n",
       "        0.        , 0.31236416, 0.35476667, 0.30130333, 0.        ,\n",
       "        0.7069461 , 0.2386593 , 0.47590992, 0.12673523, 0.        ,\n",
       "        0.        , 0.        , 0.8835529 , 0.47582352, 0.70019686,\n",
       "        0.        , 0.23015592, 0.        , 0.        , 0.        ,\n",
       "        0.442653  , 0.49580294, 0.10816516, 0.29854718, 0.        ,\n",
       "        0.        , 0.        , 0.40457267, 0.        , 0.        ,\n",
       "        0.        , 0.25411218, 0.        , 0.16714454, 0.        ,\n",
       "        0.28860873, 0.        , 0.09623601, 0.        , 0.37808865,\n",
       "        0.51549387, 0.        , 0.        , 0.5565267 , 0.        ,\n",
       "        0.8998062 , 0.19837666, 0.        , 0.        , 0.63373953,\n",
       "        0.        , 0.        , 0.0413368 , 0.        , 0.3667003 ,\n",
       "        0.        , 0.3726885 , 0.        , 0.        , 0.19490117]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [batch, timesteps, feature]\n",
    "\n",
    "BATCH = 5\n",
    "STEPS = 20\n",
    "NEURONS_GRU_MLP = 50\n",
    "NEURONS_EFF_MLP = 50\n",
    "\n",
    "inp = tf.keras.layers.Input(shape=(32,32,3))\n",
    "x = tf.keras.layers.Resizing(600,600)(inp)\n",
    "y = inp\n",
    "\n",
    "x = efficient_net_b_7_transferable_base_model(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dense(NEURONS_EFF_MLP,\n",
    "                        activation=tf.keras.activations.relu, \n",
    "                        kernel_initializer=tf.keras.initializers.GlorotNormal)(x)\n",
    "x_residual = x\n",
    "\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dense(NEURONS_EFF_MLP,\n",
    "                        activation=tf.keras.activations.relu, \n",
    "                        kernel_initializer=tf.keras.initializers.GlorotNormal)(x)\n",
    "x = tf.keras.layers.Concatenate(axis=1)([x,x_residual])\n",
    "\n",
    "y_ch0 = y[:,:,:,0] # tf.keras.layers.Flatten()\n",
    "y_ch1 = y[:,:,:,1] # tf.keras.layers.Flatten()(\n",
    "y_ch2 = y[:,:,:,2] # tf.keras.layers.Flatten()()\n",
    "\n",
    "y_ch0, y_ch0_state  = tf.keras.layers.GRU(32,input_shape=(None,32,32),return_sequences=True, return_state=True)(y_ch0)\n",
    "y_ch1, y_ch1_state  = tf.keras.layers.GRU(32,input_shape=(None,32,32),return_sequences=True, return_state=True)(y_ch1)\n",
    "y_ch2, y_ch2_state  = tf.keras.layers.GRU(32,input_shape=(None,32,32),return_sequences=True, return_state=True)(y_ch2)\n",
    "\n",
    "y_ch0 = tf.keras.layers.GRU(32,input_shape=(None,32,32))([y_ch0,y_ch0_state])\n",
    "y_ch1 = tf.keras.layers.GRU(32,input_shape=(None,32,32))([y_ch1,y_ch1_state])\n",
    "y_ch2 = tf.keras.layers.GRU(32,input_shape=(None,32,32))([y_ch2,y_ch2_state])\n",
    "\n",
    "y = tf.keras.layers.Concatenate(axis=1)([y_ch0,y_ch1,y_ch2])\n",
    "\n",
    "y = tf.keras.layers.BatchNormalization()(y)\n",
    "y = tf.keras.layers.Dense(NEURONS_GRU_MLP,\n",
    "                        activation=tf.keras.activations.relu, \n",
    "                        kernel_initializer=tf.keras.initializers.GlorotNormal)(y)\n",
    "\n",
    "y_residual = y\n",
    "\n",
    "y = tf.keras.layers.BatchNormalization()(y)\n",
    "y = tf.keras.layers.Dense(NEURONS_GRU_MLP,\n",
    "                        activation=tf.keras.activations.relu, \n",
    "                        kernel_initializer=tf.keras.initializers.GlorotNormal)(y)\n",
    "y = tf.keras.layers.Concatenate(axis=1)([y,y_residual])\n",
    "\n",
    "final_base_model_output = tf.keras.layers.Concatenate(axis=1)([x,y])\n",
    "\n",
    "\n",
    "\n",
    "concatenated_efficientnet_gru_model = tf.keras.Model(inputs=inp,outputs=final_base_model_output)\n",
    "\n",
    "concatenated_efficientnet_gru_model(x_train[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ef31223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_6 (Sli (None, 32, 32)       0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_7 (Sli (None, 32, 32)       0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_8 (Sli (None, 32, 32)       0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gru_12 (GRU)                    [(None, 32, 32), (No 6336        tf.__operators__.getitem_6[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "gru_13 (GRU)                    [(None, 32, 32), (No 6336        tf.__operators__.getitem_7[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "gru_14 (GRU)                    [(None, 32, 32), (No 6336        tf.__operators__.getitem_8[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "resizing_2 (Resizing)           (None, 600, 600, 3)  0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gru_15 (GRU)                    (None, 32)           6336        gru_12[0][0]                     \n",
      "                                                                 gru_12[0][1]                     \n",
      "__________________________________________________________________________________________________\n",
      "gru_16 (GRU)                    (None, 32)           6336        gru_13[0][0]                     \n",
      "                                                                 gru_13[0][1]                     \n",
      "__________________________________________________________________________________________________\n",
      "gru_17 (GRU)                    (None, 32)           6336        gru_14[0][0]                     \n",
      "                                                                 gru_14[0][1]                     \n",
      "__________________________________________________________________________________________________\n",
      "model (Functional)              (None, 2560)         64097687    resizing_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 96)           0           gru_15[0][0]                     \n",
      "                                                                 gru_16[0][0]                     \n",
      "                                                                 gru_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 2560)         10240       model[2][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 96)           384         concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 50)           128050      batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 50)           4850        batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 50)           200         dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 50)           200         dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 50)           2550        batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 50)           2550        batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 100)          0           dense_9[0][0]                    \n",
      "                                                                 dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 100)          0           dense_11[0][0]                   \n",
      "                                                                 dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 200)          0           concatenate_8[0][0]              \n",
      "                                                                 concatenate_10[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 64,284,727\n",
      "Trainable params: 1,819,928\n",
      "Non-trainable params: 62,464,799\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "concatenated_efficientnet_gru_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "627e562d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Date = '2022-02-18_00_23'\n",
    "PROBLEM_TYPE = 'classification'\n",
    "NUMBER_OF_CLASSES = 10\n",
    "INPUT_SHAPE = (32, 32, 3)\n",
    "BASE_MODEL_INPUT_SHAPE = (32, 32, 3)\n",
    "PROJECT_NAME = 'CIFAR10_GRU-EfficientNetB7-ResidualMLP_NAS_THIRD_PASS_SEARCH'\n",
    "TRAINING_SET_SIZE = 1000\n",
    "PATIENCE = 25\n",
    "PATIENCE_MIN_DELTA = 1e-05\n",
    "BATCH_SIZE = 50\n",
    "MAX_EPOCHS = 150\n",
    "RESULTS_DIR_FOR_SEARCH = '2022-02-12_14_48_CIFAR10_EfficientNetB7-ResidualMLP_NAS_THIRD_PASS_SEARCH_SEARCH_RUN'\n",
    "MINIMUM_LEARNING_RATE = 0.0001\n",
    "MAXIMUM_LEARNING_RATE = 0.02\n",
    "NUMBER_OF_LEARNING_RATES_TO_TRY = 7\n",
    "MINIMUM_NUMBER_OF_BLOCKS = 2\n",
    "MAXIMUM_NUMBER_OF_BLOCKS = 3\n",
    "MINIMUM_NUMBER_OF_LAYERS_PER_BLOCK = 2\n",
    "MAXIMUM_NUMBER_OF_LAYERS_PER_BLOCK = 4\n",
    "MINIMUM_NEURONS_PER_BLOCK_LAYER = 70\n",
    "MAXIMUM_NEURONS_PER_BLOCK_LAYER = 140\n",
    "N_OPTIONS_OF_NEURONS_PER_LAYER_TO_TRY = 7\n",
    "MINIMUM_NEURONS_PER_BLOCK_LAYER_DECAY = 15\n",
    "MAXIMUM_NEURONS_PER_BLOCK_LAYER_DECAY = 35\n",
    "MINIMUM_DROPOUT_RATE_FOR_BYPASS_LAYERS = 0.2\n",
    "MAXIMIM_DROPOUT_RATE_FOR_BYPASS_LAYERS = 0.6\n",
    "N_OPTIONS_DROPOUT_RATE_FOR_BYPASS_LAYERS = 3\n",
    "MINIMUM_INTER_BLOCK_LAYERS_PER_BLOCK = 0\n",
    "MAXIMUM_INTER_BLOCK_LAYERS_PER_BLOCK = 85\n",
    "N_OPTIONS_INTER_BLOCK_LAYERS_PER_BLOCK = 7\n",
    "MINIMUM_DROPOUT_RATE = 0.2\n",
    "MAXIMUM_DROPOUT_RATE = 0.6\n",
    "N_OPTIONS_DROPOUT_RATE = 5\n",
    "MINIMUM_FINAL_DENSE_LAYERS = 33\n",
    "MAXIMUM_FINAL_DENSE_LAYERS = 300\n",
    "N_OPTIONS_FINAL_DENSE_LAYERS = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec50205e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_builder = ResidualMLP(\n",
    "                    problem_type = PROBLEM_TYPE,\n",
    "                    minimum_learning_rate = MINIMUM_LEARNING_RATE, \n",
    "                    maximum_learning_rate = MAXIMUM_LEARNING_RATE, \n",
    "                    number_of_learning_rates_to_try =\n",
    "                        NUMBER_OF_LEARNING_RATES_TO_TRY, \n",
    "                    input_shape = INPUT_SHAPE, \n",
    "                    bw_images = False, \n",
    "                    base_model =\\\n",
    "                        concatenated_efficientnet_gru_model, \n",
    "                    base_model_input_shape = BASE_MODEL_INPUT_SHAPE, \n",
    "                    flatten_after_base_model = False, \n",
    "                    minimum_number_of_blocks = MINIMUM_NUMBER_OF_BLOCKS, \n",
    "                    maximum_number_of_blocks = MAXIMUM_NUMBER_OF_BLOCKS, \n",
    "                    minimum_number_of_layers_per_block =\n",
    "                        MINIMUM_NUMBER_OF_LAYERS_PER_BLOCK, \n",
    "                    maximum_number_of_layers_per_block =\n",
    "                        MAXIMUM_NUMBER_OF_LAYERS_PER_BLOCK,\n",
    "                    minimum_neurons_per_block_layer =\n",
    "                        MINIMUM_NEURONS_PER_BLOCK_LAYER, \n",
    "                    maximum_neurons_per_block_layer =\n",
    "                        MAXIMUM_NEURONS_PER_BLOCK_LAYER, \n",
    "                    n_options_of_neurons_per_layer_to_try =\n",
    "                        N_OPTIONS_OF_NEURONS_PER_LAYER_TO_TRY, \n",
    "                    minimum_neurons_per_block_layer_decay =\n",
    "                        MINIMUM_NEURONS_PER_BLOCK_LAYER_DECAY, \n",
    "                    maximum_neurons_per_block_layer_decay = \n",
    "                        MAXIMUM_NEURONS_PER_BLOCK_LAYER_DECAY, \n",
    "                    minimum_dropout_rate_for_bypass_layers =\n",
    "                        MINIMUM_DROPOUT_RATE_FOR_BYPASS_LAYERS, \n",
    "                    maximim_dropout_rate_for_bypass_layers =\n",
    "                        MAXIMIM_DROPOUT_RATE_FOR_BYPASS_LAYERS, \n",
    "                    n_options_dropout_rate_for_bypass_layers =\n",
    "                        N_OPTIONS_DROPOUT_RATE_FOR_BYPASS_LAYERS,\n",
    "                    minimum_inter_block_layers_per_block =\n",
    "                        MINIMUM_INTER_BLOCK_LAYERS_PER_BLOCK, \n",
    "                    maximum_inter_block_layers_per_block =\n",
    "                        MAXIMUM_INTER_BLOCK_LAYERS_PER_BLOCK,\n",
    "                    n_options_inter_block_layers_per_block =  \\\n",
    "                        N_OPTIONS_INTER_BLOCK_LAYERS_PER_BLOCK,\n",
    "                    minimum_dropout_rate = MINIMUM_DROPOUT_RATE, \n",
    "                    maximum_dropout_rate = MAXIMUM_DROPOUT_RATE,\n",
    "                    n_options_dropout_rate = N_OPTIONS_DROPOUT_RATE, \n",
    "                    minimum_final_dense_layers =\n",
    "                        MINIMUM_FINAL_DENSE_LAYERS,\n",
    "                    maximum_final_dense_layers =\n",
    "                        MAXIMUM_FINAL_DENSE_LAYERS, \n",
    "                    n_options_final_dense_layers =\n",
    "                        N_OPTIONS_FINAL_DENSE_LAYERS, \n",
    "                    number_of_classes = NUMBER_OF_CLASSES,\n",
    "                    final_activation = tf.keras.activations.softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "27024779",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2ccff325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All permutations:\n",
      "     number_of_blocks  layers_per_block  neurons_per_block_layer  \\\n",
      "0                   2                 2                       70   \n",
      "1                   2                 2                       70   \n",
      "2                   2                 2                       70   \n",
      "3                   2                 2                       70   \n",
      "4                   2                 2                       70   \n",
      "..                ...               ...                      ...   \n",
      "877                 3                 4                      140   \n",
      "878                 3                 4                      140   \n",
      "879                 3                 4                      140   \n",
      "880                 3                 4                      140   \n",
      "881                 3                 4                      140   \n",
      "\n",
      "     neurons_per_block_layer_decay  \n",
      "0                               15  \n",
      "1                               16  \n",
      "2                               17  \n",
      "3                               18  \n",
      "4                               19  \n",
      "..                             ...  \n",
      "877                             31  \n",
      "878                             32  \n",
      "879                             33  \n",
      "880                             34  \n",
      "881                             35  \n",
      "\n",
      "[882 rows x 4 columns]\n",
      "Valid permutations\n",
      "     number_of_blocks  layers_per_block  neurons_per_block_layer  \\\n",
      "0                   2                 2                       70   \n",
      "1                   2                 2                       70   \n",
      "2                   2                 2                       70   \n",
      "3                   2                 2                       70   \n",
      "4                   2                 2                       70   \n",
      "..                ...               ...                      ...   \n",
      "689                 3                 4                      140   \n",
      "690                 3                 4                      140   \n",
      "691                 3                 4                      140   \n",
      "692                 3                 4                      140   \n",
      "693                 3                 4                      140   \n",
      "\n",
      "     neurons_per_block_layer_decay  valid_block  \n",
      "0                               15         True  \n",
      "1                               16         True  \n",
      "2                               17         True  \n",
      "3                               18         True  \n",
      "4                               19         True  \n",
      "..                             ...          ...  \n",
      "689                             30         True  \n",
      "690                             31         True  \n",
      "691                             32         True  \n",
      "692                             33         True  \n",
      "693                             34         True  \n",
      "\n",
      "[694 rows x 5 columns]\n",
      "Valid permutations with blocks column\n",
      "     number_of_blocks  layers_per_block  neurons_per_block_layer  \\\n",
      "0                   2                 2                       70   \n",
      "1                   2                 2                       70   \n",
      "2                   2                 2                       70   \n",
      "3                   2                 2                       70   \n",
      "4                   2                 2                       70   \n",
      "..                ...               ...                      ...   \n",
      "689                 3                 4                      140   \n",
      "690                 3                 4                      140   \n",
      "691                 3                 4                      140   \n",
      "692                 3                 4                      140   \n",
      "693                 3                 4                      140   \n",
      "\n",
      "     neurons_per_block_layer_decay  valid_block  \\\n",
      "0                               15         True   \n",
      "1                               16         True   \n",
      "2                               17         True   \n",
      "3                               18         True   \n",
      "4                               19         True   \n",
      "..                             ...          ...   \n",
      "689                             30         True   \n",
      "690                             31         True   \n",
      "691                             32         True   \n",
      "692                             33         True   \n",
      "693                             34         True   \n",
      "\n",
      "                                         blocks  \n",
      "0                    [[2, 70, 15], [2, 70, 15]]  \n",
      "1                    [[2, 70, 16], [2, 70, 16]]  \n",
      "2                    [[2, 70, 17], [2, 70, 17]]  \n",
      "3                    [[2, 70, 18], [2, 70, 18]]  \n",
      "4                    [[2, 70, 19], [2, 70, 19]]  \n",
      "..                                          ...  \n",
      "689  [[4, 140, 30], [4, 140, 30], [4, 140, 30]]  \n",
      "690  [[4, 140, 31], [4, 140, 31], [4, 140, 31]]  \n",
      "691  [[4, 140, 32], [4, 140, 32], [4, 140, 32]]  \n",
      "692  [[4, 140, 33], [4, 140, 33], [4, 140, 33]]  \n",
      "693  [[4, 140, 34], [4, 140, 34], [4, 140, 34]]  \n",
      "\n",
      "[694 rows x 6 columns]\n",
      "[[2, 70, 15], [2, 70, 15]]\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.Hyperband(\n",
    "    model_builder.build_auto_residual_mlp,\n",
    "    objective='val_loss',\n",
    "    project_name = PROJECT_NAME,\n",
    "    max_epochs = MAX_EPOCHS,\n",
    "    hyperband_iterations = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc302022",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search(x=selected_x_train,  \n",
    "             y=selected_y_train_ohe,\n",
    "             epochs=MAX_EPOCHS,\n",
    "             batch_size=BATCH_SIZE, \n",
    "             callbacks=[\n",
    "                    tf.keras.callbacks.EarlyStopping(\n",
    "                        monitor=\"val_loss\",\n",
    "                        patience=PATIENCE,\n",
    "                        min_delta=PATIENCE_MIN_DELTA,\n",
    "                        restore_best_weights=True,\n",
    "                    ),\n",
    "                    tensorboard_callback_search,\n",
    "                ],\n",
    "             validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34603c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c291f2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train base model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101ade9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-18 05:34:59.292340: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n",
      "2022-02-18 05:34:59.292392: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n",
      "2022-02-18 05:34:59.635411: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n",
      "2022-02-18 05:34:59.635651: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1749] CUPTI activity buffer flushed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Search: Running Trial #1\n",
      "\n",
      "Hyperparameter    |Value             |Best Value So Far \n",
      "learning_rate     |0.0017671         |?                 \n",
      "blocks            |62                |?                 \n",
      "bypass_layers_u...|70                |?                 \n",
      "inter_block_layers|85                |?                 \n",
      "final_dense_layers|77                |?                 \n",
      "b_norm_or_dropo...|bnorm             |?                 \n",
      "dropout_rate_fo...|0.2               |?                 \n",
      "b_norm_or_dropo...|bnorm             |?                 \n",
      "dropout_rate      |0.2               |?                 \n",
      "tuner/epochs      |2                 |?                 \n",
      "tuner/initial_e...|0                 |?                 \n",
      "tuner/bracket     |4                 |?                 \n",
      "tuner/round       |0                 |?                 \n",
      "\n",
      "All permutations:\n",
      "     number_of_blocks  layers_per_block  neurons_per_block_layer  \\\n",
      "0                   2                 2                       70   \n",
      "1                   2                 2                       70   \n",
      "2                   2                 2                       70   \n",
      "3                   2                 2                       70   \n",
      "4                   2                 2                       70   \n",
      "..                ...               ...                      ...   \n",
      "877                 3                 4                      140   \n",
      "878                 3                 4                      140   \n",
      "879                 3                 4                      140   \n",
      "880                 3                 4                      140   \n",
      "881                 3                 4                      140   \n",
      "\n",
      "     neurons_per_block_layer_decay  \n",
      "0                               15  \n",
      "1                               16  \n",
      "2                               17  \n",
      "3                               18  \n",
      "4                               19  \n",
      "..                             ...  \n",
      "877                             31  \n",
      "878                             32  \n",
      "879                             33  \n",
      "880                             34  \n",
      "881                             35  \n",
      "\n",
      "[882 rows x 4 columns]\n",
      "Valid permutations\n",
      "     number_of_blocks  layers_per_block  neurons_per_block_layer  \\\n",
      "0                   2                 2                       70   \n",
      "1                   2                 2                       70   \n",
      "2                   2                 2                       70   \n",
      "3                   2                 2                       70   \n",
      "4                   2                 2                       70   \n",
      "..                ...               ...                      ...   \n",
      "689                 3                 4                      140   \n",
      "690                 3                 4                      140   \n",
      "691                 3                 4                      140   \n",
      "692                 3                 4                      140   \n",
      "693                 3                 4                      140   \n",
      "\n",
      "     neurons_per_block_layer_decay  valid_block  \n",
      "0                               15         True  \n",
      "1                               16         True  \n",
      "2                               17         True  \n",
      "3                               18         True  \n",
      "4                               19         True  \n",
      "..                             ...          ...  \n",
      "689                             30         True  \n",
      "690                             31         True  \n",
      "691                             32         True  \n",
      "692                             33         True  \n",
      "693                             34         True  \n",
      "\n",
      "[694 rows x 5 columns]\n",
      "Valid permutations with blocks column\n",
      "     number_of_blocks  layers_per_block  neurons_per_block_layer  \\\n",
      "0                   2                 2                       70   \n",
      "1                   2                 2                       70   \n",
      "2                   2                 2                       70   \n",
      "3                   2                 2                       70   \n",
      "4                   2                 2                       70   \n",
      "..                ...               ...                      ...   \n",
      "689                 3                 4                      140   \n",
      "690                 3                 4                      140   \n",
      "691                 3                 4                      140   \n",
      "692                 3                 4                      140   \n",
      "693                 3                 4                      140   \n",
      "\n",
      "     neurons_per_block_layer_decay  valid_block  \\\n",
      "0                               15         True   \n",
      "1                               16         True   \n",
      "2                               17         True   \n",
      "3                               18         True   \n",
      "4                               19         True   \n",
      "..                             ...          ...   \n",
      "689                             30         True   \n",
      "690                             31         True   \n",
      "691                             32         True   \n",
      "692                             33         True   \n",
      "693                             34         True   \n",
      "\n",
      "                                         blocks  \n",
      "0                    [[2, 70, 15], [2, 70, 15]]  \n",
      "1                    [[2, 70, 16], [2, 70, 16]]  \n",
      "2                    [[2, 70, 17], [2, 70, 17]]  \n",
      "3                    [[2, 70, 18], [2, 70, 18]]  \n",
      "4                    [[2, 70, 19], [2, 70, 19]]  \n",
      "..                                          ...  \n",
      "689  [[4, 140, 30], [4, 140, 30], [4, 140, 30]]  \n",
      "690  [[4, 140, 31], [4, 140, 31], [4, 140, 31]]  \n",
      "691  [[4, 140, 32], [4, 140, 32], [4, 140, 32]]  \n",
      "692  [[4, 140, 33], [4, 140, 33], [4, 140, 33]]  \n",
      "693  [[4, 140, 34], [4, 140, 34], [4, 140, 34]]  \n",
      "\n",
      "[694 rows x 6 columns]\n",
      "[[2, 105, 15], [2, 105, 15]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n",
      "2022-02-18 05:35:02.525136: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "  1/140 [..............................] - ETA: 1:03:19 - loss: 3.4376 - top_1_categorical_accuracy: 0.0000e+00 - top_2_categorical_accuracy: 0.0000e+00 - top_3_categorical_accuracy: 0.0000e+00 - top_4_categorical_accuracy: 0.0000e+00 - top_5_categorical_accuracy: 0.2000 - top_6_categorical_accuracy: 0.4000 - top_7_categorical_accuracy: 0.6000 - top_8_categorical_accuracy: 0.8000 - top_9_categorical_accuracy: 1.0000 - precision: 0.0000e+00 - recall: 0.0000e+00 - accuracy: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-18 05:35:31.244088: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n",
      "2022-02-18 05:35:31.244150: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "  2/140 [..............................] - ETA: 16:15 - loss: 3.1125 - top_1_categorical_accuracy: 0.0000e+00 - top_2_categorical_accuracy: 0.1000 - top_3_categorical_accuracy: 0.1000 - top_4_categorical_accuracy: 0.2000 - top_5_categorical_accuracy: 0.4000 - top_6_categorical_accuracy: 0.6000 - top_7_categorical_accuracy: 0.8000 - top_8_categorical_accuracy: 0.9000 - top_9_categorical_accuracy: 1.0000 - precision: 0.0000e+00 - recall: 0.0000e+00 - accuracy: 0.0000e+00              "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-18 05:35:36.978760: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2022-02-18 05:35:36.979346: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1749] CUPTI activity buffer flushed\n",
      "2022-02-18 05:35:37.074848: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:673]  GpuTracer has collected 5643 callback api events and 5414 activity events. \n",
      "2022-02-18 05:35:37.193003: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n",
      "2022-02-18 05:35:37.326467: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: logs/2022-02-17_efficientnet_concat_gru_model_TB/4b7f368d3655dc6743263b3ddadd936f/execution0/train/plugins/profile/2022_02_18_05_35_37\n",
      "\n",
      "2022-02-18 05:35:37.405368: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to logs/2022-02-17_efficientnet_concat_gru_model_TB/4b7f368d3655dc6743263b3ddadd936f/execution0/train/plugins/profile/2022_02_18_05_35_37/n2bws8wy7k.trace.json.gz\n",
      "2022-02-18 05:35:37.560906: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: logs/2022-02-17_efficientnet_concat_gru_model_TB/4b7f368d3655dc6743263b3ddadd936f/execution0/train/plugins/profile/2022_02_18_05_35_37\n",
      "\n",
      "2022-02-18 05:35:37.567238: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to logs/2022-02-17_efficientnet_concat_gru_model_TB/4b7f368d3655dc6743263b3ddadd936f/execution0/train/plugins/profile/2022_02_18_05_35_37/n2bws8wy7k.memory_profile.json.gz\n",
      "2022-02-18 05:35:37.600307: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: logs/2022-02-17_efficientnet_concat_gru_model_TB/4b7f368d3655dc6743263b3ddadd936f/execution0/train/plugins/profile/2022_02_18_05_35_37\n",
      "Dumped tool data for xplane.pb to logs/2022-02-17_efficientnet_concat_gru_model_TB/4b7f368d3655dc6743263b3ddadd936f/execution0/train/plugins/profile/2022_02_18_05_35_37/n2bws8wy7k.xplane.pb\n",
      "Dumped tool data for overview_page.pb to logs/2022-02-17_efficientnet_concat_gru_model_TB/4b7f368d3655dc6743263b3ddadd936f/execution0/train/plugins/profile/2022_02_18_05_35_37/n2bws8wy7k.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to logs/2022-02-17_efficientnet_concat_gru_model_TB/4b7f368d3655dc6743263b3ddadd936f/execution0/train/plugins/profile/2022_02_18_05_35_37/n2bws8wy7k.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to logs/2022-02-17_efficientnet_concat_gru_model_TB/4b7f368d3655dc6743263b3ddadd936f/execution0/train/plugins/profile/2022_02_18_05_35_37/n2bws8wy7k.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to logs/2022-02-17_efficientnet_concat_gru_model_TB/4b7f368d3655dc6743263b3ddadd936f/execution0/train/plugins/profile/2022_02_18_05_35_37/n2bws8wy7k.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140/140 [==============================] - 839s 6s/step - loss: 2.4020 - top_1_categorical_accuracy: 0.2271 - top_2_categorical_accuracy: 0.3914 - top_3_categorical_accuracy: 0.4986 - top_4_categorical_accuracy: 0.6071 - top_5_categorical_accuracy: 0.6857 - top_6_categorical_accuracy: 0.7571 - top_7_categorical_accuracy: 0.8500 - top_8_categorical_accuracy: 0.9143 - top_9_categorical_accuracy: 0.9714 - precision: 0.2908 - recall: 0.0814 - accuracy: 0.0000e+00 - val_loss: 2.4666 - val_top_1_categorical_accuracy: 0.2200 - val_top_2_categorical_accuracy: 0.3733 - val_top_3_categorical_accuracy: 0.4933 - val_top_4_categorical_accuracy: 0.6167 - val_top_5_categorical_accuracy: 0.6767 - val_top_6_categorical_accuracy: 0.7533 - val_top_7_categorical_accuracy: 0.8233 - val_top_8_categorical_accuracy: 0.9267 - val_top_9_categorical_accuracy: 0.9667 - val_precision: 0.1600 - val_recall: 0.0267 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/2\n",
      "140/140 [==============================] - ETA: 0s - loss: 1.9645 - top_1_categorical_accuracy: 0.2857 - top_2_categorical_accuracy: 0.5043 - top_3_categorical_accuracy: 0.6714 - top_4_categorical_accuracy: 0.7800 - top_5_categorical_accuracy: 0.8500 - top_6_categorical_accuracy: 0.9043 - top_7_categorical_accuracy: 0.9386 - top_8_categorical_accuracy: 0.9629 - top_9_categorical_accuracy: 0.9843 - precision: 0.3871 - recall: 0.1200 - accuracy: 0.0000e+00"
     ]
    }
   ],
   "source": [
    "import os\n",
    "BATCH_SIZE = 5\n",
    "PATIENCE = 5\n",
    "PATIENCE_MIN_DELTA = .002\n",
    "RESULTS_DIR_FOR_FINAL_MODEL = \"2022-02-17_efficientnet_concat_gru_model\"\n",
    "\n",
    "logdir_final_model = os.path.join(\"logs\",\n",
    "                                  RESULTS_DIR_FOR_FINAL_MODEL + \"_TB\")\n",
    "tensorboard_callback_search =\\\n",
    "    tf.keras.callbacks.TensorBoard(logdir_final_model, histogram_freq=1)\n",
    "\n",
    "tuner.search(x=selected_x_train,  \n",
    "             y=selected_y_train_ohe,\n",
    "             epochs=MAX_EPOCHS,\n",
    "             batch_size=BATCH_SIZE, \n",
    "             callbacks=[\n",
    "                    tf.keras.callbacks.EarlyStopping(\n",
    "                        monitor=\"val_loss\",\n",
    "                        patience=PATIENCE,\n",
    "                        min_delta=PATIENCE_MIN_DELTA,\n",
    "                        restore_best_weights=True,\n",
    "                    ),\n",
    "                    tensorboard_callback_search,\n",
    "                ],\n",
    "             validation_split=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa56763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add stanza for getting best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e17f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install matplotlib\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "hy = pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afea9d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "hy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed6594d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hy[[\"top_k_categorical_accuracy\",\"val_top_k_categorical_accuracy\"]].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc48545",
   "metadata": {},
   "outputs": [],
   "source": [
    "hy[[\"loss\",\"val_loss\"]].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20ff401",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
