{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "add2f2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_SET_SIZE = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d224726b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.5.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.3 MB 14.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (2.4.7)\n",
      "Collecting cycler>=0.10\n",
      "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (1.19.4)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.28.5-py3-none-any.whl (890 kB)\n",
      "\u001b[K     |████████████████████████████████| 890 kB 26.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (2.8.2)\n",
      "Collecting pillow>=6.2.0\n",
      "  Downloading Pillow-9.0.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.3 MB 19.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.3.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 29.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (21.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7->matplotlib) (1.15.0)\n",
      "Installing collected packages: pillow, kiwisolver, fonttools, cycler, matplotlib\n",
      "Successfully installed cycler-0.11.0 fonttools-4.28.5 kiwisolver-1.3.2 matplotlib-3.5.1 pillow-9.0.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.8/dist-packages (0.13.1)\n",
      "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.8/dist-packages (from tensorflow-addons) (2.12.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting pandas\n",
      "  Downloading pandas-1.3.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.5 MB 17.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (1.19.4)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "Installing collected packages: pandas\n",
      "Successfully installed pandas-1.3.5\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting pendulum\n",
      "  Downloading pendulum-2.1.2-cp38-cp38-manylinux1_x86_64.whl (155 kB)\n",
      "\u001b[K     |████████████████████████████████| 155 kB 24.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pytzdata>=2020.1\n",
      "  Downloading pytzdata-2020.1-py2.py3-none-any.whl (489 kB)\n",
      "\u001b[K     |████████████████████████████████| 489 kB 27.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil<3.0,>=2.6 in /usr/local/lib/python3.8/dist-packages (from pendulum) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil<3.0,>=2.6->pendulum) (1.15.0)\n",
      "Installing collected packages: pytzdata, pendulum\n",
      "Successfully installed pendulum-2.1.2 pytzdata-2020.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.3.0 and strictly below 2.6.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.6.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "! pip3 install matplotlib\n",
    "! pip3 install tensorflow-addons\n",
    "! pip3 install pandas\n",
    "! pip3 install pendulum\n",
    "import os\n",
    "import pendulum\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_addons as tfa\n",
    "from residualmlp.residual_mlp import ResidualMLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99355821",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "weight_decay = 0.0001\n",
    "batch_size = 50\n",
    "num_epochs = 100\n",
    "image_size = 32  # We'll resize input images to this size\n",
    "patch_size = 6  # Size of the patches to be extract from the input images\n",
    "num_patches = (image_size // patch_size) ** 2\n",
    "projection_dim = 64\n",
    "num_heads = 4\n",
    "transformer_units = [\n",
    "    projection_dim * 2,\n",
    "    projection_dim,\n",
    "]  # Size of the transformer layers\n",
    "transformer_layers = 5\n",
    "mlp_head_units = [2048, 1024]  # Size of the dense layers of the final classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "877f41fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar = tf.keras.datasets.cifar10.load_data()\n",
    "(x_train, y_train), (x_test, y_test) = cifar\n",
    "\n",
    "y_train_ohe = tf.one_hot([i[0] for i in y_train], 10)\n",
    "indexes_for_rows = tf.range(0, y_train.shape[0])\n",
    "shuffled_indexes = tf.random.shuffle(indexes_for_rows)\n",
    "selected_indexes = shuffled_indexes[:TRAINING_SET_SIZE]\n",
    "selected_x_train = x_train[selected_indexes, :, :, :]\n",
    "selected_y_train_ohe = y_train_ohe.numpy()[selected_indexes, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5c63047",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-14 05:11:31.310770: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    }
   ],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.Normalization(),\n",
    "        layers.Resizing(image_size, image_size),\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(factor=0.02),\n",
    "        layers.RandomZoom(\n",
    "            height_factor=0.2, width_factor=0.2\n",
    "        ),\n",
    "    ],\n",
    "    name=\"data_augmentation\",\n",
    ")\n",
    "data_augmentation.layers[0].adapt(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4759d34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Patches(layers.Layer):\n",
    "    def __init__(self, patch_size):\n",
    "        super(Patches, self).__init__()\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    def call(self, images):\n",
    "        batch_size = tf.shape(images)[0]\n",
    "        patches = tf.image.extract_patches(\n",
    "            images=images,\n",
    "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
    "            strides=[1, self.patch_size, self.patch_size, 1],\n",
    "            rates=[1, 1, 1, 1],\n",
    "            padding=\"VALID\",\n",
    "        )\n",
    "        patch_dims = patches.shape[-1]\n",
    "        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
    "        return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "efbae6ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 31.5, 31.5, -0.5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(4, 4))\n",
    "image = x_train[np.random.choice(range(x_train.shape[0]))]\n",
    "plt.imshow(image.astype(\"uint8\"))\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8477d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image size: 32 X 32\n",
      "Patch size: 6 X 6\n",
      "Patches per image: 25\n",
      "Elements per patch: 108\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "resized_image = tf.image.resize(\n",
    "    tf.convert_to_tensor([image]), size=(image_size, image_size)\n",
    ")\n",
    "\n",
    "patches = Patches(patch_size)(resized_image)\n",
    "print(f\"Image size: {image_size} X {image_size}\")\n",
    "print(f\"Patch size: {patch_size} X {patch_size}\")\n",
    "print(f\"Patches per image: {patches.shape[1]}\")\n",
    "print(f\"Elements per patch: {patches.shape[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9e587e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOwAAADnCAYAAAAdFLrXAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAASU0lEQVR4nO3d2a8l11XH8VXDGe7U3e7BQ+KJGEhw2rGbBKdtBHKCrWBLPESAAhJ5gT8hj0j8BXnjP+AFEREhxSRALGjsiHiKbMcz3cZT7J7Tfed7z1BVPFhEoKzfOj6nI5sF38/jvrd27VOn1ilp7V1rF13XGYAcyo97AAA+PAIWSISABRIhYIFECFggkTr64+233OqmkEsr5DFNr3LbVw6tue2T7R3Z1+b6htt+4eIlPQAzu/3WT7rjPnHXcXnMYDh020+fedNt39jwx/YBP/P+H+/8JBy3mdmnbrvFPbgNjlxZW3Xbp5Op2769vS376trWbT979kI49ruP3+mO+8YbbpDH9Ho9t/3ChYtu++7uruyrFeN+7cwb4bjvEeNuGr8/M7M9MQ517ZYG/r1lZra25sfFk88/746bJyyQCAELJELAAokQsEAiBCyQSJglHlR+xtdavf64EBnSyvy+Jm1f9rW27Gc/Z7nv3nvd9ltuvVke8+TTT7vtG9vrbnslsuFmZm2nM4yzlJWf1NRnMxuLTPtkMnHbl0V21szsjjs+FZxJu+fE3W77lStX5DE/ee89t320v++2l1X0fFlsTfzmzpbfW/AdDgYDt/3o4SNu+9KSzhKrTL7CExZIhIAFEiFggUQIWCARAhZIhIAFEgmndT5x7JjbHq2mHpd+en1c+lMJ/SOHZF8n7/50cCbt5Od/3W1/9rnn5DGNSK+vipR8XetLdy1Vd1aX/CmD6f5YHqN+dT95001u+8mTJ2VfBw4elH+LNOOR2765rqd1KvOnTpaH/lRf0zSyr0mwWD+yMvSvd6+nv9+bb/anB1dX/GnICxfOy762tqKXSH4eT1ggEQIWSISABRIhYIFECFggkTBLvNz3/1yXein6pPJTpMXBo277jb98Qva1WvqLwGd5RWSDN85dkscMO/+3q+r7GUtV3uRaHV5ecdv3g8xzWfhj//xdn3Xbbzp8nezrtX9/XZ8osH7+nNs+CFLmtSjLMxUvLeyIlwLMzA6s+Ndtlvvu8V9aiEoAbYkSOztjkckXn8fMrF/MrBr0P/CEBRIhYIFECFggEQIWSISABRIJs8RbV6+67UWwmnha+ms6V1f9zGQnsqJmZs/88N+C0WlnXn3VbR9W+lxl569T7RdijWrjr501MyvmzPz9d/XUX9O8HKxdVqu7T7/iX4fXX3pp7r5maXf33PYuyJCaWv/b+NdgECwX7k/1OuPIhXfeddt3dnSB+9HI/+7rvj9zEK1yLsT3rfCEBRIhYIFECFggEQIWSISABRIhYIFEwmmdulALt+ev/F/sbLrt62+9Ivtq9/xjZinFjgVtp1PovdK/FJ35JUTG02C6QlTv/zAasatCGSyiL1p/SmNvy79+0bSc2id3lkLsjVoF4y7FuLvW/56qQr90Uk4Wu+ZbV/0SNlHl/6EYx3jif54mGtqc5YR4wgKJELBAIgQskAgBCyRCwAKJFN21VL0G8JHiCQskQsACiRCwQCIELJAIAQskQsACiYSL/79yz53unE80FaTWORdiQf40WIjeiDo9p158NVzp/eDdx/0BRnuIisr/6jetETWgzMwKsfj/X156eeYK9S997rPu2FVpKbMFfnWDmby+2Bf1ey/8OBz7791zl9vrNHhJQn2kqfiwXaFfTFjuL7vtf/+jp8Jx/+7nPuOOu50Gu050/r08EjtijMSLER/05Tc/9fob7rh5wgKJELBAIgQskAgBCyRCwAKJhFniSlSwF1VMzMysFMdUlSjBElQ+V+efxd/RVe+jambWiB0LVHsdXIMuygrOMBAXd1ro/Wg7E6VTxOWLsvxtt+A1F0nzttC32Hjgl9+pVg+47cs33ij7Whn6fc3StP7nraf6OuyLj9SI+/UX+VTkCQskQsACiRCwQCIELJAIAQskQsACiYTTOtb46f9ouqUW0zeVWPwfTSIU0fxRYCDOFe5YIKZvilq0t/q3rmgW/x3si42b9aSOWWv+1FhZ+uMogumtXvC3SF35k2lFX02ymQ2OHvPbD1/vth/8lV+SfR056C/+n6U3XHPbS1HF38ys7Iv7S8VLcJcX4juS557rvwF8rAhYIBECFkiEgAUSIWCBROLF/yKDpbKP0d/Ugviq1n1VC2Ysq56fxesKnfmrK5VRVQfo7GfXxcn3SCOyqrXpUiuVKFfTE9chfKdiwY0gmrXr3PbB9X4m2MzMjoks8cpBt317rAd3bMl/YWCWI7f6mecrp/W+xXXpX8BG7HdbyH2WzeJ5kp/HExZIhIAFEiFggUQIWCARAhZIJExn9mt/BWtYSFz8qRV/KJf0KtlizgzazwxExjf4tLU4l/o8TamzxNNKF7yepT5yg9telvqaj/d33XadV9aWVhbLtt7whfv8MVznr9U1M9sVS3IPiKLgFy9clX2t9fzM8iyHb7/NbT/39ml5TF/MePRFXHQiq2xm1nXzlRPiCQskQsACiRCwQCIELJAIAQskQsACiYTTOqUotRItZa7EHplWi10EgpmbNtrPNdCItHuUQq/Fb1cnLlE31NMft995VzC62G88/IjbXg2X5DFXN3fc9qkqWSJL6JgdPXI0GJ12/KGH3PbLEz25tDXyx928/67bvvnWm7KvN0ZqB4k/kMeYmU3FvTJcW5HH1Ntbbnul9hIOzt/JfYl9PGGBRAhYIBECFkiEgAUSIWCBRIpoIT+A/114wgKJELBAIgQskAgBCyRCwAKJELBAIuHi/9+//4vunI96KcAsWPxvYp/V4FWC8Xjstn/7yR+FxZ6+eu8Jt9NoCqsW9asmoj7ToU8fl3396v33u+1//mdfn1mk6pt/9x13kAeu8yvrm5l1Pb8GUn/Zr3PUTfVLEFcvnXXbv/HIA+HY//LUD91xDw59Qh6zseHXaHr7+99y21879QPZVzf0r8+pU4+G4/6TP/xjd9y7F9/RB+1tikGol2V0vEwb/6WFR5970R03T1ggEQIWSISABRIhYIFECFggkTBL3IryGXWtD1NlWKaqVIjYU9PMbDpVZT9ik7F/rjbIEk/H+/4xS/4x/RVdsqVY1uVFZtlWl2Oix762uuq2d5W/O8Hu5k9lX4/9w3fd9m888oA8xszsvffed9tP3PZr8pjR5rrbfvHtt9z2lcKfNTAzaycbenCBzXN+Nria+vfDByfzv4tW7NNbRBvyzvnyDU9YIBECFkiEgAUSIWCBRAhYIBECFkgkrvwvpmg6sWA5MhmP3HY53XMN1EsDUXq9M/+YRkynXL16SfZ1i5gO+zAmrf8beuGi3sx4acWv1r/U88e+cfY92deZ558LRqdtr/vV8Ns2uFe2/amYbmvbbR+I78jMbLjgo2e59e/LJngppavERudip4Wy1IObt6YaT1ggEQIWSISABRIhYIFECFggkTBLXJV+VjUq61IW/m9ArcrKBFmyRXclUPufRt2Jj2qNyJSPdvxMppnZzlWd0Z1l/fw5t/2nly/LY/riJYlh7S/+/8dv/7Xs69yZM8HotMvn/fFduarHPRKfdTDyM7fRVqp1ozPIkXqBBftt4d9f6uWSqK8og+z+/1z/DeBjRcACiRCwQCIELJAIAQskEmaJ68rPbjVRWZdGrA0W2dYwGydKccyiStjEJWf8zF8pLlG/0+M+d/p0cJ7YU9971G3f3tTZ1rMv+8W6d3f9z/vmay/LvgYLZuabkX9PnDvvl44xM1v/8Qtue7Wz67ZPVCrfzCbNzBrtrlaknsPexFpxfQwlYoD/lwhYIBECFkiEgAUSIWCBRAhYIJG4RIxIo0fTLZ2a8hHp61LuJ2tWiBcJZqkqkaov/NIeZmZV6V+KfZX21zNbdvmdt/UfZ7j0hj8l1OxfkcfsnXvXP6b0940dFrqEzfDAgWB02uqyv/vAtqjub2Z25aw/5bMs7pWJeJnBzMyqgf5boOj7+/9ao7/gqvCny8rKv4c68bKAmVkrpjsVnrBAIgQskAgBCyRCwAKJELBAIsWiZVgAfPR4wgKJELBAIgQskAgBCyRCwAKJELBAIuHi/6//1hfdOZ/JRNdGmoq9Y9Ui5yKofK7qPf3t0y+EJXe++oW73HFHC61L8du1KfZrXb3jM7KvqViI/t2/+auZhYeOnzjpjn1/Q+9H24oaQ10hFqMHU3mrB65z219+8dlw7H/6F990O107tiaPefefvu+2D9Yvuu2Tnv7+KvFiwLceOxWO+2sPPeCOuwv2+FXXu+38Rf5NsGVBJ+7J7zzxuDtunrBAIgQskAgBCyRCwAKJELBAImGWeF9kg5sgg6Z+A6YiMxlU4rAiqPQe2RfDi85Vlf74xmIv3EkwtMPXH9N/nGH10CG3fW9zQx6zvOJnpZup/4HbYOeGleUVPbhAX+yzOrqiS9vsjvbcdnVtR42+73pB2ZvIrtrrNdiRohOli6Yi+R6NrJlzdwuesEAiBCyQCAELJELAAokQsEAiBCyQSDitsyfy0V2wmXFV+WnysUiFT8QCdTOzdsF6UzulqAIf/DxV5k9LTEXafXtrW/Y1sXP6RDOsb/jTIMNlUaHezA6s+Qvs1a4K29tbsq9gNiM0FtdjVIzlMa3aWWIopqlM79zQtuGtLO1M/ZsiuvX04n8RMGLK0Mxs3IoN0AWesEAiBCyQCAELJELAAokQsEAiYWpt0vPLbjTR3pkiS9zWKkusM3/Nglni6WDJ7y9cPD7fQvki+K27dOF8MLrY5St+eZRbb7xJHlP2/GtYqvI7Yv/cDw5aLE3cjvfd9t3prjxmdzRy29X+q3viRQwzs54ozzLLXiNeSpnqe6UT42g7P+Nb9/T1bqv5rjdPWCARAhZIhIAFEiFggUQIWCCRMEs8Eut/i16QkRNZYlVWo2mDLNmC61qt9rOmnQUF0NW6VlFIvAtKe9SLLsg1swMHV/1xFPp8u/t+htZENnNPZGfN9NrpWeqhfyvVE32L7ez5JWKGtbh+Pd1XGWW+A+K2tC4oOaMK3Nfm3/tVcD/0gs/k4QkLJELAAokQsEAiBCyQCAELJELAAomEOeVpJRbmB4vyW1FJXdUeKetoGmGx6ZG6J45TOXwzm4iyH404ZisoEVMuVq3EzMxW1pbd9lYsUjczm079MixVrabY9PnHYn/fWfY7f6qoXtIvdwyHftmbFTEtN6n0NSjEzgOz1KJ8S6GmlkzvgWzi5ZJSxYSZFcGexW5fc/03gI8VAQskQsACiRCwQCIELJBI0S1YhgXAR48nLJAIAQskQsACiRCwQCIELJAIAQskEi5T/80vPeDO+aj9Mc3MKlFtvhDtXbD4We0i8Phj/xy+FfA7D3/FHfdkovfibEX9I7VZwN6OrovUdv7i8BefeWbm2wwnv/zb7kBWV/xaT2ZmO1t+dX21Q8POzo7sqxTX/KVnnw3H/vAffc0ddxfsJLDxvr9DQk88R7pgn9VS3EeP/+vj4bgffOhBt9PpVL8EMRI1sdS164mXGcz0d/SDJ55wx80TFkiEgAUSIWCBRAhYIBECFkgkzBIPh4O5O1SZXVUtPco4L0qdS43NzETNdrPS/CxeoxN/Nh4v/pmGtb8nb6/UY19Z9kutqGxm1+rvtQzK6EQ2zr7vtkd78ioTMaMwKPVFn7PSys80U//77YJxV+K7KCsRTsGuBJOJX95H4QkLJELAAokQsEAiBCyQCAELJELAAomE0zpywX4wFaMWMy9CTc/MoqaKov6ixd6epaUl+bd+35+auRZbW1vyb+rzqnpdvZ6eHinFdz7LIpXB1DSbGsM0uLfKBe8V9UJI+HnEde3EUVHdtGiq0cMTFkiEgAUSIWCBRAhYIBECFkgkzBKP9vfd9iiTqDJi82bDor5mkZm/aF9bkWlVGdXwRYIFPut/UZnsKMM9bzY9yhIves3VgnjVbqbvI9Wuyg+ZLf4SSSn20I3Icy3w3ZElBv4PI2CBRAhYIBECFkiEgAUSCbPEKoMVZRLnXYsareGNCn8v0meUHVV/mzeTea0WyTCrsYzHfvmRaL13vWCGe97SQGb6Pqpr/7aMrvl0rAu7RzpRvqVr9T3eqWL54qNGGex5s/I8YYFECFggEQIWSISABRIhYIFECFggkXBaZzDwK8Sr6QKz+cuzqBT+tVBTNNG5fpE7Eyxa2sZMT11E6X91PlWqJprWWfTFheHQ331gkZcJ1DF7I/9lFDMzC/ahDamq/EXwvXf+udSuCdHI5p265AkLJELAAokQsEAiBCyQCAELJFIsWhIEwEePJyyQCAELJELAAokQsEAiBCyQCAELJPKfFLUViljL+ZsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 288x288 with 25 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = int(np.sqrt(patches.shape[1]))\n",
    "plt.figure(figsize=(4, 4))\n",
    "for i, patch in enumerate(patches[0]):\n",
    "    ax = plt.subplot(n, n, i + 1)\n",
    "    patch_img = tf.reshape(patch, (patch_size, patch_size, 3))\n",
    "    plt.imshow(patch_img.numpy().astype(\"uint8\"))\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64743dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchEncoder(layers.Layer):\n",
    "    def __init__(self, num_patches, projection_dim):\n",
    "        super(PatchEncoder, self).__init__()\n",
    "        self.num_patches = num_patches\n",
    "        self.projection = layers.Dense(units=projection_dim)\n",
    "        self.position_embedding = layers.Embedding(\n",
    "            input_dim=num_patches, output_dim=projection_dim\n",
    "        )\n",
    "\n",
    "    def call(self, patch):\n",
    "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
    "        encoded = self.projection(patch) + self.position_embedding(positions)\n",
    "        return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3431a5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(x, hidden_units, dropout_rate):\n",
    "    for units in hidden_units:\n",
    "        x = layers.Dense(units, activation=tf.nn.gelu)(x)\n",
    "        x = layers.Dropout(dropout_rate)(x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ebf8c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vit_classifier(vit_base_model_input_shape = (32, 32, 3)):\n",
    "    \n",
    "    inputs = layers.Input(shape=vit_base_model_input_shape)\n",
    "    # Augment data.\n",
    "    augmented = data_augmentation(inputs)\n",
    "    # Create patches.\n",
    "    patches = Patches(patch_size)(augmented)\n",
    "    # Encode patches.\n",
    "    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n",
    "\n",
    "    # Create multiple layers of the Transformer block.\n",
    "    for _ in range(transformer_layers):\n",
    "        # Layer normalization 1.\n",
    "        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "        # Create a multi-head attention layer.\n",
    "        attention_output = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n",
    "        )(x1, x1)\n",
    "        # Skip connection 1.\n",
    "        x2 = layers.Add()([attention_output, encoded_patches])\n",
    "        # Layer normalization 2.\n",
    "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "        # MLP.\n",
    "        x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1) # x3 = residual_mlp\n",
    "        # Skip connection 2.\n",
    "        encoded_patches = layers.Add()([x3, x2])\n",
    "\n",
    "    # Create a [batch_size, projection_dim] tensor.\n",
    "    representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "    representation = layers.Flatten()(representation)\n",
    "    #representation = layers.Dropout(0.5)(representation)\n",
    "    # Add MLP.\n",
    "    #features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=0.5)\n",
    "    # Classify outputs.\n",
    "    #logits = layers.Dense(num_classes)(features)\n",
    "    # Create the Keras model.\n",
    "    \n",
    "    model = keras.Model(inputs=inputs, outputs=representation)\n",
    "    return model\n",
    "    \n",
    "    #model = keras.Model(inputs=inputs, outputs=logits)\n",
    "    #return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "85af28b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_vit_model = create_vit_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "32062384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 1600), dtype=float32, numpy=\n",
       "array([[-0.09727544,  1.6115226 , -0.46556753, ..., -0.6117518 ,\n",
       "         0.386052  ,  0.4638875 ],\n",
       "       [ 0.0478394 ,  1.3095338 , -0.14043686, ..., -0.7465946 ,\n",
       "         1.7200768 , -0.7503596 ],\n",
       "       [ 0.47747993, -0.7891516 ,  0.03886205, ..., -0.66376525,\n",
       "        -2.072488  , -0.46693614],\n",
       "       [-0.49440977,  1.2774639 , -0.6329081 , ..., -0.88322115,\n",
       "        -2.0715237 , -0.3199136 ],\n",
       "       [-0.04102761,  0.79456884,  0.39641708, ..., -0.34075403,\n",
       "        -2.3133526 ,  0.11952156]], dtype=float32)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_vit_model(x_train[:5])  # (tf.keras.layers.Resizing(600,600)(x_train[:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0cd76a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_mlp = ResidualMLP(problem_type = 'classification', #\n",
    "                      learning_rate = .0007, #\n",
    "                      input_shape = (32, 32, 3), #(32,32,3), #\n",
    "                      bw_images = False, #\n",
    "                      base_model = base_vit_model, #\n",
    "                      base_model_input_shape = (32, 32, 3),  # (600,600,3), #\n",
    "                      flatten_after_base_model = True, #\n",
    "                      blocks = [[7, 75, 8], [5, 75, 10]], #\n",
    "                      residual_bypass_dense_layers = [[5],[5]], #\n",
    "                      b_norm_or_dropout_residual_bypass_layers = 'dropout', #\n",
    "                      dropout_rate_for_bypass_layers = .7, #\n",
    "                      inter_block_layers_per_block = [10],\n",
    "                      b_norm_or_dropout_last_layers = 'dropout', # | 'bnorm'\n",
    "                      dropout_rate = .18, #\n",
    "                      activation = tf.keras.activations.relu, #\n",
    "                      final_dense_layers = [15], #\n",
    "                      number_of_classes = 10, # 1 if a regression problem\n",
    "                      # final_activation = tf.keras.activations.softmax, #\n",
    "                      #loss = tf.keras.losses.CategoricalCrossentropy(\n",
    "                      #    from_logits=False)\n",
    "                     )\n",
    "final_residual_mlp = res_mlp.make_tandem_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5535dafc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "resizing_2 (Resizing)           (None, 32, 32, 3)    0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model (Functional)              (None, 1600)         424711      resizing_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_28 (Dense)                (None, 75)           120075      model[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 75)           300         dense_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_30 (Dense)                (None, 75)           5700        batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 75)           300         dense_30[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_31 (Dense)                (None, 67)           5092        batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 67)           268         dense_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_32 (Dense)                (None, 59)           4012        batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 59)           236         dense_32[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_33 (Dense)                (None, 51)           3060        batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 51)           204         dense_33[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_34 (Dense)                (None, 43)           2236        batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 43)           172         dense_34[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_35 (Dense)                (None, 35)           1540        batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 35)           140         dense_35[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 75)           0           dense_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_36 (Dense)                (None, 27)           972         batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_29 (Dense)                (None, 5)            380         dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 27)           108         dense_36[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 5)            0           dense_29[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 32)           0           batch_normalization_21[0][0]     \n",
      "                                                                 dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_37 (Dense)                (None, 10)           330         concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 10)           40          dense_37[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_38 (Dense)                (None, 75)           825         batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 75)           300         dense_38[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_40 (Dense)                (None, 75)           5700        batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 75)           300         dense_40[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_41 (Dense)                (None, 65)           4940        batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 65)           260         dense_41[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_42 (Dense)                (None, 55)           3630        batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 55)           220         dense_42[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_43 (Dense)                (None, 45)           2520        batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 45)           180         dense_43[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 75)           0           dense_38[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_44 (Dense)                (None, 35)           1610        batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_39 (Dense)                (None, 5)            380         dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 35)           140         dense_44[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 5)            0           dense_39[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 40)           0           batch_normalization_28[0][0]     \n",
      "                                                                 dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_45 (Dense)                (None, 15)           615         concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 15)           0           dense_45[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_46 (Dense)                (None, 10)           160         dropout_18[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 591,656\n",
      "Trainable params: 590,065\n",
      "Non-trainable params: 1,591\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "final_residual_mlp.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cd982210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 10), dtype=float32, numpy=\n",
       "array([[0.09274495, 0.10671546, 0.09974094, 0.09812085, 0.10449032,\n",
       "        0.10263701, 0.10432842, 0.10052697, 0.09261233, 0.09808278],\n",
       "       [0.09652878, 0.10207502, 0.09861594, 0.10098285, 0.10285988,\n",
       "        0.10386762, 0.10246638, 0.10042907, 0.09345301, 0.09872147],\n",
       "       [0.09895775, 0.10083399, 0.10023838, 0.1002166 , 0.10113764,\n",
       "        0.10069874, 0.10044153, 0.10002398, 0.09763651, 0.09981488],\n",
       "       [0.09793693, 0.1006134 , 0.09713675, 0.09949279, 0.10072916,\n",
       "        0.10503311, 0.1043585 , 0.10058363, 0.09611925, 0.09799642],\n",
       "       [0.09273021, 0.10635521, 0.10123222, 0.09948187, 0.10414969,\n",
       "        0.1007592 , 0.10405938, 0.10031112, 0.09193686, 0.0989842 ]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's verify that this beast can accept inputs and return a valid response ...\n",
    "\n",
    "final_residual_mlp(x_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1b3f063f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-14 05:39:16.579221: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n",
      "2022-01-14 05:39:16.579276: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Layer Patches has arguments in `__init__` and therefore must override `get_config`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-14 05:39:16.769732: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n",
      "2022-01-14 05:39:16.769951: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1749] CUPTI activity buffer flushed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " 1/70 [..............................] - ETA: 11:03 - loss: 2.4318 - top_1_categorical_accuracy: 0.1000 - top_2_categorical_accuracy: 0.2400 - top_3_categorical_accuracy: 0.3800 - top_4_categorical_accuracy: 0.5400 - top_5_categorical_accuracy: 0.6200 - top_6_categorical_accuracy: 0.6600 - top_7_categorical_accuracy: 0.7400 - top_8_categorical_accuracy: 0.8600 - top_9_categorical_accuracy: 0.9000 - precision_1: 0.2857 - recall_1: 0.0400 - accuracy: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-14 05:39:26.821477: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n",
      "2022-01-14 05:39:26.821543: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 2/70 [..............................] - ETA: 50s - loss: 2.4949 - top_1_categorical_accuracy: 0.1100 - top_2_categorical_accuracy: 0.2200 - top_3_categorical_accuracy: 0.3600 - top_4_categorical_accuracy: 0.4900 - top_5_categorical_accuracy: 0.6100 - top_6_categorical_accuracy: 0.6900 - top_7_categorical_accuracy: 0.7600 - top_8_categorical_accuracy: 0.8300 - top_9_categorical_accuracy: 0.9200 - precision_1: 0.1429 - recall_1: 0.0200 - accuracy: 0.0000e+00  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-14 05:39:27.936020: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2022-01-14 05:39:27.940790: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1749] CUPTI activity buffer flushed\n",
      "2022-01-14 05:39:28.006077: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:673]  GpuTracer has collected 3463 callback api events and 3480 activity events. \n",
      "2022-01-14 05:39:28.104711: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n",
      "2022-01-14 05:39:28.235577: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: logs/vit-ResidualMLP-image-classifier_2022-01-14_05_39_TB/train/plugins/profile/2022_01_14_05_39_28\n",
      "\n",
      "2022-01-14 05:39:28.297318: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to logs/vit-ResidualMLP-image-classifier_2022-01-14_05_39_TB/train/plugins/profile/2022_01_14_05_39_28/n7rz6l6tbj.trace.json.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5/70 [=>............................] - ETA: 34s - loss: 2.5711 - top_1_categorical_accuracy: 0.1000 - top_2_categorical_accuracy: 0.2040 - top_3_categorical_accuracy: 0.3280 - top_4_categorical_accuracy: 0.4480 - top_5_categorical_accuracy: 0.5440 - top_6_categorical_accuracy: 0.6360 - top_7_categorical_accuracy: 0.7240 - top_8_categorical_accuracy: 0.7960 - top_9_categorical_accuracy: 0.8960 - precision_1: 0.1111 - recall_1: 0.0080 - accuracy: 0.0000e+00 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-14 05:39:28.459711: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: logs/vit-ResidualMLP-image-classifier_2022-01-14_05_39_TB/train/plugins/profile/2022_01_14_05_39_28\n",
      "\n",
      "2022-01-14 05:39:28.467053: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to logs/vit-ResidualMLP-image-classifier_2022-01-14_05_39_TB/train/plugins/profile/2022_01_14_05_39_28/n7rz6l6tbj.memory_profile.json.gz\n",
      "2022-01-14 05:39:28.477642: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: logs/vit-ResidualMLP-image-classifier_2022-01-14_05_39_TB/train/plugins/profile/2022_01_14_05_39_28\n",
      "Dumped tool data for xplane.pb to logs/vit-ResidualMLP-image-classifier_2022-01-14_05_39_TB/train/plugins/profile/2022_01_14_05_39_28/n7rz6l6tbj.xplane.pb\n",
      "Dumped tool data for overview_page.pb to logs/vit-ResidualMLP-image-classifier_2022-01-14_05_39_TB/train/plugins/profile/2022_01_14_05_39_28/n7rz6l6tbj.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to logs/vit-ResidualMLP-image-classifier_2022-01-14_05_39_TB/train/plugins/profile/2022_01_14_05_39_28/n7rz6l6tbj.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to logs/vit-ResidualMLP-image-classifier_2022-01-14_05_39_TB/train/plugins/profile/2022_01_14_05_39_28/n7rz6l6tbj.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to logs/vit-ResidualMLP-image-classifier_2022-01-14_05_39_TB/train/plugins/profile/2022_01_14_05_39_28/n7rz6l6tbj.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - 16s 98ms/step - loss: 2.5070 - top_1_categorical_accuracy: 0.0974 - top_2_categorical_accuracy: 0.2083 - top_3_categorical_accuracy: 0.3097 - top_4_categorical_accuracy: 0.4166 - top_5_categorical_accuracy: 0.5163 - top_6_categorical_accuracy: 0.6123 - top_7_categorical_accuracy: 0.7094 - top_8_categorical_accuracy: 0.8154 - top_9_categorical_accuracy: 0.9066 - precision_1: 0.1316 - recall_1: 0.0029 - accuracy: 0.0000e+00 - val_loss: 2.3020 - val_top_1_categorical_accuracy: 0.1033 - val_top_2_categorical_accuracy: 0.2187 - val_top_3_categorical_accuracy: 0.3347 - val_top_4_categorical_accuracy: 0.4200 - val_top_5_categorical_accuracy: 0.5193 - val_top_6_categorical_accuracy: 0.6140 - val_top_7_categorical_accuracy: 0.6940 - val_top_8_categorical_accuracy: 0.7927 - val_top_9_categorical_accuracy: 0.8807 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "70/70 [==============================] - 3s 50ms/step - loss: 2.3752 - top_1_categorical_accuracy: 0.1160 - top_2_categorical_accuracy: 0.2317 - top_3_categorical_accuracy: 0.3334 - top_4_categorical_accuracy: 0.4366 - top_5_categorical_accuracy: 0.5394 - top_6_categorical_accuracy: 0.6314 - top_7_categorical_accuracy: 0.7283 - top_8_categorical_accuracy: 0.8257 - top_9_categorical_accuracy: 0.9106 - precision_1: 0.2857 - recall_1: 0.0011 - accuracy: 0.0000e+00 - val_loss: 2.3051 - val_top_1_categorical_accuracy: 0.0967 - val_top_2_categorical_accuracy: 0.1993 - val_top_3_categorical_accuracy: 0.3007 - val_top_4_categorical_accuracy: 0.3927 - val_top_5_categorical_accuracy: 0.4747 - val_top_6_categorical_accuracy: 0.5907 - val_top_7_categorical_accuracy: 0.7107 - val_top_8_categorical_accuracy: 0.8153 - val_top_9_categorical_accuracy: 0.9107 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "70/70 [==============================] - 3s 49ms/step - loss: 2.3413 - top_1_categorical_accuracy: 0.1300 - top_2_categorical_accuracy: 0.2431 - top_3_categorical_accuracy: 0.3431 - top_4_categorical_accuracy: 0.4400 - top_5_categorical_accuracy: 0.5380 - top_6_categorical_accuracy: 0.6354 - top_7_categorical_accuracy: 0.7329 - top_8_categorical_accuracy: 0.8271 - top_9_categorical_accuracy: 0.9129 - precision_1: 0.0000e+00 - recall_1: 0.0000e+00 - accuracy: 0.0000e+00 - val_loss: 2.3066 - val_top_1_categorical_accuracy: 0.1133 - val_top_2_categorical_accuracy: 0.2193 - val_top_3_categorical_accuracy: 0.3093 - val_top_4_categorical_accuracy: 0.3993 - val_top_5_categorical_accuracy: 0.4913 - val_top_6_categorical_accuracy: 0.5927 - val_top_7_categorical_accuracy: 0.7040 - val_top_8_categorical_accuracy: 0.8060 - val_top_9_categorical_accuracy: 0.9060 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "70/70 [==============================] - 3s 48ms/step - loss: 2.3458 - top_1_categorical_accuracy: 0.1100 - top_2_categorical_accuracy: 0.2203 - top_3_categorical_accuracy: 0.3183 - top_4_categorical_accuracy: 0.4180 - top_5_categorical_accuracy: 0.5180 - top_6_categorical_accuracy: 0.6137 - top_7_categorical_accuracy: 0.7097 - top_8_categorical_accuracy: 0.8074 - top_9_categorical_accuracy: 0.9074 - precision_1: 0.0000e+00 - recall_1: 0.0000e+00 - accuracy: 0.0000e+00 - val_loss: 2.2807 - val_top_1_categorical_accuracy: 0.1480 - val_top_2_categorical_accuracy: 0.2780 - val_top_3_categorical_accuracy: 0.3860 - val_top_4_categorical_accuracy: 0.4913 - val_top_5_categorical_accuracy: 0.5713 - val_top_6_categorical_accuracy: 0.6633 - val_top_7_categorical_accuracy: 0.7553 - val_top_8_categorical_accuracy: 0.8453 - val_top_9_categorical_accuracy: 0.9287 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "70/70 [==============================] - 3s 48ms/step - loss: 2.2918 - top_1_categorical_accuracy: 0.1311 - top_2_categorical_accuracy: 0.2591 - top_3_categorical_accuracy: 0.3697 - top_4_categorical_accuracy: 0.4714 - top_5_categorical_accuracy: 0.5583 - top_6_categorical_accuracy: 0.6489 - top_7_categorical_accuracy: 0.7389 - top_8_categorical_accuracy: 0.8323 - top_9_categorical_accuracy: 0.9186 - precision_1: 0.5000 - recall_1: 2.8571e-04 - accuracy: 0.0000e+00 - val_loss: 2.2409 - val_top_1_categorical_accuracy: 0.1547 - val_top_2_categorical_accuracy: 0.3013 - val_top_3_categorical_accuracy: 0.4240 - val_top_4_categorical_accuracy: 0.5247 - val_top_5_categorical_accuracy: 0.6047 - val_top_6_categorical_accuracy: 0.6793 - val_top_7_categorical_accuracy: 0.7873 - val_top_8_categorical_accuracy: 0.8647 - val_top_9_categorical_accuracy: 0.9393 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "70/70 [==============================] - 3s 49ms/step - loss: 2.2562 - top_1_categorical_accuracy: 0.1514 - top_2_categorical_accuracy: 0.2829 - top_3_categorical_accuracy: 0.3834 - top_4_categorical_accuracy: 0.4849 - top_5_categorical_accuracy: 0.5777 - top_6_categorical_accuracy: 0.6731 - top_7_categorical_accuracy: 0.7626 - top_8_categorical_accuracy: 0.8494 - top_9_categorical_accuracy: 0.9283 - precision_1: 0.8000 - recall_1: 0.0011 - accuracy: 0.0000e+00 - val_loss: 2.2906 - val_top_1_categorical_accuracy: 0.1200 - val_top_2_categorical_accuracy: 0.2260 - val_top_3_categorical_accuracy: 0.3180 - val_top_4_categorical_accuracy: 0.4300 - val_top_5_categorical_accuracy: 0.5207 - val_top_6_categorical_accuracy: 0.6120 - val_top_7_categorical_accuracy: 0.7067 - val_top_8_categorical_accuracy: 0.8060 - val_top_9_categorical_accuracy: 0.9173 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "70/70 [==============================] - 3s 50ms/step - loss: 2.2273 - top_1_categorical_accuracy: 0.1640 - top_2_categorical_accuracy: 0.3020 - top_3_categorical_accuracy: 0.4120 - top_4_categorical_accuracy: 0.5086 - top_5_categorical_accuracy: 0.5931 - top_6_categorical_accuracy: 0.6869 - top_7_categorical_accuracy: 0.7737 - top_8_categorical_accuracy: 0.8563 - top_9_categorical_accuracy: 0.9323 - precision_1: 0.3846 - recall_1: 0.0014 - accuracy: 0.0000e+00 - val_loss: 2.2339 - val_top_1_categorical_accuracy: 0.1560 - val_top_2_categorical_accuracy: 0.2893 - val_top_3_categorical_accuracy: 0.3940 - val_top_4_categorical_accuracy: 0.4713 - val_top_5_categorical_accuracy: 0.5633 - val_top_6_categorical_accuracy: 0.6613 - val_top_7_categorical_accuracy: 0.7507 - val_top_8_categorical_accuracy: 0.8467 - val_top_9_categorical_accuracy: 0.9473 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "70/70 [==============================] - 3s 50ms/step - loss: 2.1724 - top_1_categorical_accuracy: 0.1840 - top_2_categorical_accuracy: 0.3437 - top_3_categorical_accuracy: 0.4623 - top_4_categorical_accuracy: 0.5600 - top_5_categorical_accuracy: 0.6549 - top_6_categorical_accuracy: 0.7377 - top_7_categorical_accuracy: 0.8169 - top_8_categorical_accuracy: 0.8931 - top_9_categorical_accuracy: 0.9543 - precision_1: 0.4857 - recall_1: 0.0049 - accuracy: 0.0000e+00 - val_loss: 2.1645 - val_top_1_categorical_accuracy: 0.1980 - val_top_2_categorical_accuracy: 0.3433 - val_top_3_categorical_accuracy: 0.4767 - val_top_4_categorical_accuracy: 0.5653 - val_top_5_categorical_accuracy: 0.6527 - val_top_6_categorical_accuracy: 0.7327 - val_top_7_categorical_accuracy: 0.8153 - val_top_8_categorical_accuracy: 0.8980 - val_top_9_categorical_accuracy: 0.9627 - val_precision_1: 0.5773 - val_recall_1: 0.0373 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - 4s 51ms/step - loss: 2.1550 - top_1_categorical_accuracy: 0.1894 - top_2_categorical_accuracy: 0.3471 - top_3_categorical_accuracy: 0.4729 - top_4_categorical_accuracy: 0.5731 - top_5_categorical_accuracy: 0.6666 - top_6_categorical_accuracy: 0.7557 - top_7_categorical_accuracy: 0.8326 - top_8_categorical_accuracy: 0.8920 - top_9_categorical_accuracy: 0.9560 - precision_1: 0.5085 - recall_1: 0.0086 - accuracy: 0.0000e+00 - val_loss: 2.1797 - val_top_1_categorical_accuracy: 0.1940 - val_top_2_categorical_accuracy: 0.3607 - val_top_3_categorical_accuracy: 0.4673 - val_top_4_categorical_accuracy: 0.5540 - val_top_5_categorical_accuracy: 0.6400 - val_top_6_categorical_accuracy: 0.7173 - val_top_7_categorical_accuracy: 0.8013 - val_top_8_categorical_accuracy: 0.8820 - val_top_9_categorical_accuracy: 0.9527 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "70/70 [==============================] - 4s 53ms/step - loss: 2.1386 - top_1_categorical_accuracy: 0.1911 - top_2_categorical_accuracy: 0.3594 - top_3_categorical_accuracy: 0.4897 - top_4_categorical_accuracy: 0.5911 - top_5_categorical_accuracy: 0.6900 - top_6_categorical_accuracy: 0.7729 - top_7_categorical_accuracy: 0.8394 - top_8_categorical_accuracy: 0.9006 - top_9_categorical_accuracy: 0.9589 - precision_1: 0.3913 - recall_1: 0.0051 - accuracy: 0.0000e+00 - val_loss: 2.1938 - val_top_1_categorical_accuracy: 0.1840 - val_top_2_categorical_accuracy: 0.2940 - val_top_3_categorical_accuracy: 0.4027 - val_top_4_categorical_accuracy: 0.5047 - val_top_5_categorical_accuracy: 0.6267 - val_top_6_categorical_accuracy: 0.7193 - val_top_7_categorical_accuracy: 0.8033 - val_top_8_categorical_accuracy: 0.8673 - val_top_9_categorical_accuracy: 0.9340 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "70/70 [==============================] - 4s 53ms/step - loss: 2.1051 - top_1_categorical_accuracy: 0.2086 - top_2_categorical_accuracy: 0.3717 - top_3_categorical_accuracy: 0.5051 - top_4_categorical_accuracy: 0.6123 - top_5_categorical_accuracy: 0.7071 - top_6_categorical_accuracy: 0.8014 - top_7_categorical_accuracy: 0.8611 - top_8_categorical_accuracy: 0.9123 - top_9_categorical_accuracy: 0.9626 - precision_1: 0.5595 - recall_1: 0.0134 - accuracy: 0.0000e+00 - val_loss: 2.1645 - val_top_1_categorical_accuracy: 0.1953 - val_top_2_categorical_accuracy: 0.3320 - val_top_3_categorical_accuracy: 0.4540 - val_top_4_categorical_accuracy: 0.5613 - val_top_5_categorical_accuracy: 0.6640 - val_top_6_categorical_accuracy: 0.7560 - val_top_7_categorical_accuracy: 0.8333 - val_top_8_categorical_accuracy: 0.8947 - val_top_9_categorical_accuracy: 0.9520 - val_precision_1: 0.8000 - val_recall_1: 0.0053 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "70/70 [==============================] - 3s 46ms/step - loss: 2.0825 - top_1_categorical_accuracy: 0.2200 - top_2_categorical_accuracy: 0.3843 - top_3_categorical_accuracy: 0.5209 - top_4_categorical_accuracy: 0.6377 - top_5_categorical_accuracy: 0.7286 - top_6_categorical_accuracy: 0.8129 - top_7_categorical_accuracy: 0.8669 - top_8_categorical_accuracy: 0.9183 - top_9_categorical_accuracy: 0.9691 - precision_1: 0.5547 - recall_1: 0.0217 - accuracy: 0.0000e+00 - val_loss: 2.1332 - val_top_1_categorical_accuracy: 0.1980 - val_top_2_categorical_accuracy: 0.3580 - val_top_3_categorical_accuracy: 0.4887 - val_top_4_categorical_accuracy: 0.6047 - val_top_5_categorical_accuracy: 0.6880 - val_top_6_categorical_accuracy: 0.7713 - val_top_7_categorical_accuracy: 0.8320 - val_top_8_categorical_accuracy: 0.9007 - val_top_9_categorical_accuracy: 0.9513 - val_precision_1: 0.6757 - val_recall_1: 0.0167 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "70/70 [==============================] - 4s 52ms/step - loss: 2.0701 - top_1_categorical_accuracy: 0.2060 - top_2_categorical_accuracy: 0.3849 - top_3_categorical_accuracy: 0.5214 - top_4_categorical_accuracy: 0.6400 - top_5_categorical_accuracy: 0.7329 - top_6_categorical_accuracy: 0.8171 - top_7_categorical_accuracy: 0.8694 - top_8_categorical_accuracy: 0.9189 - top_9_categorical_accuracy: 0.9671 - precision_1: 0.5252 - recall_1: 0.0209 - accuracy: 0.0000e+00 - val_loss: 2.1788 - val_top_1_categorical_accuracy: 0.1960 - val_top_2_categorical_accuracy: 0.3520 - val_top_3_categorical_accuracy: 0.4827 - val_top_4_categorical_accuracy: 0.5920 - val_top_5_categorical_accuracy: 0.7093 - val_top_6_categorical_accuracy: 0.8113 - val_top_7_categorical_accuracy: 0.8667 - val_top_8_categorical_accuracy: 0.9073 - val_top_9_categorical_accuracy: 0.9660 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "70/70 [==============================] - 4s 51ms/step - loss: 2.0488 - top_1_categorical_accuracy: 0.2211 - top_2_categorical_accuracy: 0.4206 - top_3_categorical_accuracy: 0.5531 - top_4_categorical_accuracy: 0.6554 - top_5_categorical_accuracy: 0.7437 - top_6_categorical_accuracy: 0.8266 - top_7_categorical_accuracy: 0.8811 - top_8_categorical_accuracy: 0.9326 - top_9_categorical_accuracy: 0.9729 - precision_1: 0.3913 - recall_1: 0.0154 - accuracy: 0.0000e+00 - val_loss: 2.0686 - val_top_1_categorical_accuracy: 0.2333 - val_top_2_categorical_accuracy: 0.4053 - val_top_3_categorical_accuracy: 0.5213 - val_top_4_categorical_accuracy: 0.6340 - val_top_5_categorical_accuracy: 0.7247 - val_top_6_categorical_accuracy: 0.8193 - val_top_7_categorical_accuracy: 0.8760 - val_top_8_categorical_accuracy: 0.9247 - val_top_9_categorical_accuracy: 0.9740 - val_precision_1: 0.6000 - val_recall_1: 0.0020 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "70/70 [==============================] - 4s 52ms/step - loss: 2.0148 - top_1_categorical_accuracy: 0.2411 - top_2_categorical_accuracy: 0.4317 - top_3_categorical_accuracy: 0.5651 - top_4_categorical_accuracy: 0.6749 - top_5_categorical_accuracy: 0.7663 - top_6_categorical_accuracy: 0.8366 - top_7_categorical_accuracy: 0.8846 - top_8_categorical_accuracy: 0.9309 - top_9_categorical_accuracy: 0.9737 - precision_1: 0.5301 - recall_1: 0.0126 - accuracy: 0.0000e+00 - val_loss: 1.9858 - val_top_1_categorical_accuracy: 0.2587 - val_top_2_categorical_accuracy: 0.4653 - val_top_3_categorical_accuracy: 0.5833 - val_top_4_categorical_accuracy: 0.6887 - val_top_5_categorical_accuracy: 0.7633 - val_top_6_categorical_accuracy: 0.8527 - val_top_7_categorical_accuracy: 0.8973 - val_top_8_categorical_accuracy: 0.9347 - val_top_9_categorical_accuracy: 0.9807 - val_precision_1: 0.6667 - val_recall_1: 0.0213 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "70/70 [==============================] - 3s 50ms/step - loss: 1.9990 - top_1_categorical_accuracy: 0.2411 - top_2_categorical_accuracy: 0.4351 - top_3_categorical_accuracy: 0.5714 - top_4_categorical_accuracy: 0.6811 - top_5_categorical_accuracy: 0.7677 - top_6_categorical_accuracy: 0.8457 - top_7_categorical_accuracy: 0.8860 - top_8_categorical_accuracy: 0.9317 - top_9_categorical_accuracy: 0.9749 - precision_1: 0.4726 - recall_1: 0.0197 - accuracy: 0.0000e+00 - val_loss: 2.0046 - val_top_1_categorical_accuracy: 0.2740 - val_top_2_categorical_accuracy: 0.4553 - val_top_3_categorical_accuracy: 0.5753 - val_top_4_categorical_accuracy: 0.6867 - val_top_5_categorical_accuracy: 0.7867 - val_top_6_categorical_accuracy: 0.8753 - val_top_7_categorical_accuracy: 0.9087 - val_top_8_categorical_accuracy: 0.9380 - val_top_9_categorical_accuracy: 0.9807 - val_precision_1: 0.5235 - val_recall_1: 0.0593 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "70/70 [==============================] - 4s 51ms/step - loss: 1.9450 - top_1_categorical_accuracy: 0.2674 - top_2_categorical_accuracy: 0.4617 - top_3_categorical_accuracy: 0.5949 - top_4_categorical_accuracy: 0.7089 - top_5_categorical_accuracy: 0.7931 - top_6_categorical_accuracy: 0.8643 - top_7_categorical_accuracy: 0.9074 - top_8_categorical_accuracy: 0.9440 - top_9_categorical_accuracy: 0.9800 - precision_1: 0.5846 - recall_1: 0.0326 - accuracy: 0.0000e+00 - val_loss: 1.9596 - val_top_1_categorical_accuracy: 0.2787 - val_top_2_categorical_accuracy: 0.4833 - val_top_3_categorical_accuracy: 0.5867 - val_top_4_categorical_accuracy: 0.6940 - val_top_5_categorical_accuracy: 0.7893 - val_top_6_categorical_accuracy: 0.8647 - val_top_7_categorical_accuracy: 0.9167 - val_top_8_categorical_accuracy: 0.9420 - val_top_9_categorical_accuracy: 0.9807 - val_precision_1: 0.5610 - val_recall_1: 0.0613 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/100\n",
      "70/70 [==============================] - 3s 47ms/step - loss: 1.8893 - top_1_categorical_accuracy: 0.2889 - top_2_categorical_accuracy: 0.4854 - top_3_categorical_accuracy: 0.6191 - top_4_categorical_accuracy: 0.7280 - top_5_categorical_accuracy: 0.8094 - top_6_categorical_accuracy: 0.8731 - top_7_categorical_accuracy: 0.9149 - top_8_categorical_accuracy: 0.9494 - top_9_categorical_accuracy: 0.9783 - precision_1: 0.5675 - recall_1: 0.0469 - accuracy: 0.0000e+00 - val_loss: 1.9514 - val_top_1_categorical_accuracy: 0.2773 - val_top_2_categorical_accuracy: 0.4700 - val_top_3_categorical_accuracy: 0.5993 - val_top_4_categorical_accuracy: 0.7133 - val_top_5_categorical_accuracy: 0.8073 - val_top_6_categorical_accuracy: 0.8827 - val_top_7_categorical_accuracy: 0.9220 - val_top_8_categorical_accuracy: 0.9553 - val_top_9_categorical_accuracy: 0.9880 - val_precision_1: 0.5860 - val_recall_1: 0.0727 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "70/70 [==============================] - 3s 47ms/step - loss: 1.8844 - top_1_categorical_accuracy: 0.2880 - top_2_categorical_accuracy: 0.4983 - top_3_categorical_accuracy: 0.6286 - top_4_categorical_accuracy: 0.7311 - top_5_categorical_accuracy: 0.8060 - top_6_categorical_accuracy: 0.8746 - top_7_categorical_accuracy: 0.9146 - top_8_categorical_accuracy: 0.9474 - top_9_categorical_accuracy: 0.9803 - precision_1: 0.5788 - recall_1: 0.0671 - accuracy: 0.0000e+00 - val_loss: 1.8503 - val_top_1_categorical_accuracy: 0.2980 - val_top_2_categorical_accuracy: 0.5073 - val_top_3_categorical_accuracy: 0.6313 - val_top_4_categorical_accuracy: 0.7460 - val_top_5_categorical_accuracy: 0.8427 - val_top_6_categorical_accuracy: 0.9127 - val_top_7_categorical_accuracy: 0.9407 - val_top_8_categorical_accuracy: 0.9647 - val_top_9_categorical_accuracy: 0.9853 - val_precision_1: 0.6636 - val_recall_1: 0.0473 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "70/70 [==============================] - 3s 47ms/step - loss: 1.8425 - top_1_categorical_accuracy: 0.3023 - top_2_categorical_accuracy: 0.5077 - top_3_categorical_accuracy: 0.6440 - top_4_categorical_accuracy: 0.7474 - top_5_categorical_accuracy: 0.8243 - top_6_categorical_accuracy: 0.8934 - top_7_categorical_accuracy: 0.9326 - top_8_categorical_accuracy: 0.9589 - top_9_categorical_accuracy: 0.9834 - precision_1: 0.6077 - recall_1: 0.0766 - accuracy: 0.0000e+00 - val_loss: 1.8494 - val_top_1_categorical_accuracy: 0.2840 - val_top_2_categorical_accuracy: 0.5093 - val_top_3_categorical_accuracy: 0.6533 - val_top_4_categorical_accuracy: 0.7593 - val_top_5_categorical_accuracy: 0.8333 - val_top_6_categorical_accuracy: 0.8947 - val_top_7_categorical_accuracy: 0.9253 - val_top_8_categorical_accuracy: 0.9587 - val_top_9_categorical_accuracy: 0.9813 - val_precision_1: 0.6453 - val_recall_1: 0.0873 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "70/70 [==============================] - 4s 52ms/step - loss: 1.8427 - top_1_categorical_accuracy: 0.3054 - top_2_categorical_accuracy: 0.5146 - top_3_categorical_accuracy: 0.6569 - top_4_categorical_accuracy: 0.7489 - top_5_categorical_accuracy: 0.8254 - top_6_categorical_accuracy: 0.8911 - top_7_categorical_accuracy: 0.9223 - top_8_categorical_accuracy: 0.9569 - top_9_categorical_accuracy: 0.9829 - precision_1: 0.5670 - recall_1: 0.0737 - accuracy: 0.0000e+00 - val_loss: 1.9249 - val_top_1_categorical_accuracy: 0.2973 - val_top_2_categorical_accuracy: 0.4993 - val_top_3_categorical_accuracy: 0.6267 - val_top_4_categorical_accuracy: 0.7127 - val_top_5_categorical_accuracy: 0.7860 - val_top_6_categorical_accuracy: 0.8573 - val_top_7_categorical_accuracy: 0.8933 - val_top_8_categorical_accuracy: 0.9253 - val_top_9_categorical_accuracy: 0.9627 - val_precision_1: 0.6226 - val_recall_1: 0.1067 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "70/70 [==============================] - 3s 49ms/step - loss: 1.7979 - top_1_categorical_accuracy: 0.3269 - top_2_categorical_accuracy: 0.5423 - top_3_categorical_accuracy: 0.6717 - top_4_categorical_accuracy: 0.7674 - top_5_categorical_accuracy: 0.8391 - top_6_categorical_accuracy: 0.9049 - top_7_categorical_accuracy: 0.9340 - top_8_categorical_accuracy: 0.9611 - top_9_categorical_accuracy: 0.9846 - precision_1: 0.6301 - recall_1: 0.0837 - accuracy: 0.0000e+00 - val_loss: 1.8146 - val_top_1_categorical_accuracy: 0.3193 - val_top_2_categorical_accuracy: 0.5400 - val_top_3_categorical_accuracy: 0.6480 - val_top_4_categorical_accuracy: 0.7520 - val_top_5_categorical_accuracy: 0.8253 - val_top_6_categorical_accuracy: 0.8967 - val_top_7_categorical_accuracy: 0.9327 - val_top_8_categorical_accuracy: 0.9707 - val_top_9_categorical_accuracy: 0.9887 - val_precision_1: 0.6093 - val_recall_1: 0.1227 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "70/70 [==============================] - 4s 51ms/step - loss: 1.7803 - top_1_categorical_accuracy: 0.3360 - top_2_categorical_accuracy: 0.5614 - top_3_categorical_accuracy: 0.6851 - top_4_categorical_accuracy: 0.7711 - top_5_categorical_accuracy: 0.8426 - top_6_categorical_accuracy: 0.8989 - top_7_categorical_accuracy: 0.9371 - top_8_categorical_accuracy: 0.9646 - top_9_categorical_accuracy: 0.9849 - precision_1: 0.6034 - recall_1: 0.1017 - accuracy: 0.0000e+00 - val_loss: 1.8019 - val_top_1_categorical_accuracy: 0.3320 - val_top_2_categorical_accuracy: 0.5433 - val_top_3_categorical_accuracy: 0.6640 - val_top_4_categorical_accuracy: 0.7660 - val_top_5_categorical_accuracy: 0.8373 - val_top_6_categorical_accuracy: 0.8953 - val_top_7_categorical_accuracy: 0.9273 - val_top_8_categorical_accuracy: 0.9633 - val_top_9_categorical_accuracy: 0.9840 - val_precision_1: 0.7385 - val_recall_1: 0.0960 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "70/70 [==============================] - 3s 48ms/step - loss: 1.7637 - top_1_categorical_accuracy: 0.3360 - top_2_categorical_accuracy: 0.5611 - top_3_categorical_accuracy: 0.6923 - top_4_categorical_accuracy: 0.7817 - top_5_categorical_accuracy: 0.8503 - top_6_categorical_accuracy: 0.9054 - top_7_categorical_accuracy: 0.9377 - top_8_categorical_accuracy: 0.9646 - top_9_categorical_accuracy: 0.9840 - precision_1: 0.6385 - recall_1: 0.0994 - accuracy: 0.0000e+00 - val_loss: 1.7770 - val_top_1_categorical_accuracy: 0.3207 - val_top_2_categorical_accuracy: 0.5453 - val_top_3_categorical_accuracy: 0.6740 - val_top_4_categorical_accuracy: 0.7720 - val_top_5_categorical_accuracy: 0.8547 - val_top_6_categorical_accuracy: 0.9147 - val_top_7_categorical_accuracy: 0.9440 - val_top_8_categorical_accuracy: 0.9740 - val_top_9_categorical_accuracy: 0.9860 - val_precision_1: 0.6254 - val_recall_1: 0.1213 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "70/70 [==============================] - 3s 48ms/step - loss: 1.7484 - top_1_categorical_accuracy: 0.3491 - top_2_categorical_accuracy: 0.5583 - top_3_categorical_accuracy: 0.6803 - top_4_categorical_accuracy: 0.7751 - top_5_categorical_accuracy: 0.8503 - top_6_categorical_accuracy: 0.9151 - top_7_categorical_accuracy: 0.9426 - top_8_categorical_accuracy: 0.9706 - top_9_categorical_accuracy: 0.9897 - precision_1: 0.6319 - recall_1: 0.1109 - accuracy: 0.0000e+00 - val_loss: 1.7272 - val_top_1_categorical_accuracy: 0.3607 - val_top_2_categorical_accuracy: 0.5780 - val_top_3_categorical_accuracy: 0.7020 - val_top_4_categorical_accuracy: 0.7980 - val_top_5_categorical_accuracy: 0.8653 - val_top_6_categorical_accuracy: 0.9227 - val_top_7_categorical_accuracy: 0.9513 - val_top_8_categorical_accuracy: 0.9720 - val_top_9_categorical_accuracy: 0.9867 - val_precision_1: 0.6304 - val_recall_1: 0.1547 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "70/70 [==============================] - 3s 48ms/step - loss: 1.7338 - top_1_categorical_accuracy: 0.3557 - top_2_categorical_accuracy: 0.5686 - top_3_categorical_accuracy: 0.6963 - top_4_categorical_accuracy: 0.7851 - top_5_categorical_accuracy: 0.8503 - top_6_categorical_accuracy: 0.9077 - top_7_categorical_accuracy: 0.9400 - top_8_categorical_accuracy: 0.9657 - top_9_categorical_accuracy: 0.9849 - precision_1: 0.6427 - recall_1: 0.1203 - accuracy: 0.0000e+00 - val_loss: 1.8021 - val_top_1_categorical_accuracy: 0.3353 - val_top_2_categorical_accuracy: 0.5367 - val_top_3_categorical_accuracy: 0.6533 - val_top_4_categorical_accuracy: 0.7613 - val_top_5_categorical_accuracy: 0.8340 - val_top_6_categorical_accuracy: 0.9000 - val_top_7_categorical_accuracy: 0.9393 - val_top_8_categorical_accuracy: 0.9580 - val_top_9_categorical_accuracy: 0.9793 - val_precision_1: 0.6148 - val_recall_1: 0.1000 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/100\n",
      "70/70 [==============================] - 3s 47ms/step - loss: 1.7291 - top_1_categorical_accuracy: 0.3491 - top_2_categorical_accuracy: 0.5751 - top_3_categorical_accuracy: 0.6966 - top_4_categorical_accuracy: 0.7866 - top_5_categorical_accuracy: 0.8591 - top_6_categorical_accuracy: 0.9180 - top_7_categorical_accuracy: 0.9463 - top_8_categorical_accuracy: 0.9683 - top_9_categorical_accuracy: 0.9834 - precision_1: 0.6515 - recall_1: 0.1229 - accuracy: 0.0000e+00 - val_loss: 1.7250 - val_top_1_categorical_accuracy: 0.3460 - val_top_2_categorical_accuracy: 0.5673 - val_top_3_categorical_accuracy: 0.6933 - val_top_4_categorical_accuracy: 0.7773 - val_top_5_categorical_accuracy: 0.8440 - val_top_6_categorical_accuracy: 0.9020 - val_top_7_categorical_accuracy: 0.9387 - val_top_8_categorical_accuracy: 0.9573 - val_top_9_categorical_accuracy: 0.9773 - val_precision_1: 0.6644 - val_recall_1: 0.1280 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "70/70 [==============================] - 3s 48ms/step - loss: 1.6976 - top_1_categorical_accuracy: 0.3626 - top_2_categorical_accuracy: 0.5823 - top_3_categorical_accuracy: 0.7129 - top_4_categorical_accuracy: 0.7957 - top_5_categorical_accuracy: 0.8617 - top_6_categorical_accuracy: 0.9209 - top_7_categorical_accuracy: 0.9474 - top_8_categorical_accuracy: 0.9700 - top_9_categorical_accuracy: 0.9863 - precision_1: 0.6422 - recall_1: 0.1323 - accuracy: 0.0000e+00 - val_loss: 1.7550 - val_top_1_categorical_accuracy: 0.3407 - val_top_2_categorical_accuracy: 0.5667 - val_top_3_categorical_accuracy: 0.6900 - val_top_4_categorical_accuracy: 0.7760 - val_top_5_categorical_accuracy: 0.8387 - val_top_6_categorical_accuracy: 0.9047 - val_top_7_categorical_accuracy: 0.9380 - val_top_8_categorical_accuracy: 0.9653 - val_top_9_categorical_accuracy: 0.9847 - val_precision_1: 0.7290 - val_recall_1: 0.0753 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "70/70 [==============================] - 4s 53ms/step - loss: 1.6878 - top_1_categorical_accuracy: 0.3646 - top_2_categorical_accuracy: 0.5891 - top_3_categorical_accuracy: 0.7226 - top_4_categorical_accuracy: 0.8017 - top_5_categorical_accuracy: 0.8654 - top_6_categorical_accuracy: 0.9163 - top_7_categorical_accuracy: 0.9474 - top_8_categorical_accuracy: 0.9691 - top_9_categorical_accuracy: 0.9854 - precision_1: 0.6690 - recall_1: 0.1346 - accuracy: 0.0000e+00 - val_loss: 1.6922 - val_top_1_categorical_accuracy: 0.3640 - val_top_2_categorical_accuracy: 0.5933 - val_top_3_categorical_accuracy: 0.7007 - val_top_4_categorical_accuracy: 0.7993 - val_top_5_categorical_accuracy: 0.8653 - val_top_6_categorical_accuracy: 0.9193 - val_top_7_categorical_accuracy: 0.9493 - val_top_8_categorical_accuracy: 0.9700 - val_top_9_categorical_accuracy: 0.9840 - val_precision_1: 0.6733 - val_recall_1: 0.1347 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "70/70 [==============================] - 4s 56ms/step - loss: 1.6604 - top_1_categorical_accuracy: 0.3874 - top_2_categorical_accuracy: 0.6060 - top_3_categorical_accuracy: 0.7243 - top_4_categorical_accuracy: 0.8140 - top_5_categorical_accuracy: 0.8691 - top_6_categorical_accuracy: 0.9226 - top_7_categorical_accuracy: 0.9517 - top_8_categorical_accuracy: 0.9740 - top_9_categorical_accuracy: 0.9889 - precision_1: 0.6638 - recall_1: 0.1540 - accuracy: 0.0000e+00 - val_loss: 1.7650 - val_top_1_categorical_accuracy: 0.3387 - val_top_2_categorical_accuracy: 0.5540 - val_top_3_categorical_accuracy: 0.6960 - val_top_4_categorical_accuracy: 0.7920 - val_top_5_categorical_accuracy: 0.8607 - val_top_6_categorical_accuracy: 0.9227 - val_top_7_categorical_accuracy: 0.9513 - val_top_8_categorical_accuracy: 0.9760 - val_top_9_categorical_accuracy: 0.9900 - val_precision_1: 0.6053 - val_recall_1: 0.1073 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "70/70 [==============================] - 3s 49ms/step - loss: 1.6720 - top_1_categorical_accuracy: 0.3806 - top_2_categorical_accuracy: 0.6160 - top_3_categorical_accuracy: 0.7271 - top_4_categorical_accuracy: 0.8040 - top_5_categorical_accuracy: 0.8674 - top_6_categorical_accuracy: 0.9206 - top_7_categorical_accuracy: 0.9457 - top_8_categorical_accuracy: 0.9683 - top_9_categorical_accuracy: 0.9854 - precision_1: 0.6528 - recall_1: 0.1343 - accuracy: 0.0000e+00 - val_loss: 1.6969 - val_top_1_categorical_accuracy: 0.3727 - val_top_2_categorical_accuracy: 0.5947 - val_top_3_categorical_accuracy: 0.7013 - val_top_4_categorical_accuracy: 0.7820 - val_top_5_categorical_accuracy: 0.8493 - val_top_6_categorical_accuracy: 0.9080 - val_top_7_categorical_accuracy: 0.9473 - val_top_8_categorical_accuracy: 0.9727 - val_top_9_categorical_accuracy: 0.9867 - val_precision_1: 0.7049 - val_recall_1: 0.1147 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "70/70 [==============================] - 3s 48ms/step - loss: 1.6205 - top_1_categorical_accuracy: 0.3966 - top_2_categorical_accuracy: 0.6257 - top_3_categorical_accuracy: 0.7414 - top_4_categorical_accuracy: 0.8174 - top_5_categorical_accuracy: 0.8774 - top_6_categorical_accuracy: 0.9229 - top_7_categorical_accuracy: 0.9517 - top_8_categorical_accuracy: 0.9729 - top_9_categorical_accuracy: 0.9889 - precision_1: 0.6626 - recall_1: 0.1566 - accuracy: 0.0000e+00 - val_loss: 1.6624 - val_top_1_categorical_accuracy: 0.3927 - val_top_2_categorical_accuracy: 0.6060 - val_top_3_categorical_accuracy: 0.7320 - val_top_4_categorical_accuracy: 0.8133 - val_top_5_categorical_accuracy: 0.8780 - val_top_6_categorical_accuracy: 0.9273 - val_top_7_categorical_accuracy: 0.9540 - val_top_8_categorical_accuracy: 0.9760 - val_top_9_categorical_accuracy: 0.9867 - val_precision_1: 0.6521 - val_recall_1: 0.1587 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "70/70 [==============================] - 4s 51ms/step - loss: 1.6334 - top_1_categorical_accuracy: 0.4026 - top_2_categorical_accuracy: 0.6329 - top_3_categorical_accuracy: 0.7417 - top_4_categorical_accuracy: 0.8177 - top_5_categorical_accuracy: 0.8709 - top_6_categorical_accuracy: 0.9246 - top_7_categorical_accuracy: 0.9486 - top_8_categorical_accuracy: 0.9711 - top_9_categorical_accuracy: 0.9886 - precision_1: 0.6508 - recall_1: 0.1560 - accuracy: 0.0000e+00 - val_loss: 1.7171 - val_top_1_categorical_accuracy: 0.3700 - val_top_2_categorical_accuracy: 0.5880 - val_top_3_categorical_accuracy: 0.7087 - val_top_4_categorical_accuracy: 0.7800 - val_top_5_categorical_accuracy: 0.8433 - val_top_6_categorical_accuracy: 0.8987 - val_top_7_categorical_accuracy: 0.9387 - val_top_8_categorical_accuracy: 0.9647 - val_top_9_categorical_accuracy: 0.9813 - val_precision_1: 0.7102 - val_recall_1: 0.1160 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "70/70 [==============================] - 4s 50ms/step - loss: 1.6033 - top_1_categorical_accuracy: 0.4126 - top_2_categorical_accuracy: 0.6363 - top_3_categorical_accuracy: 0.7477 - top_4_categorical_accuracy: 0.8311 - top_5_categorical_accuracy: 0.8817 - top_6_categorical_accuracy: 0.9254 - top_7_categorical_accuracy: 0.9523 - top_8_categorical_accuracy: 0.9754 - top_9_categorical_accuracy: 0.9883 - precision_1: 0.6710 - recall_1: 0.1637 - accuracy: 0.0000e+00 - val_loss: 1.7217 - val_top_1_categorical_accuracy: 0.3693 - val_top_2_categorical_accuracy: 0.5947 - val_top_3_categorical_accuracy: 0.7047 - val_top_4_categorical_accuracy: 0.7867 - val_top_5_categorical_accuracy: 0.8460 - val_top_6_categorical_accuracy: 0.9067 - val_top_7_categorical_accuracy: 0.9393 - val_top_8_categorical_accuracy: 0.9653 - val_top_9_categorical_accuracy: 0.9833 - val_precision_1: 0.6400 - val_recall_1: 0.1707 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "70/70 [==============================] - 4s 51ms/step - loss: 1.5980 - top_1_categorical_accuracy: 0.4203 - top_2_categorical_accuracy: 0.6437 - top_3_categorical_accuracy: 0.7517 - top_4_categorical_accuracy: 0.8234 - top_5_categorical_accuracy: 0.8774 - top_6_categorical_accuracy: 0.9226 - top_7_categorical_accuracy: 0.9466 - top_8_categorical_accuracy: 0.9706 - top_9_categorical_accuracy: 0.9863 - precision_1: 0.6879 - recall_1: 0.1694 - accuracy: 0.0000e+00 - val_loss: 1.6879 - val_top_1_categorical_accuracy: 0.3813 - val_top_2_categorical_accuracy: 0.5900 - val_top_3_categorical_accuracy: 0.6980 - val_top_4_categorical_accuracy: 0.7727 - val_top_5_categorical_accuracy: 0.8400 - val_top_6_categorical_accuracy: 0.8987 - val_top_7_categorical_accuracy: 0.9293 - val_top_8_categorical_accuracy: 0.9593 - val_top_9_categorical_accuracy: 0.9767 - val_precision_1: 0.6585 - val_recall_1: 0.1620 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/100\n",
      "70/70 [==============================] - 4s 51ms/step - loss: 1.5882 - top_1_categorical_accuracy: 0.4283 - top_2_categorical_accuracy: 0.6557 - top_3_categorical_accuracy: 0.7531 - top_4_categorical_accuracy: 0.8254 - top_5_categorical_accuracy: 0.8766 - top_6_categorical_accuracy: 0.9269 - top_7_categorical_accuracy: 0.9557 - top_8_categorical_accuracy: 0.9726 - top_9_categorical_accuracy: 0.9880 - precision_1: 0.6656 - recall_1: 0.1820 - accuracy: 0.0000e+00 - val_loss: 1.6783 - val_top_1_categorical_accuracy: 0.3967 - val_top_2_categorical_accuracy: 0.6213 - val_top_3_categorical_accuracy: 0.7240 - val_top_4_categorical_accuracy: 0.7987 - val_top_5_categorical_accuracy: 0.8540 - val_top_6_categorical_accuracy: 0.9060 - val_top_7_categorical_accuracy: 0.9380 - val_top_8_categorical_accuracy: 0.9673 - val_top_9_categorical_accuracy: 0.9807 - val_precision_1: 0.6818 - val_recall_1: 0.1400 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "70/70 [==============================] - 4s 50ms/step - loss: 1.5703 - top_1_categorical_accuracy: 0.4234 - top_2_categorical_accuracy: 0.6551 - top_3_categorical_accuracy: 0.7643 - top_4_categorical_accuracy: 0.8331 - top_5_categorical_accuracy: 0.8866 - top_6_categorical_accuracy: 0.9289 - top_7_categorical_accuracy: 0.9520 - top_8_categorical_accuracy: 0.9737 - top_9_categorical_accuracy: 0.9883 - precision_1: 0.6673 - recall_1: 0.1891 - accuracy: 0.0000e+00 - val_loss: 1.6856 - val_top_1_categorical_accuracy: 0.3947 - val_top_2_categorical_accuracy: 0.6067 - val_top_3_categorical_accuracy: 0.7147 - val_top_4_categorical_accuracy: 0.7993 - val_top_5_categorical_accuracy: 0.8667 - val_top_6_categorical_accuracy: 0.9173 - val_top_7_categorical_accuracy: 0.9513 - val_top_8_categorical_accuracy: 0.9733 - val_top_9_categorical_accuracy: 0.9853 - val_precision_1: 0.6053 - val_recall_1: 0.1820 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "70/70 [==============================] - 4s 51ms/step - loss: 1.5635 - top_1_categorical_accuracy: 0.4337 - top_2_categorical_accuracy: 0.6571 - top_3_categorical_accuracy: 0.7674 - top_4_categorical_accuracy: 0.8380 - top_5_categorical_accuracy: 0.8877 - top_6_categorical_accuracy: 0.9329 - top_7_categorical_accuracy: 0.9586 - top_8_categorical_accuracy: 0.9786 - top_9_categorical_accuracy: 0.9886 - precision_1: 0.6723 - recall_1: 0.1934 - accuracy: 0.0000e+00 - val_loss: 1.7406 - val_top_1_categorical_accuracy: 0.3907 - val_top_2_categorical_accuracy: 0.6107 - val_top_3_categorical_accuracy: 0.7280 - val_top_4_categorical_accuracy: 0.8160 - val_top_5_categorical_accuracy: 0.8740 - val_top_6_categorical_accuracy: 0.9280 - val_top_7_categorical_accuracy: 0.9533 - val_top_8_categorical_accuracy: 0.9700 - val_top_9_categorical_accuracy: 0.9853 - val_precision_1: 0.5222 - val_recall_1: 0.2113 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "70/70 [==============================] - 4s 51ms/step - loss: 1.5569 - top_1_categorical_accuracy: 0.4354 - top_2_categorical_accuracy: 0.6600 - top_3_categorical_accuracy: 0.7583 - top_4_categorical_accuracy: 0.8286 - top_5_categorical_accuracy: 0.8800 - top_6_categorical_accuracy: 0.9300 - top_7_categorical_accuracy: 0.9580 - top_8_categorical_accuracy: 0.9754 - top_9_categorical_accuracy: 0.9894 - precision_1: 0.6712 - recall_1: 0.1960 - accuracy: 0.0000e+00 - val_loss: 1.6583 - val_top_1_categorical_accuracy: 0.3940 - val_top_2_categorical_accuracy: 0.6127 - val_top_3_categorical_accuracy: 0.7347 - val_top_4_categorical_accuracy: 0.8053 - val_top_5_categorical_accuracy: 0.8667 - val_top_6_categorical_accuracy: 0.9080 - val_top_7_categorical_accuracy: 0.9400 - val_top_8_categorical_accuracy: 0.9693 - val_top_9_categorical_accuracy: 0.9800 - val_precision_1: 0.6284 - val_recall_1: 0.1860 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "70/70 [==============================] - 4s 51ms/step - loss: 1.5374 - top_1_categorical_accuracy: 0.4511 - top_2_categorical_accuracy: 0.6694 - top_3_categorical_accuracy: 0.7783 - top_4_categorical_accuracy: 0.8440 - top_5_categorical_accuracy: 0.8974 - top_6_categorical_accuracy: 0.9389 - top_7_categorical_accuracy: 0.9629 - top_8_categorical_accuracy: 0.9763 - top_9_categorical_accuracy: 0.9897 - precision_1: 0.6771 - recall_1: 0.2043 - accuracy: 0.0000e+00 - val_loss: 1.6765 - val_top_1_categorical_accuracy: 0.3853 - val_top_2_categorical_accuracy: 0.6193 - val_top_3_categorical_accuracy: 0.7333 - val_top_4_categorical_accuracy: 0.8187 - val_top_5_categorical_accuracy: 0.8733 - val_top_6_categorical_accuracy: 0.9160 - val_top_7_categorical_accuracy: 0.9407 - val_top_8_categorical_accuracy: 0.9653 - val_top_9_categorical_accuracy: 0.9827 - val_precision_1: 0.5886 - val_recall_1: 0.2193 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "70/70 [==============================] - 3s 49ms/step - loss: 1.5230 - top_1_categorical_accuracy: 0.4457 - top_2_categorical_accuracy: 0.6763 - top_3_categorical_accuracy: 0.7763 - top_4_categorical_accuracy: 0.8506 - top_5_categorical_accuracy: 0.9000 - top_6_categorical_accuracy: 0.9369 - top_7_categorical_accuracy: 0.9597 - top_8_categorical_accuracy: 0.9774 - top_9_categorical_accuracy: 0.9897 - precision_1: 0.6995 - recall_1: 0.2069 - accuracy: 0.0000e+00 - val_loss: 1.7646 - val_top_1_categorical_accuracy: 0.3773 - val_top_2_categorical_accuracy: 0.5980 - val_top_3_categorical_accuracy: 0.7007 - val_top_4_categorical_accuracy: 0.7820 - val_top_5_categorical_accuracy: 0.8460 - val_top_6_categorical_accuracy: 0.8993 - val_top_7_categorical_accuracy: 0.9460 - val_top_8_categorical_accuracy: 0.9653 - val_top_9_categorical_accuracy: 0.9813 - val_precision_1: 0.5730 - val_recall_1: 0.2067 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "70/70 [==============================] - 3s 49ms/step - loss: 1.5218 - top_1_categorical_accuracy: 0.4440 - top_2_categorical_accuracy: 0.6709 - top_3_categorical_accuracy: 0.7794 - top_4_categorical_accuracy: 0.8480 - top_5_categorical_accuracy: 0.8966 - top_6_categorical_accuracy: 0.9334 - top_7_categorical_accuracy: 0.9606 - top_8_categorical_accuracy: 0.9749 - top_9_categorical_accuracy: 0.9883 - precision_1: 0.6861 - recall_1: 0.2123 - accuracy: 0.0000e+00 - val_loss: 1.6324 - val_top_1_categorical_accuracy: 0.4060 - val_top_2_categorical_accuracy: 0.6307 - val_top_3_categorical_accuracy: 0.7527 - val_top_4_categorical_accuracy: 0.8460 - val_top_5_categorical_accuracy: 0.8953 - val_top_6_categorical_accuracy: 0.9307 - val_top_7_categorical_accuracy: 0.9540 - val_top_8_categorical_accuracy: 0.9733 - val_top_9_categorical_accuracy: 0.9867 - val_precision_1: 0.5782 - val_recall_1: 0.2193 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "70/70 [==============================] - 3s 48ms/step - loss: 1.5100 - top_1_categorical_accuracy: 0.4500 - top_2_categorical_accuracy: 0.6734 - top_3_categorical_accuracy: 0.7794 - top_4_categorical_accuracy: 0.8514 - top_5_categorical_accuracy: 0.8974 - top_6_categorical_accuracy: 0.9400 - top_7_categorical_accuracy: 0.9637 - top_8_categorical_accuracy: 0.9766 - top_9_categorical_accuracy: 0.9903 - precision_1: 0.6943 - recall_1: 0.2246 - accuracy: 0.0000e+00 - val_loss: 1.5784 - val_top_1_categorical_accuracy: 0.4127 - val_top_2_categorical_accuracy: 0.6533 - val_top_3_categorical_accuracy: 0.7553 - val_top_4_categorical_accuracy: 0.8373 - val_top_5_categorical_accuracy: 0.8880 - val_top_6_categorical_accuracy: 0.9273 - val_top_7_categorical_accuracy: 0.9573 - val_top_8_categorical_accuracy: 0.9807 - val_top_9_categorical_accuracy: 0.9887 - val_precision_1: 0.6154 - val_recall_1: 0.2187 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "70/70 [==============================] - 3s 48ms/step - loss: 1.4980 - top_1_categorical_accuracy: 0.4617 - top_2_categorical_accuracy: 0.6794 - top_3_categorical_accuracy: 0.7891 - top_4_categorical_accuracy: 0.8566 - top_5_categorical_accuracy: 0.9054 - top_6_categorical_accuracy: 0.9423 - top_7_categorical_accuracy: 0.9643 - top_8_categorical_accuracy: 0.9771 - top_9_categorical_accuracy: 0.9911 - precision_1: 0.6954 - recall_1: 0.2237 - accuracy: 0.0000e+00 - val_loss: 1.6805 - val_top_1_categorical_accuracy: 0.3833 - val_top_2_categorical_accuracy: 0.6007 - val_top_3_categorical_accuracy: 0.7293 - val_top_4_categorical_accuracy: 0.8080 - val_top_5_categorical_accuracy: 0.8607 - val_top_6_categorical_accuracy: 0.9153 - val_top_7_categorical_accuracy: 0.9473 - val_top_8_categorical_accuracy: 0.9713 - val_top_9_categorical_accuracy: 0.9847 - val_precision_1: 0.5744 - val_recall_1: 0.2187 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/100\n",
      "70/70 [==============================] - 4s 52ms/step - loss: 1.4882 - top_1_categorical_accuracy: 0.4649 - top_2_categorical_accuracy: 0.6757 - top_3_categorical_accuracy: 0.7860 - top_4_categorical_accuracy: 0.8549 - top_5_categorical_accuracy: 0.9006 - top_6_categorical_accuracy: 0.9394 - top_7_categorical_accuracy: 0.9623 - top_8_categorical_accuracy: 0.9769 - top_9_categorical_accuracy: 0.9914 - precision_1: 0.7090 - recall_1: 0.2374 - accuracy: 0.0000e+00 - val_loss: 1.5955 - val_top_1_categorical_accuracy: 0.4413 - val_top_2_categorical_accuracy: 0.6553 - val_top_3_categorical_accuracy: 0.7647 - val_top_4_categorical_accuracy: 0.8333 - val_top_5_categorical_accuracy: 0.8907 - val_top_6_categorical_accuracy: 0.9280 - val_top_7_categorical_accuracy: 0.9547 - val_top_8_categorical_accuracy: 0.9693 - val_top_9_categorical_accuracy: 0.9860 - val_precision_1: 0.6142 - val_recall_1: 0.2367 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "70/70 [==============================] - 3s 48ms/step - loss: 1.4650 - top_1_categorical_accuracy: 0.4834 - top_2_categorical_accuracy: 0.6909 - top_3_categorical_accuracy: 0.7940 - top_4_categorical_accuracy: 0.8571 - top_5_categorical_accuracy: 0.9014 - top_6_categorical_accuracy: 0.9423 - top_7_categorical_accuracy: 0.9669 - top_8_categorical_accuracy: 0.9780 - top_9_categorical_accuracy: 0.9903 - precision_1: 0.7351 - recall_1: 0.2426 - accuracy: 0.0000e+00 - val_loss: 1.5947 - val_top_1_categorical_accuracy: 0.4407 - val_top_2_categorical_accuracy: 0.6547 - val_top_3_categorical_accuracy: 0.7653 - val_top_4_categorical_accuracy: 0.8240 - val_top_5_categorical_accuracy: 0.8793 - val_top_6_categorical_accuracy: 0.9187 - val_top_7_categorical_accuracy: 0.9493 - val_top_8_categorical_accuracy: 0.9720 - val_top_9_categorical_accuracy: 0.9853 - val_precision_1: 0.6258 - val_recall_1: 0.2620 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "70/70 [==============================] - 3s 48ms/step - loss: 1.4390 - top_1_categorical_accuracy: 0.4809 - top_2_categorical_accuracy: 0.7100 - top_3_categorical_accuracy: 0.8017 - top_4_categorical_accuracy: 0.8660 - top_5_categorical_accuracy: 0.9109 - top_6_categorical_accuracy: 0.9443 - top_7_categorical_accuracy: 0.9660 - top_8_categorical_accuracy: 0.9817 - top_9_categorical_accuracy: 0.9937 - precision_1: 0.7012 - recall_1: 0.2554 - accuracy: 0.0000e+00 - val_loss: 1.5952 - val_top_1_categorical_accuracy: 0.4413 - val_top_2_categorical_accuracy: 0.6407 - val_top_3_categorical_accuracy: 0.7420 - val_top_4_categorical_accuracy: 0.8187 - val_top_5_categorical_accuracy: 0.8807 - val_top_6_categorical_accuracy: 0.9240 - val_top_7_categorical_accuracy: 0.9607 - val_top_8_categorical_accuracy: 0.9753 - val_top_9_categorical_accuracy: 0.9827 - val_precision_1: 0.6687 - val_recall_1: 0.2153 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "70/70 [==============================] - 4s 52ms/step - loss: 1.4608 - top_1_categorical_accuracy: 0.4820 - top_2_categorical_accuracy: 0.6894 - top_3_categorical_accuracy: 0.7857 - top_4_categorical_accuracy: 0.8551 - top_5_categorical_accuracy: 0.8986 - top_6_categorical_accuracy: 0.9386 - top_7_categorical_accuracy: 0.9611 - top_8_categorical_accuracy: 0.9774 - top_9_categorical_accuracy: 0.9923 - precision_1: 0.6977 - recall_1: 0.2546 - accuracy: 0.0000e+00 - val_loss: 1.5666 - val_top_1_categorical_accuracy: 0.4387 - val_top_2_categorical_accuracy: 0.6600 - val_top_3_categorical_accuracy: 0.7620 - val_top_4_categorical_accuracy: 0.8340 - val_top_5_categorical_accuracy: 0.8933 - val_top_6_categorical_accuracy: 0.9280 - val_top_7_categorical_accuracy: 0.9567 - val_top_8_categorical_accuracy: 0.9727 - val_top_9_categorical_accuracy: 0.9873 - val_precision_1: 0.6179 - val_recall_1: 0.2673 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "70/70 [==============================] - 3s 49ms/step - loss: 1.4347 - top_1_categorical_accuracy: 0.4823 - top_2_categorical_accuracy: 0.7029 - top_3_categorical_accuracy: 0.7989 - top_4_categorical_accuracy: 0.8631 - top_5_categorical_accuracy: 0.9089 - top_6_categorical_accuracy: 0.9423 - top_7_categorical_accuracy: 0.9629 - top_8_categorical_accuracy: 0.9774 - top_9_categorical_accuracy: 0.9894 - precision_1: 0.7143 - recall_1: 0.2600 - accuracy: 0.0000e+00 - val_loss: 1.5918 - val_top_1_categorical_accuracy: 0.4387 - val_top_2_categorical_accuracy: 0.6533 - val_top_3_categorical_accuracy: 0.7660 - val_top_4_categorical_accuracy: 0.8260 - val_top_5_categorical_accuracy: 0.8827 - val_top_6_categorical_accuracy: 0.9213 - val_top_7_categorical_accuracy: 0.9527 - val_top_8_categorical_accuracy: 0.9740 - val_top_9_categorical_accuracy: 0.9840 - val_precision_1: 0.6144 - val_recall_1: 0.2667 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "70/70 [==============================] - 3s 48ms/step - loss: 1.4193 - top_1_categorical_accuracy: 0.4894 - top_2_categorical_accuracy: 0.7089 - top_3_categorical_accuracy: 0.8069 - top_4_categorical_accuracy: 0.8714 - top_5_categorical_accuracy: 0.9169 - top_6_categorical_accuracy: 0.9480 - top_7_categorical_accuracy: 0.9680 - top_8_categorical_accuracy: 0.9806 - top_9_categorical_accuracy: 0.9909 - precision_1: 0.7173 - recall_1: 0.2603 - accuracy: 0.0000e+00 - val_loss: 1.6099 - val_top_1_categorical_accuracy: 0.4480 - val_top_2_categorical_accuracy: 0.6540 - val_top_3_categorical_accuracy: 0.7560 - val_top_4_categorical_accuracy: 0.8220 - val_top_5_categorical_accuracy: 0.8753 - val_top_6_categorical_accuracy: 0.9153 - val_top_7_categorical_accuracy: 0.9453 - val_top_8_categorical_accuracy: 0.9667 - val_top_9_categorical_accuracy: 0.9820 - val_precision_1: 0.6083 - val_recall_1: 0.2547 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "70/70 [==============================] - 4s 51ms/step - loss: 1.4167 - top_1_categorical_accuracy: 0.4971 - top_2_categorical_accuracy: 0.7106 - top_3_categorical_accuracy: 0.8017 - top_4_categorical_accuracy: 0.8606 - top_5_categorical_accuracy: 0.9080 - top_6_categorical_accuracy: 0.9429 - top_7_categorical_accuracy: 0.9637 - top_8_categorical_accuracy: 0.9800 - top_9_categorical_accuracy: 0.9903 - precision_1: 0.7424 - recall_1: 0.2783 - accuracy: 0.0000e+00 - val_loss: 1.6048 - val_top_1_categorical_accuracy: 0.4400 - val_top_2_categorical_accuracy: 0.6500 - val_top_3_categorical_accuracy: 0.7567 - val_top_4_categorical_accuracy: 0.8373 - val_top_5_categorical_accuracy: 0.8800 - val_top_6_categorical_accuracy: 0.9207 - val_top_7_categorical_accuracy: 0.9433 - val_top_8_categorical_accuracy: 0.9660 - val_top_9_categorical_accuracy: 0.9827 - val_precision_1: 0.6225 - val_recall_1: 0.2320 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "70/70 [==============================] - 3s 50ms/step - loss: 1.3870 - top_1_categorical_accuracy: 0.5003 - top_2_categorical_accuracy: 0.7234 - top_3_categorical_accuracy: 0.8149 - top_4_categorical_accuracy: 0.8749 - top_5_categorical_accuracy: 0.9151 - top_6_categorical_accuracy: 0.9486 - top_7_categorical_accuracy: 0.9677 - top_8_categorical_accuracy: 0.9831 - top_9_categorical_accuracy: 0.9946 - precision_1: 0.7344 - recall_1: 0.2797 - accuracy: 0.0000e+00 - val_loss: 1.6439 - val_top_1_categorical_accuracy: 0.4380 - val_top_2_categorical_accuracy: 0.6400 - val_top_3_categorical_accuracy: 0.7473 - val_top_4_categorical_accuracy: 0.8280 - val_top_5_categorical_accuracy: 0.8820 - val_top_6_categorical_accuracy: 0.9280 - val_top_7_categorical_accuracy: 0.9540 - val_top_8_categorical_accuracy: 0.9713 - val_top_9_categorical_accuracy: 0.9873 - val_precision_1: 0.5716 - val_recall_1: 0.2847 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "70/70 [==============================] - 3s 50ms/step - loss: 1.4242 - top_1_categorical_accuracy: 0.5131 - top_2_categorical_accuracy: 0.7186 - top_3_categorical_accuracy: 0.8097 - top_4_categorical_accuracy: 0.8629 - top_5_categorical_accuracy: 0.9046 - top_6_categorical_accuracy: 0.9406 - top_7_categorical_accuracy: 0.9626 - top_8_categorical_accuracy: 0.9780 - top_9_categorical_accuracy: 0.9914 - precision_1: 0.7028 - recall_1: 0.2831 - accuracy: 0.0000e+00 - val_loss: 1.6559 - val_top_1_categorical_accuracy: 0.4340 - val_top_2_categorical_accuracy: 0.6440 - val_top_3_categorical_accuracy: 0.7520 - val_top_4_categorical_accuracy: 0.8253 - val_top_5_categorical_accuracy: 0.8720 - val_top_6_categorical_accuracy: 0.9200 - val_top_7_categorical_accuracy: 0.9453 - val_top_8_categorical_accuracy: 0.9667 - val_top_9_categorical_accuracy: 0.9873 - val_precision_1: 0.6043 - val_recall_1: 0.2453 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/100\n",
      "70/70 [==============================] - 3s 48ms/step - loss: 1.3879 - top_1_categorical_accuracy: 0.4966 - top_2_categorical_accuracy: 0.7194 - top_3_categorical_accuracy: 0.8106 - top_4_categorical_accuracy: 0.8669 - top_5_categorical_accuracy: 0.9074 - top_6_categorical_accuracy: 0.9434 - top_7_categorical_accuracy: 0.9671 - top_8_categorical_accuracy: 0.9783 - top_9_categorical_accuracy: 0.9914 - precision_1: 0.7298 - recall_1: 0.2840 - accuracy: 0.0000e+00 - val_loss: 1.5833 - val_top_1_categorical_accuracy: 0.4547 - val_top_2_categorical_accuracy: 0.6673 - val_top_3_categorical_accuracy: 0.7700 - val_top_4_categorical_accuracy: 0.8380 - val_top_5_categorical_accuracy: 0.8793 - val_top_6_categorical_accuracy: 0.9187 - val_top_7_categorical_accuracy: 0.9467 - val_top_8_categorical_accuracy: 0.9693 - val_top_9_categorical_accuracy: 0.9880 - val_precision_1: 0.6152 - val_recall_1: 0.2920 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "70/70 [==============================] - 3s 48ms/step - loss: 1.3845 - top_1_categorical_accuracy: 0.5080 - top_2_categorical_accuracy: 0.7280 - top_3_categorical_accuracy: 0.8180 - top_4_categorical_accuracy: 0.8751 - top_5_categorical_accuracy: 0.9123 - top_6_categorical_accuracy: 0.9489 - top_7_categorical_accuracy: 0.9694 - top_8_categorical_accuracy: 0.9820 - top_9_categorical_accuracy: 0.9951 - precision_1: 0.7037 - recall_1: 0.2966 - accuracy: 0.0000e+00 - val_loss: 1.6212 - val_top_1_categorical_accuracy: 0.4453 - val_top_2_categorical_accuracy: 0.6547 - val_top_3_categorical_accuracy: 0.7527 - val_top_4_categorical_accuracy: 0.8187 - val_top_5_categorical_accuracy: 0.8800 - val_top_6_categorical_accuracy: 0.9300 - val_top_7_categorical_accuracy: 0.9513 - val_top_8_categorical_accuracy: 0.9733 - val_top_9_categorical_accuracy: 0.9880 - val_precision_1: 0.6028 - val_recall_1: 0.2873 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "70/70 [==============================] - 3s 47ms/step - loss: 1.3625 - top_1_categorical_accuracy: 0.5120 - top_2_categorical_accuracy: 0.7254 - top_3_categorical_accuracy: 0.8106 - top_4_categorical_accuracy: 0.8720 - top_5_categorical_accuracy: 0.9137 - top_6_categorical_accuracy: 0.9509 - top_7_categorical_accuracy: 0.9709 - top_8_categorical_accuracy: 0.9849 - top_9_categorical_accuracy: 0.9943 - precision_1: 0.7393 - recall_1: 0.2957 - accuracy: 0.0000e+00 - val_loss: 1.5765 - val_top_1_categorical_accuracy: 0.4460 - val_top_2_categorical_accuracy: 0.6720 - val_top_3_categorical_accuracy: 0.7753 - val_top_4_categorical_accuracy: 0.8427 - val_top_5_categorical_accuracy: 0.8867 - val_top_6_categorical_accuracy: 0.9267 - val_top_7_categorical_accuracy: 0.9533 - val_top_8_categorical_accuracy: 0.9713 - val_top_9_categorical_accuracy: 0.9900 - val_precision_1: 0.6112 - val_recall_1: 0.2547 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "70/70 [==============================] - 3s 50ms/step - loss: 1.3480 - top_1_categorical_accuracy: 0.5200 - top_2_categorical_accuracy: 0.7363 - top_3_categorical_accuracy: 0.8231 - top_4_categorical_accuracy: 0.8746 - top_5_categorical_accuracy: 0.9160 - top_6_categorical_accuracy: 0.9514 - top_7_categorical_accuracy: 0.9680 - top_8_categorical_accuracy: 0.9820 - top_9_categorical_accuracy: 0.9943 - precision_1: 0.7453 - recall_1: 0.3051 - accuracy: 0.0000e+00 - val_loss: 1.5495 - val_top_1_categorical_accuracy: 0.4607 - val_top_2_categorical_accuracy: 0.6753 - val_top_3_categorical_accuracy: 0.7747 - val_top_4_categorical_accuracy: 0.8480 - val_top_5_categorical_accuracy: 0.8973 - val_top_6_categorical_accuracy: 0.9293 - val_top_7_categorical_accuracy: 0.9540 - val_top_8_categorical_accuracy: 0.9720 - val_top_9_categorical_accuracy: 0.9867 - val_precision_1: 0.6485 - val_recall_1: 0.2620 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "70/70 [==============================] - 4s 51ms/step - loss: 1.3617 - top_1_categorical_accuracy: 0.5237 - top_2_categorical_accuracy: 0.7329 - top_3_categorical_accuracy: 0.8186 - top_4_categorical_accuracy: 0.8837 - top_5_categorical_accuracy: 0.9206 - top_6_categorical_accuracy: 0.9491 - top_7_categorical_accuracy: 0.9663 - top_8_categorical_accuracy: 0.9823 - top_9_categorical_accuracy: 0.9923 - precision_1: 0.7155 - recall_1: 0.2989 - accuracy: 0.0000e+00 - val_loss: 1.6095 - val_top_1_categorical_accuracy: 0.4480 - val_top_2_categorical_accuracy: 0.6533 - val_top_3_categorical_accuracy: 0.7633 - val_top_4_categorical_accuracy: 0.8433 - val_top_5_categorical_accuracy: 0.8887 - val_top_6_categorical_accuracy: 0.9213 - val_top_7_categorical_accuracy: 0.9500 - val_top_8_categorical_accuracy: 0.9760 - val_top_9_categorical_accuracy: 0.9880 - val_precision_1: 0.6243 - val_recall_1: 0.3047 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "70/70 [==============================] - 4s 51ms/step - loss: 1.3597 - top_1_categorical_accuracy: 0.5229 - top_2_categorical_accuracy: 0.7331 - top_3_categorical_accuracy: 0.8223 - top_4_categorical_accuracy: 0.8809 - top_5_categorical_accuracy: 0.9171 - top_6_categorical_accuracy: 0.9457 - top_7_categorical_accuracy: 0.9671 - top_8_categorical_accuracy: 0.9806 - top_9_categorical_accuracy: 0.9917 - precision_1: 0.7232 - recall_1: 0.3031 - accuracy: 0.0000e+00 - val_loss: 1.5727 - val_top_1_categorical_accuracy: 0.4433 - val_top_2_categorical_accuracy: 0.6780 - val_top_3_categorical_accuracy: 0.7720 - val_top_4_categorical_accuracy: 0.8600 - val_top_5_categorical_accuracy: 0.8980 - val_top_6_categorical_accuracy: 0.9293 - val_top_7_categorical_accuracy: 0.9540 - val_top_8_categorical_accuracy: 0.9740 - val_top_9_categorical_accuracy: 0.9900 - val_precision_1: 0.5789 - val_recall_1: 0.2960 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "70/70 [==============================] - 4s 52ms/step - loss: 1.3393 - top_1_categorical_accuracy: 0.5280 - top_2_categorical_accuracy: 0.7391 - top_3_categorical_accuracy: 0.8254 - top_4_categorical_accuracy: 0.8849 - top_5_categorical_accuracy: 0.9231 - top_6_categorical_accuracy: 0.9534 - top_7_categorical_accuracy: 0.9683 - top_8_categorical_accuracy: 0.9811 - top_9_categorical_accuracy: 0.9931 - precision_1: 0.7282 - recall_1: 0.3131 - accuracy: 0.0000e+00 - val_loss: 1.5614 - val_top_1_categorical_accuracy: 0.4613 - val_top_2_categorical_accuracy: 0.6853 - val_top_3_categorical_accuracy: 0.7847 - val_top_4_categorical_accuracy: 0.8507 - val_top_5_categorical_accuracy: 0.8947 - val_top_6_categorical_accuracy: 0.9307 - val_top_7_categorical_accuracy: 0.9500 - val_top_8_categorical_accuracy: 0.9693 - val_top_9_categorical_accuracy: 0.9860 - val_precision_1: 0.6063 - val_recall_1: 0.2967 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "70/70 [==============================] - 4s 52ms/step - loss: 1.2932 - top_1_categorical_accuracy: 0.5503 - top_2_categorical_accuracy: 0.7534 - top_3_categorical_accuracy: 0.8346 - top_4_categorical_accuracy: 0.8914 - top_5_categorical_accuracy: 0.9269 - top_6_categorical_accuracy: 0.9540 - top_7_categorical_accuracy: 0.9680 - top_8_categorical_accuracy: 0.9829 - top_9_categorical_accuracy: 0.9920 - precision_1: 0.7480 - recall_1: 0.3400 - accuracy: 0.0000e+00 - val_loss: 1.5905 - val_top_1_categorical_accuracy: 0.4653 - val_top_2_categorical_accuracy: 0.6727 - val_top_3_categorical_accuracy: 0.7767 - val_top_4_categorical_accuracy: 0.8393 - val_top_5_categorical_accuracy: 0.8900 - val_top_6_categorical_accuracy: 0.9220 - val_top_7_categorical_accuracy: 0.9493 - val_top_8_categorical_accuracy: 0.9727 - val_top_9_categorical_accuracy: 0.9907 - val_precision_1: 0.6134 - val_recall_1: 0.3120 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "70/70 [==============================] - 4s 51ms/step - loss: 1.3172 - top_1_categorical_accuracy: 0.5366 - top_2_categorical_accuracy: 0.7434 - top_3_categorical_accuracy: 0.8306 - top_4_categorical_accuracy: 0.8883 - top_5_categorical_accuracy: 0.9209 - top_6_categorical_accuracy: 0.9531 - top_7_categorical_accuracy: 0.9734 - top_8_categorical_accuracy: 0.9866 - top_9_categorical_accuracy: 0.9940 - precision_1: 0.7273 - recall_1: 0.3391 - accuracy: 0.0000e+00 - val_loss: 1.5454 - val_top_1_categorical_accuracy: 0.4587 - val_top_2_categorical_accuracy: 0.6713 - val_top_3_categorical_accuracy: 0.7793 - val_top_4_categorical_accuracy: 0.8433 - val_top_5_categorical_accuracy: 0.8840 - val_top_6_categorical_accuracy: 0.9220 - val_top_7_categorical_accuracy: 0.9487 - val_top_8_categorical_accuracy: 0.9627 - val_top_9_categorical_accuracy: 0.9833 - val_precision_1: 0.6817 - val_recall_1: 0.2613 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/100\n",
      "70/70 [==============================] - 3s 50ms/step - loss: 1.3029 - top_1_categorical_accuracy: 0.5377 - top_2_categorical_accuracy: 0.7446 - top_3_categorical_accuracy: 0.8291 - top_4_categorical_accuracy: 0.8846 - top_5_categorical_accuracy: 0.9234 - top_6_categorical_accuracy: 0.9557 - top_7_categorical_accuracy: 0.9731 - top_8_categorical_accuracy: 0.9846 - top_9_categorical_accuracy: 0.9949 - precision_1: 0.7326 - recall_1: 0.3406 - accuracy: 0.0000e+00 - val_loss: 1.6169 - val_top_1_categorical_accuracy: 0.4667 - val_top_2_categorical_accuracy: 0.6560 - val_top_3_categorical_accuracy: 0.7580 - val_top_4_categorical_accuracy: 0.8327 - val_top_5_categorical_accuracy: 0.8813 - val_top_6_categorical_accuracy: 0.9173 - val_top_7_categorical_accuracy: 0.9493 - val_top_8_categorical_accuracy: 0.9760 - val_top_9_categorical_accuracy: 0.9880 - val_precision_1: 0.6122 - val_recall_1: 0.3020 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "70/70 [==============================] - 4s 53ms/step - loss: 1.2722 - top_1_categorical_accuracy: 0.5540 - top_2_categorical_accuracy: 0.7574 - top_3_categorical_accuracy: 0.8403 - top_4_categorical_accuracy: 0.8903 - top_5_categorical_accuracy: 0.9269 - top_6_categorical_accuracy: 0.9549 - top_7_categorical_accuracy: 0.9740 - top_8_categorical_accuracy: 0.9846 - top_9_categorical_accuracy: 0.9954 - precision_1: 0.7402 - recall_1: 0.3566 - accuracy: 0.0000e+00 - val_loss: 1.6012 - val_top_1_categorical_accuracy: 0.4500 - val_top_2_categorical_accuracy: 0.6647 - val_top_3_categorical_accuracy: 0.7640 - val_top_4_categorical_accuracy: 0.8400 - val_top_5_categorical_accuracy: 0.8867 - val_top_6_categorical_accuracy: 0.9247 - val_top_7_categorical_accuracy: 0.9540 - val_top_8_categorical_accuracy: 0.9673 - val_top_9_categorical_accuracy: 0.9880 - val_precision_1: 0.6008 - val_recall_1: 0.3160 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "70/70 [==============================] - 3s 49ms/step - loss: 1.2578 - top_1_categorical_accuracy: 0.5491 - top_2_categorical_accuracy: 0.7571 - top_3_categorical_accuracy: 0.8446 - top_4_categorical_accuracy: 0.8954 - top_5_categorical_accuracy: 0.9363 - top_6_categorical_accuracy: 0.9620 - top_7_categorical_accuracy: 0.9757 - top_8_categorical_accuracy: 0.9860 - top_9_categorical_accuracy: 0.9954 - precision_1: 0.7206 - recall_1: 0.3603 - accuracy: 0.0000e+00 - val_loss: 1.6265 - val_top_1_categorical_accuracy: 0.4427 - val_top_2_categorical_accuracy: 0.6573 - val_top_3_categorical_accuracy: 0.7653 - val_top_4_categorical_accuracy: 0.8500 - val_top_5_categorical_accuracy: 0.8973 - val_top_6_categorical_accuracy: 0.9300 - val_top_7_categorical_accuracy: 0.9560 - val_top_8_categorical_accuracy: 0.9707 - val_top_9_categorical_accuracy: 0.9880 - val_precision_1: 0.5604 - val_recall_1: 0.3093 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "70/70 [==============================] - 3s 49ms/step - loss: 1.2545 - top_1_categorical_accuracy: 0.5577 - top_2_categorical_accuracy: 0.7623 - top_3_categorical_accuracy: 0.8431 - top_4_categorical_accuracy: 0.8923 - top_5_categorical_accuracy: 0.9257 - top_6_categorical_accuracy: 0.9534 - top_7_categorical_accuracy: 0.9720 - top_8_categorical_accuracy: 0.9843 - top_9_categorical_accuracy: 0.9940 - precision_1: 0.7432 - recall_1: 0.3754 - accuracy: 0.0000e+00 - val_loss: 1.6236 - val_top_1_categorical_accuracy: 0.4633 - val_top_2_categorical_accuracy: 0.6840 - val_top_3_categorical_accuracy: 0.7667 - val_top_4_categorical_accuracy: 0.8353 - val_top_5_categorical_accuracy: 0.8840 - val_top_6_categorical_accuracy: 0.9253 - val_top_7_categorical_accuracy: 0.9493 - val_top_8_categorical_accuracy: 0.9667 - val_top_9_categorical_accuracy: 0.9847 - val_precision_1: 0.5753 - val_recall_1: 0.3387 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "70/70 [==============================] - 3s 49ms/step - loss: 1.2629 - top_1_categorical_accuracy: 0.5557 - top_2_categorical_accuracy: 0.7640 - top_3_categorical_accuracy: 0.8517 - top_4_categorical_accuracy: 0.9014 - top_5_categorical_accuracy: 0.9351 - top_6_categorical_accuracy: 0.9603 - top_7_categorical_accuracy: 0.9746 - top_8_categorical_accuracy: 0.9863 - top_9_categorical_accuracy: 0.9949 - precision_1: 0.7171 - recall_1: 0.3643 - accuracy: 0.0000e+00 - val_loss: 1.5727 - val_top_1_categorical_accuracy: 0.4433 - val_top_2_categorical_accuracy: 0.6740 - val_top_3_categorical_accuracy: 0.7813 - val_top_4_categorical_accuracy: 0.8460 - val_top_5_categorical_accuracy: 0.8953 - val_top_6_categorical_accuracy: 0.9233 - val_top_7_categorical_accuracy: 0.9533 - val_top_8_categorical_accuracy: 0.9680 - val_top_9_categorical_accuracy: 0.9853 - val_precision_1: 0.6019 - val_recall_1: 0.3033 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "70/70 [==============================] - 3s 48ms/step - loss: 1.2689 - top_1_categorical_accuracy: 0.5526 - top_2_categorical_accuracy: 0.7546 - top_3_categorical_accuracy: 0.8420 - top_4_categorical_accuracy: 0.8906 - top_5_categorical_accuracy: 0.9303 - top_6_categorical_accuracy: 0.9554 - top_7_categorical_accuracy: 0.9751 - top_8_categorical_accuracy: 0.9866 - top_9_categorical_accuracy: 0.9946 - precision_1: 0.7282 - recall_1: 0.3697 - accuracy: 0.0000e+00 - val_loss: 1.5759 - val_top_1_categorical_accuracy: 0.4707 - val_top_2_categorical_accuracy: 0.6820 - val_top_3_categorical_accuracy: 0.7747 - val_top_4_categorical_accuracy: 0.8480 - val_top_5_categorical_accuracy: 0.8887 - val_top_6_categorical_accuracy: 0.9253 - val_top_7_categorical_accuracy: 0.9480 - val_top_8_categorical_accuracy: 0.9667 - val_top_9_categorical_accuracy: 0.9847 - val_precision_1: 0.6038 - val_recall_1: 0.3180 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "70/70 [==============================] - 4s 55ms/step - loss: 1.2383 - top_1_categorical_accuracy: 0.5606 - top_2_categorical_accuracy: 0.7723 - top_3_categorical_accuracy: 0.8531 - top_4_categorical_accuracy: 0.9029 - top_5_categorical_accuracy: 0.9383 - top_6_categorical_accuracy: 0.9603 - top_7_categorical_accuracy: 0.9763 - top_8_categorical_accuracy: 0.9866 - top_9_categorical_accuracy: 0.9951 - precision_1: 0.7350 - recall_1: 0.3757 - accuracy: 0.0000e+00 - val_loss: 1.6418 - val_top_1_categorical_accuracy: 0.4553 - val_top_2_categorical_accuracy: 0.6700 - val_top_3_categorical_accuracy: 0.7780 - val_top_4_categorical_accuracy: 0.8513 - val_top_5_categorical_accuracy: 0.8967 - val_top_6_categorical_accuracy: 0.9367 - val_top_7_categorical_accuracy: 0.9593 - val_top_8_categorical_accuracy: 0.9767 - val_top_9_categorical_accuracy: 0.9913 - val_precision_1: 0.5766 - val_recall_1: 0.3413 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "70/70 [==============================] - 3s 48ms/step - loss: 1.2030 - top_1_categorical_accuracy: 0.5774 - top_2_categorical_accuracy: 0.7769 - top_3_categorical_accuracy: 0.8566 - top_4_categorical_accuracy: 0.9077 - top_5_categorical_accuracy: 0.9423 - top_6_categorical_accuracy: 0.9671 - top_7_categorical_accuracy: 0.9777 - top_8_categorical_accuracy: 0.9891 - top_9_categorical_accuracy: 0.9940 - precision_1: 0.7453 - recall_1: 0.3889 - accuracy: 0.0000e+00 - val_loss: 1.5650 - val_top_1_categorical_accuracy: 0.4793 - val_top_2_categorical_accuracy: 0.6807 - val_top_3_categorical_accuracy: 0.7780 - val_top_4_categorical_accuracy: 0.8447 - val_top_5_categorical_accuracy: 0.8927 - val_top_6_categorical_accuracy: 0.9260 - val_top_7_categorical_accuracy: 0.9513 - val_top_8_categorical_accuracy: 0.9720 - val_top_9_categorical_accuracy: 0.9887 - val_precision_1: 0.5995 - val_recall_1: 0.3473 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "70/70 [==============================] - 3s 48ms/step - loss: 1.2346 - top_1_categorical_accuracy: 0.5623 - top_2_categorical_accuracy: 0.7729 - top_3_categorical_accuracy: 0.8506 - top_4_categorical_accuracy: 0.9020 - top_5_categorical_accuracy: 0.9394 - top_6_categorical_accuracy: 0.9646 - top_7_categorical_accuracy: 0.9777 - top_8_categorical_accuracy: 0.9860 - top_9_categorical_accuracy: 0.9940 - precision_1: 0.7194 - recall_1: 0.3780 - accuracy: 0.0000e+00 - val_loss: 1.5463 - val_top_1_categorical_accuracy: 0.4707 - val_top_2_categorical_accuracy: 0.6773 - val_top_3_categorical_accuracy: 0.7787 - val_top_4_categorical_accuracy: 0.8447 - val_top_5_categorical_accuracy: 0.8907 - val_top_6_categorical_accuracy: 0.9300 - val_top_7_categorical_accuracy: 0.9533 - val_top_8_categorical_accuracy: 0.9720 - val_top_9_categorical_accuracy: 0.9907 - val_precision_1: 0.6060 - val_recall_1: 0.3220 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/100\n",
      "70/70 [==============================] - 4s 51ms/step - loss: 1.2344 - top_1_categorical_accuracy: 0.5763 - top_2_categorical_accuracy: 0.7700 - top_3_categorical_accuracy: 0.8503 - top_4_categorical_accuracy: 0.9009 - top_5_categorical_accuracy: 0.9360 - top_6_categorical_accuracy: 0.9594 - top_7_categorical_accuracy: 0.9749 - top_8_categorical_accuracy: 0.9869 - top_9_categorical_accuracy: 0.9937 - precision_1: 0.7411 - recall_1: 0.3869 - accuracy: 0.0000e+00 - val_loss: 1.6674 - val_top_1_categorical_accuracy: 0.4587 - val_top_2_categorical_accuracy: 0.6560 - val_top_3_categorical_accuracy: 0.7687 - val_top_4_categorical_accuracy: 0.8333 - val_top_5_categorical_accuracy: 0.8840 - val_top_6_categorical_accuracy: 0.9147 - val_top_7_categorical_accuracy: 0.9420 - val_top_8_categorical_accuracy: 0.9620 - val_top_9_categorical_accuracy: 0.9847 - val_precision_1: 0.5718 - val_recall_1: 0.3187 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "70/70 [==============================] - 3s 48ms/step - loss: 1.2363 - top_1_categorical_accuracy: 0.5803 - top_2_categorical_accuracy: 0.7814 - top_3_categorical_accuracy: 0.8546 - top_4_categorical_accuracy: 0.9029 - top_5_categorical_accuracy: 0.9360 - top_6_categorical_accuracy: 0.9609 - top_7_categorical_accuracy: 0.9746 - top_8_categorical_accuracy: 0.9849 - top_9_categorical_accuracy: 0.9940 - precision_1: 0.7505 - recall_1: 0.3911 - accuracy: 0.0000e+00 - val_loss: 1.5818 - val_top_1_categorical_accuracy: 0.4600 - val_top_2_categorical_accuracy: 0.6767 - val_top_3_categorical_accuracy: 0.7880 - val_top_4_categorical_accuracy: 0.8460 - val_top_5_categorical_accuracy: 0.8947 - val_top_6_categorical_accuracy: 0.9247 - val_top_7_categorical_accuracy: 0.9587 - val_top_8_categorical_accuracy: 0.9727 - val_top_9_categorical_accuracy: 0.9873 - val_precision_1: 0.5928 - val_recall_1: 0.3193 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "70/70 [==============================] - 3s 49ms/step - loss: 1.2177 - top_1_categorical_accuracy: 0.5797 - top_2_categorical_accuracy: 0.7811 - top_3_categorical_accuracy: 0.8500 - top_4_categorical_accuracy: 0.8997 - top_5_categorical_accuracy: 0.9334 - top_6_categorical_accuracy: 0.9586 - top_7_categorical_accuracy: 0.9743 - top_8_categorical_accuracy: 0.9843 - top_9_categorical_accuracy: 0.9940 - precision_1: 0.7609 - recall_1: 0.3837 - accuracy: 0.0000e+00 - val_loss: 1.6189 - val_top_1_categorical_accuracy: 0.4707 - val_top_2_categorical_accuracy: 0.6753 - val_top_3_categorical_accuracy: 0.7820 - val_top_4_categorical_accuracy: 0.8487 - val_top_5_categorical_accuracy: 0.9000 - val_top_6_categorical_accuracy: 0.9253 - val_top_7_categorical_accuracy: 0.9533 - val_top_8_categorical_accuracy: 0.9707 - val_top_9_categorical_accuracy: 0.9893 - val_precision_1: 0.5883 - val_recall_1: 0.3553 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "70/70 [==============================] - 3s 50ms/step - loss: 1.1782 - top_1_categorical_accuracy: 0.5903 - top_2_categorical_accuracy: 0.7951 - top_3_categorical_accuracy: 0.8674 - top_4_categorical_accuracy: 0.9080 - top_5_categorical_accuracy: 0.9371 - top_6_categorical_accuracy: 0.9617 - top_7_categorical_accuracy: 0.9789 - top_8_categorical_accuracy: 0.9883 - top_9_categorical_accuracy: 0.9931 - precision_1: 0.7693 - recall_1: 0.4163 - accuracy: 0.0000e+00 - val_loss: 1.5941 - val_top_1_categorical_accuracy: 0.4713 - val_top_2_categorical_accuracy: 0.6873 - val_top_3_categorical_accuracy: 0.7873 - val_top_4_categorical_accuracy: 0.8427 - val_top_5_categorical_accuracy: 0.8967 - val_top_6_categorical_accuracy: 0.9253 - val_top_7_categorical_accuracy: 0.9547 - val_top_8_categorical_accuracy: 0.9713 - val_top_9_categorical_accuracy: 0.9867 - val_precision_1: 0.5914 - val_recall_1: 0.3580 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "70/70 [==============================] - 3s 48ms/step - loss: 1.1835 - top_1_categorical_accuracy: 0.5831 - top_2_categorical_accuracy: 0.7834 - top_3_categorical_accuracy: 0.8637 - top_4_categorical_accuracy: 0.9111 - top_5_categorical_accuracy: 0.9423 - top_6_categorical_accuracy: 0.9640 - top_7_categorical_accuracy: 0.9774 - top_8_categorical_accuracy: 0.9877 - top_9_categorical_accuracy: 0.9934 - precision_1: 0.7416 - recall_1: 0.4109 - accuracy: 0.0000e+00 - val_loss: 1.6138 - val_top_1_categorical_accuracy: 0.4780 - val_top_2_categorical_accuracy: 0.6820 - val_top_3_categorical_accuracy: 0.7800 - val_top_4_categorical_accuracy: 0.8553 - val_top_5_categorical_accuracy: 0.8967 - val_top_6_categorical_accuracy: 0.9247 - val_top_7_categorical_accuracy: 0.9513 - val_top_8_categorical_accuracy: 0.9673 - val_top_9_categorical_accuracy: 0.9880 - val_precision_1: 0.6130 - val_recall_1: 0.3400 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "70/70 [==============================] - 4s 52ms/step - loss: 1.1354 - top_1_categorical_accuracy: 0.6074 - top_2_categorical_accuracy: 0.7943 - top_3_categorical_accuracy: 0.8640 - top_4_categorical_accuracy: 0.9106 - top_5_categorical_accuracy: 0.9406 - top_6_categorical_accuracy: 0.9657 - top_7_categorical_accuracy: 0.9789 - top_8_categorical_accuracy: 0.9903 - top_9_categorical_accuracy: 0.9957 - precision_1: 0.7673 - recall_1: 0.4249 - accuracy: 0.0000e+00 - val_loss: 1.6379 - val_top_1_categorical_accuracy: 0.4527 - val_top_2_categorical_accuracy: 0.6567 - val_top_3_categorical_accuracy: 0.7520 - val_top_4_categorical_accuracy: 0.8300 - val_top_5_categorical_accuracy: 0.8873 - val_top_6_categorical_accuracy: 0.9160 - val_top_7_categorical_accuracy: 0.9493 - val_top_8_categorical_accuracy: 0.9693 - val_top_9_categorical_accuracy: 0.9880 - val_precision_1: 0.5924 - val_recall_1: 0.3333 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "70/70 [==============================] - 3s 48ms/step - loss: 1.1559 - top_1_categorical_accuracy: 0.5986 - top_2_categorical_accuracy: 0.7969 - top_3_categorical_accuracy: 0.8689 - top_4_categorical_accuracy: 0.9126 - top_5_categorical_accuracy: 0.9426 - top_6_categorical_accuracy: 0.9666 - top_7_categorical_accuracy: 0.9791 - top_8_categorical_accuracy: 0.9891 - top_9_categorical_accuracy: 0.9949 - precision_1: 0.7524 - recall_1: 0.4263 - accuracy: 0.0000e+00 - val_loss: 1.5861 - val_top_1_categorical_accuracy: 0.4840 - val_top_2_categorical_accuracy: 0.6747 - val_top_3_categorical_accuracy: 0.7740 - val_top_4_categorical_accuracy: 0.8427 - val_top_5_categorical_accuracy: 0.8800 - val_top_6_categorical_accuracy: 0.9233 - val_top_7_categorical_accuracy: 0.9507 - val_top_8_categorical_accuracy: 0.9727 - val_top_9_categorical_accuracy: 0.9913 - val_precision_1: 0.5964 - val_recall_1: 0.3567 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "70/70 [==============================] - 3s 48ms/step - loss: 1.1500 - top_1_categorical_accuracy: 0.6006 - top_2_categorical_accuracy: 0.7914 - top_3_categorical_accuracy: 0.8711 - top_4_categorical_accuracy: 0.9163 - top_5_categorical_accuracy: 0.9469 - top_6_categorical_accuracy: 0.9686 - top_7_categorical_accuracy: 0.9809 - top_8_categorical_accuracy: 0.9894 - top_9_categorical_accuracy: 0.9971 - precision_1: 0.7567 - recall_1: 0.4371 - accuracy: 0.0000e+00 - val_loss: 1.6080 - val_top_1_categorical_accuracy: 0.4700 - val_top_2_categorical_accuracy: 0.6727 - val_top_3_categorical_accuracy: 0.7840 - val_top_4_categorical_accuracy: 0.8427 - val_top_5_categorical_accuracy: 0.8800 - val_top_6_categorical_accuracy: 0.9200 - val_top_7_categorical_accuracy: 0.9473 - val_top_8_categorical_accuracy: 0.9727 - val_top_9_categorical_accuracy: 0.9873 - val_precision_1: 0.5827 - val_recall_1: 0.3500 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "70/70 [==============================] - 3s 49ms/step - loss: 1.1097 - top_1_categorical_accuracy: 0.6120 - top_2_categorical_accuracy: 0.8034 - top_3_categorical_accuracy: 0.8731 - top_4_categorical_accuracy: 0.9180 - top_5_categorical_accuracy: 0.9489 - top_6_categorical_accuracy: 0.9691 - top_7_categorical_accuracy: 0.9834 - top_8_categorical_accuracy: 0.9920 - top_9_categorical_accuracy: 0.9971 - precision_1: 0.7553 - recall_1: 0.4471 - accuracy: 0.0000e+00 - val_loss: 1.6278 - val_top_1_categorical_accuracy: 0.4600 - val_top_2_categorical_accuracy: 0.6820 - val_top_3_categorical_accuracy: 0.7780 - val_top_4_categorical_accuracy: 0.8427 - val_top_5_categorical_accuracy: 0.8907 - val_top_6_categorical_accuracy: 0.9287 - val_top_7_categorical_accuracy: 0.9540 - val_top_8_categorical_accuracy: 0.9753 - val_top_9_categorical_accuracy: 0.9907 - val_precision_1: 0.5606 - val_recall_1: 0.3547 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/100\n",
      "70/70 [==============================] - 4s 52ms/step - loss: 1.1336 - top_1_categorical_accuracy: 0.6109 - top_2_categorical_accuracy: 0.7991 - top_3_categorical_accuracy: 0.8769 - top_4_categorical_accuracy: 0.9183 - top_5_categorical_accuracy: 0.9486 - top_6_categorical_accuracy: 0.9654 - top_7_categorical_accuracy: 0.9780 - top_8_categorical_accuracy: 0.9869 - top_9_categorical_accuracy: 0.9954 - precision_1: 0.7479 - recall_1: 0.4551 - accuracy: 0.0000e+00 - val_loss: 1.6076 - val_top_1_categorical_accuracy: 0.4633 - val_top_2_categorical_accuracy: 0.6773 - val_top_3_categorical_accuracy: 0.7640 - val_top_4_categorical_accuracy: 0.8273 - val_top_5_categorical_accuracy: 0.8827 - val_top_6_categorical_accuracy: 0.9267 - val_top_7_categorical_accuracy: 0.9513 - val_top_8_categorical_accuracy: 0.9713 - val_top_9_categorical_accuracy: 0.9880 - val_precision_1: 0.5817 - val_recall_1: 0.3467 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "70/70 [==============================] - 3s 49ms/step - loss: 1.0770 - top_1_categorical_accuracy: 0.6237 - top_2_categorical_accuracy: 0.8183 - top_3_categorical_accuracy: 0.8834 - top_4_categorical_accuracy: 0.9206 - top_5_categorical_accuracy: 0.9506 - top_6_categorical_accuracy: 0.9703 - top_7_categorical_accuracy: 0.9789 - top_8_categorical_accuracy: 0.9866 - top_9_categorical_accuracy: 0.9954 - precision_1: 0.7664 - recall_1: 0.4649 - accuracy: 0.0000e+00 - val_loss: 1.6137 - val_top_1_categorical_accuracy: 0.4787 - val_top_2_categorical_accuracy: 0.6780 - val_top_3_categorical_accuracy: 0.7707 - val_top_4_categorical_accuracy: 0.8440 - val_top_5_categorical_accuracy: 0.8947 - val_top_6_categorical_accuracy: 0.9227 - val_top_7_categorical_accuracy: 0.9527 - val_top_8_categorical_accuracy: 0.9727 - val_top_9_categorical_accuracy: 0.9873 - val_precision_1: 0.5920 - val_recall_1: 0.3753 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "70/70 [==============================] - 3s 48ms/step - loss: 1.1009 - top_1_categorical_accuracy: 0.6206 - top_2_categorical_accuracy: 0.8031 - top_3_categorical_accuracy: 0.8700 - top_4_categorical_accuracy: 0.9134 - top_5_categorical_accuracy: 0.9500 - top_6_categorical_accuracy: 0.9683 - top_7_categorical_accuracy: 0.9794 - top_8_categorical_accuracy: 0.9871 - top_9_categorical_accuracy: 0.9954 - precision_1: 0.7855 - recall_1: 0.4677 - accuracy: 0.0000e+00 - val_loss: 1.6445 - val_top_1_categorical_accuracy: 0.4853 - val_top_2_categorical_accuracy: 0.6780 - val_top_3_categorical_accuracy: 0.7667 - val_top_4_categorical_accuracy: 0.8333 - val_top_5_categorical_accuracy: 0.8853 - val_top_6_categorical_accuracy: 0.9213 - val_top_7_categorical_accuracy: 0.9480 - val_top_8_categorical_accuracy: 0.9687 - val_top_9_categorical_accuracy: 0.9847 - val_precision_1: 0.5933 - val_recall_1: 0.3773 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "70/70 [==============================] - 3s 49ms/step - loss: 1.0918 - top_1_categorical_accuracy: 0.6214 - top_2_categorical_accuracy: 0.8046 - top_3_categorical_accuracy: 0.8751 - top_4_categorical_accuracy: 0.9197 - top_5_categorical_accuracy: 0.9477 - top_6_categorical_accuracy: 0.9691 - top_7_categorical_accuracy: 0.9826 - top_8_categorical_accuracy: 0.9894 - top_9_categorical_accuracy: 0.9951 - precision_1: 0.7611 - recall_1: 0.4734 - accuracy: 0.0000e+00 - val_loss: 1.6112 - val_top_1_categorical_accuracy: 0.4873 - val_top_2_categorical_accuracy: 0.6913 - val_top_3_categorical_accuracy: 0.7820 - val_top_4_categorical_accuracy: 0.8380 - val_top_5_categorical_accuracy: 0.8880 - val_top_6_categorical_accuracy: 0.9220 - val_top_7_categorical_accuracy: 0.9567 - val_top_8_categorical_accuracy: 0.9753 - val_top_9_categorical_accuracy: 0.9907 - val_precision_1: 0.5977 - val_recall_1: 0.3833 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "70/70 [==============================] - 3s 48ms/step - loss: 1.1310 - top_1_categorical_accuracy: 0.6243 - top_2_categorical_accuracy: 0.8014 - top_3_categorical_accuracy: 0.8726 - top_4_categorical_accuracy: 0.9166 - top_5_categorical_accuracy: 0.9463 - top_6_categorical_accuracy: 0.9686 - top_7_categorical_accuracy: 0.9823 - top_8_categorical_accuracy: 0.9894 - top_9_categorical_accuracy: 0.9957 - precision_1: 0.7617 - recall_1: 0.4677 - accuracy: 0.0000e+00 - val_loss: 1.6518 - val_top_1_categorical_accuracy: 0.4827 - val_top_2_categorical_accuracy: 0.6900 - val_top_3_categorical_accuracy: 0.7733 - val_top_4_categorical_accuracy: 0.8347 - val_top_5_categorical_accuracy: 0.8907 - val_top_6_categorical_accuracy: 0.9220 - val_top_7_categorical_accuracy: 0.9540 - val_top_8_categorical_accuracy: 0.9753 - val_top_9_categorical_accuracy: 0.9893 - val_precision_1: 0.5673 - val_recall_1: 0.3767 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "70/70 [==============================] - 3s 49ms/step - loss: 1.0718 - top_1_categorical_accuracy: 0.6234 - top_2_categorical_accuracy: 0.8151 - top_3_categorical_accuracy: 0.8843 - top_4_categorical_accuracy: 0.9280 - top_5_categorical_accuracy: 0.9500 - top_6_categorical_accuracy: 0.9677 - top_7_categorical_accuracy: 0.9817 - top_8_categorical_accuracy: 0.9894 - top_9_categorical_accuracy: 0.9966 - precision_1: 0.7704 - recall_1: 0.4640 - accuracy: 0.0000e+00 - val_loss: 1.6305 - val_top_1_categorical_accuracy: 0.4947 - val_top_2_categorical_accuracy: 0.6933 - val_top_3_categorical_accuracy: 0.7833 - val_top_4_categorical_accuracy: 0.8373 - val_top_5_categorical_accuracy: 0.8833 - val_top_6_categorical_accuracy: 0.9227 - val_top_7_categorical_accuracy: 0.9587 - val_top_8_categorical_accuracy: 0.9753 - val_top_9_categorical_accuracy: 0.9900 - val_precision_1: 0.5867 - val_recall_1: 0.4107 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "70/70 [==============================] - 3s 49ms/step - loss: 1.0558 - top_1_categorical_accuracy: 0.6309 - top_2_categorical_accuracy: 0.8223 - top_3_categorical_accuracy: 0.8943 - top_4_categorical_accuracy: 0.9320 - top_5_categorical_accuracy: 0.9571 - top_6_categorical_accuracy: 0.9746 - top_7_categorical_accuracy: 0.9857 - top_8_categorical_accuracy: 0.9931 - top_9_categorical_accuracy: 0.9980 - precision_1: 0.7598 - recall_1: 0.4863 - accuracy: 0.0000e+00 - val_loss: 1.5842 - val_top_1_categorical_accuracy: 0.4780 - val_top_2_categorical_accuracy: 0.6740 - val_top_3_categorical_accuracy: 0.7620 - val_top_4_categorical_accuracy: 0.8287 - val_top_5_categorical_accuracy: 0.8880 - val_top_6_categorical_accuracy: 0.9187 - val_top_7_categorical_accuracy: 0.9473 - val_top_8_categorical_accuracy: 0.9673 - val_top_9_categorical_accuracy: 0.9827 - val_precision_1: 0.6153 - val_recall_1: 0.3647 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "\n",
    "date = pendulum.now().__str__()[:16].replace(\"T\",\"_\").replace(\":\",\"_\")\n",
    "\n",
    "RESULTS_DIR = f'vit-ResidualMLP-image-classifier_{date}'\n",
    "PATIENCE = 25\n",
    "PATIENCE_MIN_DELTA = 0.00001\n",
    "BATCH_SIZE = 50\n",
    "EPOCHS = 100\n",
    "\n",
    "logdir = os.path.join(\"logs\", RESULTS_DIR + \"_TB\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "\n",
    "history = final_residual_mlp.fit(\n",
    "    x=selected_x_train,\n",
    "    y=selected_y_train_ohe,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    verbose=\"auto\",\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor=\"val_loss\",\n",
    "            patience=PATIENCE,\n",
    "            min_delta=PATIENCE_MIN_DELTA,\n",
    "            restore_best_weights=True,\n",
    "        ),\n",
    "        tensorboard_callback,\n",
    "    ],\n",
    "    validation_split=0.3,\n",
    "    validation_data=None,\n",
    "    shuffle=True,\n",
    "    class_weight=None,\n",
    "    sample_weight=None,\n",
    "    initial_epoch=0,\n",
    "    steps_per_epoch=None,\n",
    "    validation_steps=None,\n",
    "    validation_batch_size=10,\n",
    "    validation_freq=1,\n",
    "    max_queue_size=10,\n",
    "    workers=5,\n",
    "    use_multiprocessing=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6bc273a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hy = pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ab5378db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>top_1_categorical_accuracy</th>\n",
       "      <th>top_2_categorical_accuracy</th>\n",
       "      <th>top_3_categorical_accuracy</th>\n",
       "      <th>top_4_categorical_accuracy</th>\n",
       "      <th>top_5_categorical_accuracy</th>\n",
       "      <th>top_6_categorical_accuracy</th>\n",
       "      <th>top_7_categorical_accuracy</th>\n",
       "      <th>top_8_categorical_accuracy</th>\n",
       "      <th>top_9_categorical_accuracy</th>\n",
       "      <th>...</th>\n",
       "      <th>val_top_3_categorical_accuracy</th>\n",
       "      <th>val_top_4_categorical_accuracy</th>\n",
       "      <th>val_top_5_categorical_accuracy</th>\n",
       "      <th>val_top_6_categorical_accuracy</th>\n",
       "      <th>val_top_7_categorical_accuracy</th>\n",
       "      <th>val_top_8_categorical_accuracy</th>\n",
       "      <th>val_top_9_categorical_accuracy</th>\n",
       "      <th>val_precision_1</th>\n",
       "      <th>val_recall_1</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.507020</td>\n",
       "      <td>0.097429</td>\n",
       "      <td>0.208286</td>\n",
       "      <td>0.309714</td>\n",
       "      <td>0.416571</td>\n",
       "      <td>0.516286</td>\n",
       "      <td>0.612286</td>\n",
       "      <td>0.709429</td>\n",
       "      <td>0.815429</td>\n",
       "      <td>0.906571</td>\n",
       "      <td>...</td>\n",
       "      <td>0.334667</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.519333</td>\n",
       "      <td>0.614000</td>\n",
       "      <td>0.694000</td>\n",
       "      <td>0.792667</td>\n",
       "      <td>0.880667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.375168</td>\n",
       "      <td>0.116000</td>\n",
       "      <td>0.231714</td>\n",
       "      <td>0.333429</td>\n",
       "      <td>0.436571</td>\n",
       "      <td>0.539429</td>\n",
       "      <td>0.631429</td>\n",
       "      <td>0.728286</td>\n",
       "      <td>0.825714</td>\n",
       "      <td>0.910571</td>\n",
       "      <td>...</td>\n",
       "      <td>0.300667</td>\n",
       "      <td>0.392667</td>\n",
       "      <td>0.474667</td>\n",
       "      <td>0.590667</td>\n",
       "      <td>0.710667</td>\n",
       "      <td>0.815333</td>\n",
       "      <td>0.910667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.341347</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.243143</td>\n",
       "      <td>0.343143</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.538000</td>\n",
       "      <td>0.635429</td>\n",
       "      <td>0.732857</td>\n",
       "      <td>0.827143</td>\n",
       "      <td>0.912857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.309333</td>\n",
       "      <td>0.399333</td>\n",
       "      <td>0.491333</td>\n",
       "      <td>0.592667</td>\n",
       "      <td>0.704000</td>\n",
       "      <td>0.806000</td>\n",
       "      <td>0.906000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.345788</td>\n",
       "      <td>0.110000</td>\n",
       "      <td>0.220286</td>\n",
       "      <td>0.318286</td>\n",
       "      <td>0.418000</td>\n",
       "      <td>0.518000</td>\n",
       "      <td>0.613714</td>\n",
       "      <td>0.709714</td>\n",
       "      <td>0.807429</td>\n",
       "      <td>0.907429</td>\n",
       "      <td>...</td>\n",
       "      <td>0.386000</td>\n",
       "      <td>0.491333</td>\n",
       "      <td>0.571333</td>\n",
       "      <td>0.663333</td>\n",
       "      <td>0.755333</td>\n",
       "      <td>0.845333</td>\n",
       "      <td>0.928667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.291778</td>\n",
       "      <td>0.131143</td>\n",
       "      <td>0.259143</td>\n",
       "      <td>0.369714</td>\n",
       "      <td>0.471429</td>\n",
       "      <td>0.558286</td>\n",
       "      <td>0.648857</td>\n",
       "      <td>0.738857</td>\n",
       "      <td>0.832286</td>\n",
       "      <td>0.918571</td>\n",
       "      <td>...</td>\n",
       "      <td>0.424000</td>\n",
       "      <td>0.524667</td>\n",
       "      <td>0.604667</td>\n",
       "      <td>0.679333</td>\n",
       "      <td>0.787333</td>\n",
       "      <td>0.864667</td>\n",
       "      <td>0.939333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>1.100874</td>\n",
       "      <td>0.620571</td>\n",
       "      <td>0.803143</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>0.913429</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.968286</td>\n",
       "      <td>0.979429</td>\n",
       "      <td>0.987143</td>\n",
       "      <td>0.995429</td>\n",
       "      <td>...</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.885333</td>\n",
       "      <td>0.921333</td>\n",
       "      <td>0.948000</td>\n",
       "      <td>0.968667</td>\n",
       "      <td>0.984667</td>\n",
       "      <td>0.593291</td>\n",
       "      <td>0.377333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>1.091774</td>\n",
       "      <td>0.621429</td>\n",
       "      <td>0.804571</td>\n",
       "      <td>0.875143</td>\n",
       "      <td>0.919714</td>\n",
       "      <td>0.947714</td>\n",
       "      <td>0.969143</td>\n",
       "      <td>0.982571</td>\n",
       "      <td>0.989429</td>\n",
       "      <td>0.995143</td>\n",
       "      <td>...</td>\n",
       "      <td>0.782000</td>\n",
       "      <td>0.838000</td>\n",
       "      <td>0.888000</td>\n",
       "      <td>0.922000</td>\n",
       "      <td>0.956667</td>\n",
       "      <td>0.975333</td>\n",
       "      <td>0.990667</td>\n",
       "      <td>0.597713</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>1.131027</td>\n",
       "      <td>0.624286</td>\n",
       "      <td>0.801429</td>\n",
       "      <td>0.872571</td>\n",
       "      <td>0.916571</td>\n",
       "      <td>0.946286</td>\n",
       "      <td>0.968571</td>\n",
       "      <td>0.982286</td>\n",
       "      <td>0.989429</td>\n",
       "      <td>0.995714</td>\n",
       "      <td>...</td>\n",
       "      <td>0.773333</td>\n",
       "      <td>0.834667</td>\n",
       "      <td>0.890667</td>\n",
       "      <td>0.922000</td>\n",
       "      <td>0.954000</td>\n",
       "      <td>0.975333</td>\n",
       "      <td>0.989333</td>\n",
       "      <td>0.567269</td>\n",
       "      <td>0.376667</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>1.071786</td>\n",
       "      <td>0.623429</td>\n",
       "      <td>0.815143</td>\n",
       "      <td>0.884286</td>\n",
       "      <td>0.928000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.967714</td>\n",
       "      <td>0.981714</td>\n",
       "      <td>0.989429</td>\n",
       "      <td>0.996571</td>\n",
       "      <td>...</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.837333</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.922667</td>\n",
       "      <td>0.958667</td>\n",
       "      <td>0.975333</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.586667</td>\n",
       "      <td>0.410667</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>1.055765</td>\n",
       "      <td>0.630857</td>\n",
       "      <td>0.822286</td>\n",
       "      <td>0.894286</td>\n",
       "      <td>0.932000</td>\n",
       "      <td>0.957143</td>\n",
       "      <td>0.974571</td>\n",
       "      <td>0.985714</td>\n",
       "      <td>0.993143</td>\n",
       "      <td>0.998000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.762000</td>\n",
       "      <td>0.828667</td>\n",
       "      <td>0.888000</td>\n",
       "      <td>0.918667</td>\n",
       "      <td>0.947333</td>\n",
       "      <td>0.967333</td>\n",
       "      <td>0.982667</td>\n",
       "      <td>0.615298</td>\n",
       "      <td>0.364667</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>87 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss  top_1_categorical_accuracy  top_2_categorical_accuracy  \\\n",
       "0   2.507020                    0.097429                    0.208286   \n",
       "1   2.375168                    0.116000                    0.231714   \n",
       "2   2.341347                    0.130000                    0.243143   \n",
       "3   2.345788                    0.110000                    0.220286   \n",
       "4   2.291778                    0.131143                    0.259143   \n",
       "..       ...                         ...                         ...   \n",
       "82  1.100874                    0.620571                    0.803143   \n",
       "83  1.091774                    0.621429                    0.804571   \n",
       "84  1.131027                    0.624286                    0.801429   \n",
       "85  1.071786                    0.623429                    0.815143   \n",
       "86  1.055765                    0.630857                    0.822286   \n",
       "\n",
       "    top_3_categorical_accuracy  top_4_categorical_accuracy  \\\n",
       "0                     0.309714                    0.416571   \n",
       "1                     0.333429                    0.436571   \n",
       "2                     0.343143                    0.440000   \n",
       "3                     0.318286                    0.418000   \n",
       "4                     0.369714                    0.471429   \n",
       "..                         ...                         ...   \n",
       "82                    0.870000                    0.913429   \n",
       "83                    0.875143                    0.919714   \n",
       "84                    0.872571                    0.916571   \n",
       "85                    0.884286                    0.928000   \n",
       "86                    0.894286                    0.932000   \n",
       "\n",
       "    top_5_categorical_accuracy  top_6_categorical_accuracy  \\\n",
       "0                     0.516286                    0.612286   \n",
       "1                     0.539429                    0.631429   \n",
       "2                     0.538000                    0.635429   \n",
       "3                     0.518000                    0.613714   \n",
       "4                     0.558286                    0.648857   \n",
       "..                         ...                         ...   \n",
       "82                    0.950000                    0.968286   \n",
       "83                    0.947714                    0.969143   \n",
       "84                    0.946286                    0.968571   \n",
       "85                    0.950000                    0.967714   \n",
       "86                    0.957143                    0.974571   \n",
       "\n",
       "    top_7_categorical_accuracy  top_8_categorical_accuracy  \\\n",
       "0                     0.709429                    0.815429   \n",
       "1                     0.728286                    0.825714   \n",
       "2                     0.732857                    0.827143   \n",
       "3                     0.709714                    0.807429   \n",
       "4                     0.738857                    0.832286   \n",
       "..                         ...                         ...   \n",
       "82                    0.979429                    0.987143   \n",
       "83                    0.982571                    0.989429   \n",
       "84                    0.982286                    0.989429   \n",
       "85                    0.981714                    0.989429   \n",
       "86                    0.985714                    0.993143   \n",
       "\n",
       "    top_9_categorical_accuracy  ...  val_top_3_categorical_accuracy  \\\n",
       "0                     0.906571  ...                        0.334667   \n",
       "1                     0.910571  ...                        0.300667   \n",
       "2                     0.912857  ...                        0.309333   \n",
       "3                     0.907429  ...                        0.386000   \n",
       "4                     0.918571  ...                        0.424000   \n",
       "..                         ...  ...                             ...   \n",
       "82                    0.995429  ...                        0.766667   \n",
       "83                    0.995143  ...                        0.782000   \n",
       "84                    0.995714  ...                        0.773333   \n",
       "85                    0.996571  ...                        0.783333   \n",
       "86                    0.998000  ...                        0.762000   \n",
       "\n",
       "    val_top_4_categorical_accuracy  val_top_5_categorical_accuracy  \\\n",
       "0                         0.420000                        0.519333   \n",
       "1                         0.392667                        0.474667   \n",
       "2                         0.399333                        0.491333   \n",
       "3                         0.491333                        0.571333   \n",
       "4                         0.524667                        0.604667   \n",
       "..                             ...                             ...   \n",
       "82                        0.833333                        0.885333   \n",
       "83                        0.838000                        0.888000   \n",
       "84                        0.834667                        0.890667   \n",
       "85                        0.837333                        0.883333   \n",
       "86                        0.828667                        0.888000   \n",
       "\n",
       "    val_top_6_categorical_accuracy  val_top_7_categorical_accuracy  \\\n",
       "0                         0.614000                        0.694000   \n",
       "1                         0.590667                        0.710667   \n",
       "2                         0.592667                        0.704000   \n",
       "3                         0.663333                        0.755333   \n",
       "4                         0.679333                        0.787333   \n",
       "..                             ...                             ...   \n",
       "82                        0.921333                        0.948000   \n",
       "83                        0.922000                        0.956667   \n",
       "84                        0.922000                        0.954000   \n",
       "85                        0.922667                        0.958667   \n",
       "86                        0.918667                        0.947333   \n",
       "\n",
       "    val_top_8_categorical_accuracy  val_top_9_categorical_accuracy  \\\n",
       "0                         0.792667                        0.880667   \n",
       "1                         0.815333                        0.910667   \n",
       "2                         0.806000                        0.906000   \n",
       "3                         0.845333                        0.928667   \n",
       "4                         0.864667                        0.939333   \n",
       "..                             ...                             ...   \n",
       "82                        0.968667                        0.984667   \n",
       "83                        0.975333                        0.990667   \n",
       "84                        0.975333                        0.989333   \n",
       "85                        0.975333                        0.990000   \n",
       "86                        0.967333                        0.982667   \n",
       "\n",
       "    val_precision_1  val_recall_1  val_accuracy  \n",
       "0          0.000000      0.000000           0.0  \n",
       "1          0.000000      0.000000           0.0  \n",
       "2          0.000000      0.000000           0.0  \n",
       "3          0.000000      0.000000           0.0  \n",
       "4          0.000000      0.000000           0.0  \n",
       "..              ...           ...           ...  \n",
       "82         0.593291      0.377333           0.0  \n",
       "83         0.597713      0.383333           0.0  \n",
       "84         0.567269      0.376667           0.0  \n",
       "85         0.586667      0.410667           0.0  \n",
       "86         0.615298      0.364667           0.0  \n",
       "\n",
       "[87 rows x 26 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f3746a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "hy.to_csv(f'{date}_test_history.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a9cdd6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "hy.to_json(f'{date}_test_history.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f62440fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['loss', 'top_1_categorical_accuracy', 'top_2_categorical_accuracy',\n",
       "       'top_3_categorical_accuracy', 'top_4_categorical_accuracy',\n",
       "       'top_5_categorical_accuracy', 'top_6_categorical_accuracy',\n",
       "       'top_7_categorical_accuracy', 'top_8_categorical_accuracy',\n",
       "       'top_9_categorical_accuracy', 'precision_1', 'recall_1', 'accuracy',\n",
       "       'val_loss', 'val_top_1_categorical_accuracy',\n",
       "       'val_top_2_categorical_accuracy', 'val_top_3_categorical_accuracy',\n",
       "       'val_top_4_categorical_accuracy', 'val_top_5_categorical_accuracy',\n",
       "       'val_top_6_categorical_accuracy', 'val_top_7_categorical_accuracy',\n",
       "       'val_top_8_categorical_accuracy', 'val_top_9_categorical_accuracy',\n",
       "       'val_precision_1', 'val_recall_1', 'val_accuracy'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hy.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d61afa80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hy[['top_1_categorical_accuracy','val_top_1_categorical_accuracy']].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3b0e3a",
   "metadata": {},
   "source": [
    "# A little better, but still was not a great run. Things to try:\n",
    "1. Continue optimizing transformer_layers. \n",
    "2. First try bnorm in the main block of Dense layers. The diminishing gradient over epochs may be a sign of internal covariate shift.\n",
    "3. Try a less complex model:\n",
    "    1. Try fewer layers per block \n",
    "    2. Smaller layers in blocks\n",
    "    3. Less Dense units on residual bypass\n",
    "4. Optimize learning rate \n",
    "5. Start with a suitable pre-trained vision transformer as a base model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fbada6de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "top_1_categorical_accuracy        0.630857\n",
       "val_top_1_categorical_accuracy    0.494667\n",
       "dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hy[['top_1_categorical_accuracy','val_top_1_categorical_accuracy']].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa08628",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
