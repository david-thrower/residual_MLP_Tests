{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9791e0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "TRAINING_SET_SIZE = 5000\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29b66024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.5.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.3 MB 21.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (21.0)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.3.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 29.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (1.19.4)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.28.5-py3-none-any.whl (890 kB)\n",
      "\u001b[K     |████████████████████████████████| 890 kB 22.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pillow>=6.2.0\n",
      "  Downloading Pillow-9.0.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.3 MB 26.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cycler>=0.10\n",
      "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7->matplotlib) (1.15.0)\n",
      "Installing collected packages: pillow, kiwisolver, fonttools, cycler, matplotlib\n",
      "Successfully installed cycler-0.11.0 fonttools-4.28.5 kiwisolver-1.3.2 matplotlib-3.5.1 pillow-9.0.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.8/dist-packages (0.13.1)\n",
      "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.8/dist-packages (from tensorflow-addons) (2.12.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting pandas\n",
      "  Downloading pandas-1.3.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.5 MB 19.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (1.19.4)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "Installing collected packages: pandas\n",
      "Successfully installed pandas-1.3.5\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting pendulum\n",
      "  Downloading pendulum-2.1.2-cp38-cp38-manylinux1_x86_64.whl (155 kB)\n",
      "\u001b[K     |████████████████████████████████| 155 kB 24.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil<3.0,>=2.6 in /usr/local/lib/python3.8/dist-packages (from pendulum) (2.8.2)\n",
      "Collecting pytzdata>=2020.1\n",
      "  Downloading pytzdata-2020.1-py2.py3-none-any.whl (489 kB)\n",
      "\u001b[K     |████████████████████████████████| 489 kB 28.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil<3.0,>=2.6->pendulum) (1.15.0)\n",
      "Installing collected packages: pytzdata, pendulum\n",
      "Successfully installed pendulum-2.1.2 pytzdata-2020.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting keras_tuner\n",
      "  Downloading keras_tuner-1.1.0-py3-none-any.whl (98 kB)\n",
      "\u001b[K     |████████████████████████████████| 98 kB 10.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting kt-legacy\n",
      "  Downloading kt_legacy-1.0.4-py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: ipython in /usr/local/lib/python3.8/dist-packages (from keras_tuner) (7.27.0)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from keras_tuner) (1.4.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from keras_tuner) (21.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from keras_tuner) (1.19.4)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from keras_tuner) (2.26.0)\n",
      "Requirement already satisfied: tensorboard in /usr/local/lib/python3.8/dist-packages (from keras_tuner) (2.6.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.8/dist-packages (from ipython->keras_tuner) (4.7.0)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from ipython->keras_tuner) (5.1.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.8/dist-packages (from ipython->keras_tuner) (58.1.0)\n",
      "Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from ipython->keras_tuner) (0.2.0)\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.8/dist-packages (from ipython->keras_tuner) (2.10.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.8/dist-packages (from ipython->keras_tuner) (0.18.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from ipython->keras_tuner) (3.0.20)\n",
      "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.8/dist-packages (from ipython->keras_tuner) (5.1.0)\n",
      "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.8/dist-packages (from ipython->keras_tuner) (0.1.3)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from ipython->keras_tuner) (0.7.5)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.16->ipython->keras_tuner) (0.8.2)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.8/dist-packages (from pexpect>4.3->ipython->keras_tuner) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->keras_tuner) (0.2.5)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->keras_tuner) (2.4.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->keras_tuner) (2021.5.30)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.8/dist-packages (from requests->keras_tuner) (2.0.6)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->keras_tuner) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->keras_tuner) (3.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard->keras_tuner) (0.4.6)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.8/dist-packages (from tensorboard->keras_tuner) (0.12.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard->keras_tuner) (0.6.1)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard->keras_tuner) (1.39.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard->keras_tuner) (1.35.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard->keras_tuner) (1.8.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.8/dist-packages (from tensorboard->keras_tuner) (0.37.0)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard->keras_tuner) (3.17.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard->keras_tuner) (3.3.4)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.8/dist-packages (from tensorboard->keras_tuner) (2.0.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from absl-py>=0.4->tensorboard->keras_tuner) (1.15.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<2,>=1.6.3->tensorboard->keras_tuner) (4.2.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<2,>=1.6.3->tensorboard->keras_tuner) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<2,>=1.6.3->tensorboard->keras_tuner) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras_tuner) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard->keras_tuner) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras_tuner) (3.1.1)\n",
      "Installing collected packages: kt-legacy, keras-tuner\n",
      "Successfully installed keras-tuner-1.1.0 kt-legacy-1.0.4\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.3.0 and strictly below 2.6.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.6.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "! pip3 install matplotlib\n",
    "! pip3 install tensorflow-addons\n",
    "! pip3 install pandas\n",
    "! pip3 install pendulum\n",
    "! pip3 install keras_tuner\n",
    "import os\n",
    "import pendulum\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_addons as tfa\n",
    "import keras_tuner as kt\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14db7b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from residualmlp.residual_mlp import ResidualMLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "819bcb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "weight_decay = 0.0001\n",
    "batch_size = 50\n",
    "num_epochs = 100\n",
    "image_size = 32  # We'll resize input images to this size\n",
    "patch_size = 6  # Size of the patches to be extract from the input images\n",
    "num_patches = (image_size // patch_size) ** 2\n",
    "projection_dim = 64\n",
    "num_heads = 4\n",
    "transformer_units = [\n",
    "    projection_dim * 2,\n",
    "    projection_dim,\n",
    "]  # Size of the transformer layers\n",
    "transformer_layers = 5\n",
    "mlp_head_units = [2048, 1024]  # Size of the dense layers of the final classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62827950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 8s 0us/step\n",
      "170508288/170498071 [==============================] - 8s 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-17 09:06:55.248576: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-17 09:06:55.259862: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-17 09:06:55.260551: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-17 09:06:55.262477: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-17 09:06:55.263087: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-17 09:06:55.263632: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-17 09:06:56.033193: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-17 09:06:56.033832: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-17 09:06:56.034389: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-17 09:06:56.034905: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6696 MB memory:  -> device: 0, name: Quadro RTX 4000, pci bus id: 0000:00:05.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "cifar = tf.keras.datasets.cifar10.load_data()\n",
    "(x_train, y_train), (x_test, y_test) = cifar\n",
    "\n",
    "y_train_ohe = tf.one_hot([i[0] for i in y_train], 10)\n",
    "indexes_for_rows = tf.range(0, y_train.shape[0])\n",
    "shuffled_indexes = tf.random.shuffle(indexes_for_rows)\n",
    "selected_indexes = shuffled_indexes[:TRAINING_SET_SIZE]\n",
    "selected_x_train = x_train[selected_indexes, :, :, :]\n",
    "selected_y_train_ohe = y_train_ohe.numpy()[selected_indexes, :]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "184dce68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-17 09:06:57.081656: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.Normalization(),\n",
    "        layers.Resizing(image_size, image_size),\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(factor=0.02),\n",
    "        layers.RandomZoom(\n",
    "            height_factor=0.2, width_factor=0.2\n",
    "        ),\n",
    "    ],\n",
    "    name=\"data_augmentation\",\n",
    ")\n",
    "data_augmentation.layers[0].adapt(x_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3ce99b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Patches(layers.Layer):\n",
    "    def __init__(self, patch_size):\n",
    "        super(Patches, self).__init__()\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    def call(self, images):\n",
    "        batch_size = tf.shape(images)[0]\n",
    "        patches = tf.image.extract_patches(\n",
    "            images=images,\n",
    "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
    "            strides=[1, self.patch_size, self.patch_size, 1],\n",
    "            rates=[1, 1, 1, 1],\n",
    "            padding=\"VALID\",\n",
    "        )\n",
    "        patch_dims = patches.shape[-1]\n",
    "        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
    "        return patches\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5ca6a73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 31.5, 31.5, -0.5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "image = x_train[np.random.choice(range(x_train.shape[0]))]\n",
    "plt.imshow(image.astype(\"uint8\"))\n",
    "plt.axis(\"off\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4cae7c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image size: 32 X 32\n",
      "Patch size: 6 X 6\n",
      "Patches per image: 25\n",
      "Elements per patch: 108\n"
     ]
    }
   ],
   "source": [
    "resized_image = tf.image.resize(\n",
    "    tf.convert_to_tensor([image]), size=(image_size, image_size)\n",
    ")\n",
    "\n",
    "patches = Patches(patch_size)(resized_image)\n",
    "print(f\"Image size: {image_size} X {image_size}\")\n",
    "print(f\"Patch size: {patch_size} X {patch_size}\")\n",
    "print(f\"Patches per image: {patches.shape[1]}\")\n",
    "print(f\"Elements per patch: {patches.shape[-1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c77a22d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 25 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "n = int(np.sqrt(patches.shape[1]))\n",
    "plt.figure(figsize=(4, 4))\n",
    "for i, patch in enumerate(patches[0]):\n",
    "    ax = plt.subplot(n, n, i + 1)\n",
    "    patch_img = tf.reshape(patch, (patch_size, patch_size, 3))\n",
    "    plt.imshow(patch_img.numpy().astype(\"uint8\"))\n",
    "    plt.axis(\"off\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5a17b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class PatchEncoder(layers.Layer):\n",
    "    def __init__(self, num_patches, projection_dim):\n",
    "        super(PatchEncoder, self).__init__()\n",
    "        self.num_patches = num_patches\n",
    "        self.projection = layers.Dense(units=projection_dim)\n",
    "        self.position_embedding = layers.Embedding(\n",
    "            input_dim=num_patches, output_dim=projection_dim\n",
    "        )\n",
    "\n",
    "    def call(self, patch):\n",
    "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
    "        encoded = self.projection(patch) + self.position_embedding(positions)\n",
    "        return encoded\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "400389a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(x, hidden_units, dropout_rate):\n",
    "    for units in hidden_units:\n",
    "        x = layers.Dense(units, activation=tf.nn.gelu)(x)\n",
    "        x = layers.Dropout(dropout_rate)(x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40b4b1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vit_classifier(vit_base_model_input_shape = (32, 32, 3)):\n",
    "    \n",
    "    inputs = layers.Input(shape=vit_base_model_input_shape)\n",
    "    # Augment data.\n",
    "    augmented = data_augmentation(inputs)\n",
    "    # Create patches.\n",
    "    patches = Patches(patch_size)(augmented)\n",
    "    # Encode patches.\n",
    "    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n",
    "\n",
    "    # Create multiple layers of the Transformer block.\n",
    "    for _ in range(transformer_layers):\n",
    "        # Layer normalization 1.\n",
    "        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "        # Create a multi-head attention layer.\n",
    "        attention_output = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n",
    "        )(x1, x1)\n",
    "        # Skip connection 1.\n",
    "        x2 = layers.Add()([attention_output, encoded_patches])\n",
    "        # Layer normalization 2.\n",
    "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "        # MLP.\n",
    "        x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1) # x3 = residual_mlp\n",
    "        # Skip connection 2.\n",
    "        encoded_patches = layers.Add()([x3, x2])\n",
    "\n",
    "    # Create a [batch_size, projection_dim] tensor.\n",
    "    representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "    representation = layers.Flatten()(representation)\n",
    "    #representation = layers.Dropout(0.5)(representation)\n",
    "    # Add MLP.\n",
    "    #features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=0.5)\n",
    "    # Classify outputs.\n",
    "    #logits = layers.Dense(num_classes)(features)\n",
    "    # Create the Keras model.\n",
    "    \n",
    "    model = keras.Model(inputs=inputs, outputs=representation)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5de4145b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "base_vit_model = create_vit_classifier()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af45a2e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "data_augmentation (Sequential)  (None, 32, 32, 3)    7           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "patches_1 (Patches)             (None, None, 108)    0           data_augmentation[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "patch_encoder (PatchEncoder)    (None, 25, 64)       8576        patches_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization (LayerNorma (None, 25, 64)       128         patch_encoder[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention (MultiHead (None, 25, 64)       66368       layer_normalization[0][0]        \n",
      "                                                                 layer_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 25, 64)       0           multi_head_attention[0][0]       \n",
      "                                                                 patch_encoder[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_1 (LayerNor (None, 25, 64)       128         add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 25, 128)      8320        layer_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 25, 128)      0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 25, 64)       8256        dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 25, 64)       0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 25, 64)       0           dropout_1[0][0]                  \n",
      "                                                                 add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_2 (LayerNor (None, 25, 64)       128         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_1 (MultiHe (None, 25, 64)       66368       layer_normalization_2[0][0]      \n",
      "                                                                 layer_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 25, 64)       0           multi_head_attention_1[0][0]     \n",
      "                                                                 add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_3 (LayerNor (None, 25, 64)       128         add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 25, 128)      8320        layer_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 25, 128)      0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 25, 64)       8256        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 25, 64)       0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 25, 64)       0           dropout_3[0][0]                  \n",
      "                                                                 add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_4 (LayerNor (None, 25, 64)       128         add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_2 (MultiHe (None, 25, 64)       66368       layer_normalization_4[0][0]      \n",
      "                                                                 layer_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 25, 64)       0           multi_head_attention_2[0][0]     \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_5 (LayerNor (None, 25, 64)       128         add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 25, 128)      8320        layer_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 25, 128)      0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 25, 64)       8256        dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 25, 64)       0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 25, 64)       0           dropout_5[0][0]                  \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_6 (LayerNor (None, 25, 64)       128         add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_3 (MultiHe (None, 25, 64)       66368       layer_normalization_6[0][0]      \n",
      "                                                                 layer_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 25, 64)       0           multi_head_attention_3[0][0]     \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_7 (LayerNor (None, 25, 64)       128         add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 25, 128)      8320        layer_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 25, 128)      0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 25, 64)       8256        dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 25, 64)       0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 25, 64)       0           dropout_7[0][0]                  \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_8 (LayerNor (None, 25, 64)       128         add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_4 (MultiHe (None, 25, 64)       66368       layer_normalization_8[0][0]      \n",
      "                                                                 layer_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 25, 64)       0           multi_head_attention_4[0][0]     \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_9 (LayerNor (None, 25, 64)       128         add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 25, 128)      8320        layer_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 25, 128)      0           dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 25, 64)       8256        dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 25, 64)       0           dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 25, 64)       0           dropout_9[0][0]                  \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_10 (LayerNo (None, 25, 64)       128         add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 1600)         0           layer_normalization_10[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 424,711\n",
      "Trainable params: 424,704\n",
      "Non-trainable params: 7\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_vit_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e578c1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 1600), dtype=float32, numpy=\n",
       "array([[ 2.3454142 , -0.4750308 , -0.742527  , ..., -0.14118469,\n",
       "        -0.6517954 ,  1.7791226 ],\n",
       "       [ 1.334048  , -0.2568164 , -0.5088399 , ..., -0.1422742 ,\n",
       "        -1.1282926 ,  0.06327623],\n",
       "       [-1.6194777 , -0.38929886,  0.07982185, ..., -0.02445328,\n",
       "        -0.6952469 ,  0.844184  ],\n",
       "       [ 1.8533131 , -0.17120257, -0.75661623, ..., -0.84780395,\n",
       "        -2.5262234 ,  1.4657283 ],\n",
       "       [-1.2375643 , -0.9151571 ,  0.7243939 , ..., -0.26934433,\n",
       "        -2.4512022 ,  1.3618976 ]], dtype=float32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "base_vit_model(x_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0984df1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "res_mlp = ResidualMLP(problem_type = 'classification', #\n",
    "                      learning_rate = .0007, #\n",
    "                      input_shape = (32, 32, 3), #(32,32,3), #\n",
    "                      bw_images = False, #\n",
    "                      base_model = base_vit_model, #\n",
    "                      base_model_input_shape = (32, 32, 3),  # (600,600,3), #\n",
    "                      flatten_after_base_model = False, #\n",
    "                      blocks = [[7, 75, 8], [5, 75, 10]], #\n",
    "                      residual_bypass_dense_layers = list(), #\n",
    "                      b_norm_or_dropout_residual_bypass_layers = 'dropout', #\n",
    "                      dropout_rate_for_bypass_layers = .7, #\n",
    "                      inter_block_layers_per_block = [],\n",
    "                      b_norm_or_dropout_last_layers = 'dropout', # | 'bnorm'\n",
    "                      dropout_rate = .18, #\n",
    "                      activation = tf.keras.activations.relu, #\n",
    "                      final_dense_layers = [], #\n",
    "                      number_of_classes = 10, # 1 if a regression problem\n",
    "                      # final_activation = tf.keras.activations.softmax, #\n",
    "                      #loss = tf.keras.losses.CategoricalCrossentropy(\n",
    "                      #    from_logits=False)\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc096120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 6 Complete [00h 01m 55s]\n",
      "val_loss: 2.0508553981781006\n",
      "\n",
      "Best val_loss So Far: 2.0508553981781006\n",
      "Total elapsed time: 00h 07m 33s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.RandomSearch(\n",
    "    res_mlp.build_auto_residual_mlp,\n",
    "    objective='val_loss',\n",
    "    max_trials=5)\n",
    "tuner.search(selected_x_train, selected_y_train_ohe, epochs=20, validation_split=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "80797e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 3\n",
      "learning_rate (Float)\n",
      "{'default': 7e-05, 'conditions': [], 'min_value': 7e-05, 'max_value': 0.7, 'step': None, 'sampling': 'log'}\n",
      "blocks (Choice)\n",
      "{'default': 0, 'conditions': [], 'values': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286], 'ordered': True}\n",
      "bypass_layers_units (Choice)\n",
      "{'default': 0, 'conditions': [], 'values': [0, 1, 2, 3, 4, 5, 6], 'ordered': True}\n"
     ]
    }
   ],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6b54fb38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All permutations:\n",
      "      number_of_blocks  layers_per_block  neurons_per_block_layer  \\\n",
      "0                    1                 1                        1   \n",
      "1                    1                 1                        1   \n",
      "2                    1                 1                        1   \n",
      "3                    1                 1                        1   \n",
      "4                    1                 1                        1   \n",
      "...                ...               ...                      ...   \n",
      "2396                 7                 7                        7   \n",
      "2397                 7                 7                        7   \n",
      "2398                 7                 7                        7   \n",
      "2399                 7                 7                        7   \n",
      "2400                 7                 7                        7   \n",
      "\n",
      "      neurons_per_block_layer_decay  \n",
      "0                                 1  \n",
      "1                                 2  \n",
      "2                                 3  \n",
      "3                                 4  \n",
      "4                                 5  \n",
      "...                             ...  \n",
      "2396                              3  \n",
      "2397                              4  \n",
      "2398                              5  \n",
      "2399                              6  \n",
      "2400                              7  \n",
      "\n",
      "[2401 rows x 4 columns]\n",
      "Valid permutations\n",
      "     number_of_blocks  layers_per_block  neurons_per_block_layer  \\\n",
      "0                   1                 1                        2   \n",
      "1                   1                 1                        3   \n",
      "2                   1                 1                        3   \n",
      "3                   1                 1                        4   \n",
      "4                   1                 1                        4   \n",
      "..                ...               ...                      ...   \n",
      "282                 7                 4                        6   \n",
      "283                 7                 4                        7   \n",
      "284                 7                 5                        6   \n",
      "285                 7                 5                        7   \n",
      "286                 7                 6                        7   \n",
      "\n",
      "     neurons_per_block_layer_decay  valid_block  \n",
      "0                                1         True  \n",
      "1                                1         True  \n",
      "2                                2         True  \n",
      "3                                1         True  \n",
      "4                                2         True  \n",
      "..                             ...          ...  \n",
      "282                              1         True  \n",
      "283                              1         True  \n",
      "284                              1         True  \n",
      "285                              1         True  \n",
      "286                              1         True  \n",
      "\n",
      "[287 rows x 5 columns]\n",
      "Valid permutations with blocks column\n",
      "     number_of_blocks  layers_per_block  neurons_per_block_layer  \\\n",
      "0                   1                 1                        2   \n",
      "1                   1                 1                        3   \n",
      "2                   1                 1                        3   \n",
      "3                   1                 1                        4   \n",
      "4                   1                 1                        4   \n",
      "..                ...               ...                      ...   \n",
      "282                 7                 4                        6   \n",
      "283                 7                 4                        7   \n",
      "284                 7                 5                        6   \n",
      "285                 7                 5                        7   \n",
      "286                 7                 6                        7   \n",
      "\n",
      "     neurons_per_block_layer_decay  valid_block  \\\n",
      "0                                1         True   \n",
      "1                                1         True   \n",
      "2                                2         True   \n",
      "3                                1         True   \n",
      "4                                2         True   \n",
      "..                             ...          ...   \n",
      "282                              1         True   \n",
      "283                              1         True   \n",
      "284                              1         True   \n",
      "285                              1         True   \n",
      "286                              1         True   \n",
      "\n",
      "                                                blocks  \n",
      "0                                          [[1, 2, 1]]  \n",
      "1                                          [[1, 3, 1]]  \n",
      "2                                          [[1, 3, 2]]  \n",
      "3                                          [[1, 4, 1]]  \n",
      "4                                          [[1, 4, 2]]  \n",
      "..                                                 ...  \n",
      "282  [[4, 6, 1], [4, 6, 1], [4, 6, 1], [4, 6, 1], [...  \n",
      "283  [[4, 7, 1], [4, 7, 1], [4, 7, 1], [4, 7, 1], [...  \n",
      "284  [[5, 6, 1], [5, 6, 1], [5, 6, 1], [5, 6, 1], [...  \n",
      "285  [[5, 7, 1], [5, 7, 1], [5, 7, 1], [5, 7, 1], [...  \n",
      "286  [[6, 7, 1], [6, 7, 1], [6, 7, 1], [6, 7, 1], [...  \n",
      "\n",
      "[287 rows x 6 columns]\n",
      "[[3, 5, 1], [3, 5, 1]]\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "model = tuner.get_best_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f4ad3fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-17 09:21:06.522766: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "WARNING:absl:Found untraced functions such as dense_layer_call_and_return_conditional_losses, dense_layer_call_fn, embedding_layer_call_and_return_conditional_losses, embedding_layer_call_fn, query_layer_call_and_return_conditional_losses while saving (showing 5 of 160). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: test_model_from_first_successful_auto_run/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: test_model_from_first_successful_auto_run/assets\n",
      "/usr/local/lib/python3.8/dist-packages/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    }
   ],
   "source": [
    "model[0].save('test_model_from_first_successful_auto_run')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd26cac2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
