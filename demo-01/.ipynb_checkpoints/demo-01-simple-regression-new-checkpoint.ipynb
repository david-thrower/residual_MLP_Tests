{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cc2d5a9",
   "metadata": {},
   "source": [
    "# A simple demo of the residualmlp python package\n",
    "## This is a regression case pure resudual multi layer perceptron with no base model. \n",
    "\n",
    "1. Purpose:\n",
    "    1. This is a simple demo of the residualmlp python package that generates resisual_mlp models.\n",
    "2. Please note:\n",
    "    1. This version of the demo neither demonstrates an optimal neural network architecture nor does any preprocessing on the data, even though doing so would boost the performance of the model.This demo sumply demonstrates how to use the API and the syntax.\n",
    "    2. For a more complete example, see the demo for the tandem EfficientNetB7->residualMLP model discussed in the readme.md."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d647318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement upgrade (from versions: none)\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for upgrade\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.5.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.3 MB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11.3 MB 21.4 MB/s eta 0:00:01    |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                   | 4.4 MB 21.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.28.5-py3-none-any.whl (890 kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 890 kB 33.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (2.4.7)\n",
      "Collecting pillow>=6.2.0\n",
      "  Downloading Pillow-9.0.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4.3 MB 30.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.3.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.2 MB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.2 MB 29.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (1.19.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (21.0)\n",
      "Collecting cycler>=0.10\n",
      "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7->matplotlib) (1.15.0)\n",
      "Installing collected packages: pillow, kiwisolver, fonttools, cycler, matplotlib\n",
      "Successfully installed cycler-0.11.0 fonttools-4.28.5 kiwisolver-1.3.2 matplotlib-3.5.1 pillow-9.0.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting pandas\n",
      "  Downloading pandas-1.3.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11.5 MB 15.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (1.19.4)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "Installing collected packages: pandas\n",
      "Successfully installed pandas-1.3.5\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install anything missing\n",
    "!python -m pip install upgrade pip\n",
    "!pip3 install matplotlib\n",
    "!pip3 install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e54daa1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import what we need ...\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from residualmlp.residual_mlp import make_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbc7503c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the California housing data. \n",
    "df = pd.read_csv(\"https://storage.googleapis.com/ml_universities/california_housing_train.csv\", sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72fc239f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17000 entries, 0 to 16999\n",
      "Data columns (total 9 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   longitude           17000 non-null  float64\n",
      " 1   latitude            17000 non-null  float64\n",
      " 2   housing_median_age  17000 non-null  float64\n",
      " 3   total_rooms         17000 non-null  float64\n",
      " 4   total_bedrooms      17000 non-null  float64\n",
      " 5   population          17000 non-null  float64\n",
      " 6   households          17000 non-null  float64\n",
      " 7   median_income       17000 non-null  float64\n",
      " 8   median_house_value  17000 non-null  float64\n",
      "dtypes: float64(9)\n",
      "memory usage: 1.2 MB\n"
     ]
    }
   ],
   "source": [
    "# Let's see what this looks like.\n",
    "# In the real world, data would never be this clean... \n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "842d8cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In a use-worthy model, we would bucketize and cross the lattitude and longitude.\n",
    "# and probably bucketize several of the continuous variables\n",
    "# Here we are just doing a simple example to demo how to work our API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67038a63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-114.31</td>\n",
       "      <td>34.19</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5612.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>472.0</td>\n",
       "      <td>1.4936</td>\n",
       "      <td>66900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-114.47</td>\n",
       "      <td>34.40</td>\n",
       "      <td>19.0</td>\n",
       "      <td>7650.0</td>\n",
       "      <td>1901.0</td>\n",
       "      <td>1129.0</td>\n",
       "      <td>463.0</td>\n",
       "      <td>1.8200</td>\n",
       "      <td>80100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-114.57</td>\n",
       "      <td>33.64</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1501.0</td>\n",
       "      <td>337.0</td>\n",
       "      <td>515.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>3.1917</td>\n",
       "      <td>73400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-114.57</td>\n",
       "      <td>33.57</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1454.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>624.0</td>\n",
       "      <td>262.0</td>\n",
       "      <td>1.9250</td>\n",
       "      <td>65500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-114.58</td>\n",
       "      <td>33.61</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2907.0</td>\n",
       "      <td>680.0</td>\n",
       "      <td>1841.0</td>\n",
       "      <td>633.0</td>\n",
       "      <td>2.6768</td>\n",
       "      <td>82400.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0    -114.31     34.19                15.0       5612.0          1283.0   \n",
       "1    -114.47     34.40                19.0       7650.0          1901.0   \n",
       "3    -114.57     33.64                14.0       1501.0           337.0   \n",
       "4    -114.57     33.57                20.0       1454.0           326.0   \n",
       "6    -114.58     33.61                25.0       2907.0           680.0   \n",
       "\n",
       "   population  households  median_income  median_house_value  \n",
       "0      1015.0       472.0         1.4936             66900.0  \n",
       "1      1129.0       463.0         1.8200             80100.0  \n",
       "3       515.0       226.0         3.1917             73400.0  \n",
       "4       624.0       262.0         1.9250             65500.0  \n",
       "6      1841.0       633.0         2.6768             82400.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pseudo quasi random numbers between 0 and 1. \n",
    "# ~ 80% of them should be below .8 \n",
    "msk = np.random.rand(len(df)) < 0.8\n",
    "traindf = df[msk]\n",
    "evaldf = df[~msk]\n",
    "traindf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06af295d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull label from df\n",
    "y_train = traindf.pop('median_house_value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fe65df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert label to a numpy array\n",
    "y_train = y_train.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3875246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull label from df\n",
    "y_eval = evaldf.pop('median_house_value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b58ec6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert label to a numpy array\n",
    "y_eval = y_eval.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c51dc0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data - the features to a numpy array\n",
    "x_train = traindf.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7bf99abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data - the features to a numpy array\n",
    "x_eval = evaldf.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7417b38a",
   "metadata": {},
   "source": [
    "## Here we build our model: \n",
    "### We start by setting the hyperparameters:\n",
    "\n",
    "1. LEARNING_RATE / learning_rate: The learning rate for the optimizer.\n",
    "2. INPUT_SHAPE, input_shape: The input shape for the model as a whole, In other words, the shape of one observation in your data. In our case, each observation has 9 columns. One was removed as the label, so 8 columns, so shape is 8.\n",
    "3. BASE_MODEL / base_model: If you were building a tandem model, starting with a pre-trained base model and passing the output of that model to the residual MLP we are building, then you would pass in that keras model object (e.g. and EfficientNetB7 model.). In the case of this demo, we are not doing this. We are passing our data and labels straight into a residual MLP, so base_model will be set to empty string '':\n",
    "4. BASE_MODEL_INPUT_SHAPE / base_model_input_shape: If you are using a base model with a different input shape than your data, you would enter the input shape for the base model, and the model built by make_model() would include a rescaling layer before between your input layer and your base model. For example, if you have training / test images of shape (32,32,3) and were using EfficientNet, pretrained on imagenet from keras applications having an input shape of (600,600,3), as your base_model, you would set the parameter 'base_model_input_shape' to (600,600,3).\n",
    "5. Flatten: Whether or not to put a Flatten layer before your data passes into the residual multi layer perceptron being built. This is usually set to True if you have a Conv2d layer as the last layer of your base model or otherwise have any data that will pass to your residualMLP model that is not a rank 1 tensor. Settign it to true will coerce the data being fed into your residualMLP model to a rank tensor. If you are building a tandem ConvolutionalNeuraNetworkModel->residualMLP model, this must be set to true, or the shape will raise an exception at the Concat layer(s) in the residualMLP model being built. Here, each observation is a rank 1 tensor, and it is going straight into our model with no upstream operation that will change its rank, so there is nothing to flatten. Flatten is set to False.\n",
    "6. BLOCKS / blocks: A 2d array. Each ith nested array will create a residualMLP block. See the image in readme.md for a visual of this. In each ith nested arry, you will find 3 positive integers (except l which can be positive or may be 0): j,k,l (from left to right). The positive integer j on the left of each nested array gives you control of how many Dense layers that this block will consist of. The second positive integer, k sets the number of Dense units in the first layer of the block. The third [0 or positive integer] l is how many LESS Dense units each succesive layer in the block will consist of than its predecessor. There is one additional obvious rule that the product of the first and third numbers, j and l must be < k, the second number, otherwise, you are asking the API to add some layer(s) with O Dense units or a negative number of Dense units. This will of course raise an exception and make you feel as embarassed as I did the first time I did this ðŸ˜³. As a reminder, you must be concious of this when trying to run an auto-ml algorithym or running a gridsearch over permutations of these hyperparameters. A try .. except ... or better yet, a pre-screening of these permutations will be needed.\n",
    "7. RESIDUAL_BYPASS_DENSE_LAYERS / residual_bypass_dense_layers: If you want to include (a) Dense layer(s) in the residual bypass tensor, you would set this to a 2d array as we did below [[3],[3]], this will place a Dense layer with 3 units in the residual bypass of Block 1 and will place another Dense layer with 3 units in the resisual bypass of block 2. By default this is empty string \"\". If you set this, there must be a nested list for each blcok and may eb as many numbers in each blcok as your isel model architecture will have. Each ith nested 1d array would control the Dense layers in the residual bypass for the ith residual block. One layer will be inserted for each positive integer in the nested list and each layer will have the number of units as the integer.  If this is left as the default of '', then there will be no blocks in the residual bypass. You may add layers to one blocks's bypass and not the other like this: [[],[5]] See the image on readme.md. For this to make sense, please see the image on readme.md.The residual bypass is the through the network in yellow nodes on the right.).\n",
    "8. B_NORM_OR_DROPOUT_RESIDUAL_BYPASS_LAYERS / b_norm_or_dropout_residual_bypass_layers: You may insert BatchNormalization or dropout layers after each layer of the residual bypass. Options: Default \"dropout\" | \"bnorm\".\n",
    "9. DROPOUT_RATE_FOR_BYPASS_LAYERS / dropout_rate_for_bypass_layers: The global dropout rate for the dropout laters in the RESIDUAL BYPASSES (ignored if B_NORM_OR_DROPOUT_RESIDUAL_BYPASS_LAYERS is set to 'bnorm'). This usually performs best as dropout and often with a higher DROPOUT_RATE_FOR_BYPASS_LAYERS (e.g. 25%).\n",
    "10. B_NORM_OR_DROPOUT_LAST_LAYERS / b_norm_or_dropout_last_layers: After all last residual block, the hyperparameter FINAL_DENSE_LAYERS allows you to add a series (or just one) Dense layer(s). The hyperparameter b_norm_or_dropout_last_layers controls whether there will be a Dropout or BatchNormalization layer after each of these layer(s). This defaults to 'dropout' but can be set to 'bnorm'. It seems that about 60% of the time, dropout with the right dropout_rate will perform best, but be advised that these layers are more apt to internal covariate shift than the residual bypass layers. You amy want to experiment with both.  \n",
    "11. DROPOUT_RATE / dropout_rate: The dropout rate for the dropout layers after each final Dense layer inserted after the last residualMLP block by the parameter   \n",
    "12. FINAL_DENSE_LAYERS / final_dense_layers: A 1d array of positive integers: Each ith positive integer will insert a Dense layer after the last ResidualMLP block.\n",
    "13. NUMBER_OF_CLASSES = how many Dense units the final layer of the network should consist of / also the number of classes in your labels. For example, a simple linear regression model would have this parameter set to 1. So would a binary logistic regression problem. For a multi - class - classification problem, it would be the number of classes, eg 10 for a classification problem where there are 10 possible classes.\n",
    "14. FINAL_ACTIVATION - The activatinn fucntion e.g. tf.keras.activations.sigmoid - [no parentheses after it]. It defaults to tf.keras.activations.softmax. Since we are doing simple linear regression, the activation is None.\n",
    "15. LOSS - The loss that is appropriate for your problem. Here we are doign simpel linear regression, so the default chice is f.keras.losses.MeanSquaredError(), but tf.keras.losses.Huber() and tf.keras.losses.MeanAbsoluteError() are fair game. The default is: tf.keras.losses.CategoricalCrossentropy(from_logits=False), but that doesn't help us with this problem ... so we set it to None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a387fa37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the hyperparameters for the  \n",
    "\n",
    "LEARNING_RATE = 0.007\n",
    "INPUT_SHAPE = 8\n",
    "BASE_MODEL = ''\n",
    "BASE_MODEL_INPUT_SHAPE = None\n",
    "FLATTEN = False\n",
    "BLOCKS = [[5,12,2],[5,12,2]]\n",
    "RESIDUAL_BYPASS_DENSE_LAYERS = [[3],[3]]\n",
    "B_NORM_OR_DROPOUT_RESIDUAL_BYPASS_LAYERS = 'bnorm'\n",
    "DROPOUT_RATE_FOR_BYPASS_LAYERS = 0.0\n",
    "B_NORM_OR_DROPOUT_LAST_LAYERS = 'bnorm'\n",
    "DROPOUT_RATE = 0.0\n",
    "FINAL_DENSE_LAYERS = [4,4]\n",
    "NUMBER_OF_CLASSES = 1\n",
    "FINAL_ACTIVATION = None\n",
    "LOSS = tf.keras.losses.MeanSquaredError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0aee21e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-07 04:30:37.951383: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-07 04:30:38.118521: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-07 04:30:38.119760: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-07 04:30:38.122968: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-07 04:30:38.124213: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-07 04:30:38.125309: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-07 04:30:40.906583: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-07 04:30:40.907623: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-07 04:30:40.908583: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-07 04:30:40.909871: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15392 MB memory:  -> device: 0, name: Quadro P5000, pci bus id: 0000:00:05.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "model0001=\\\n",
    "    make_model(learning_rate=LEARNING_RATE,\n",
    "                input_shape = INPUT_SHAPE,  \n",
    "                base_model= BASE_MODEL,\n",
    "                base_model_input_shape = BASE_MODEL_INPUT_SHAPE,\n",
    "                flatten_after_base_model = FLATTEN,\n",
    "                blocks = BLOCKS,\n",
    "                residual_bypass_dense_layers = RESIDUAL_BYPASS_DENSE_LAYERS,\n",
    "                b_norm_or_dropout_residual_bypass_layers=B_NORM_OR_DROPOUT_RESIDUAL_BYPASS_LAYERS,\n",
    "                dropout_rate_for_bypass_layers=DROPOUT_RATE_FOR_BYPASS_LAYERS,\n",
    "                b_norm_or_dropout_last_layers=B_NORM_OR_DROPOUT_LAST_LAYERS,\n",
    "                dropout_rate=DROPOUT_RATE,\n",
    "                final_dense_layers =\\\n",
    "                    FINAL_DENSE_LAYERS,\n",
    "                number_of_classes = NUMBER_OF_CLASSES,\n",
    "                final_activation = FINAL_ACTIVATION,\n",
    "               loss = LOSS\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8f1df5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 8)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 12)           108         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 12)           48          dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 12)           156         batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 12)           48          dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           130         batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 10)           40          dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 8)            88          batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 8)            32          dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 12)           48          batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 6)            54          batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 3)            39          batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 6)            24          dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 3)            12          dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 9)            0           batch_normalization_6[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 4)            40          concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 4)            16          dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 12)           60          batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 12)           48          dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 12)           156         batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 12)           48          dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 10)           130         batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 10)           40          dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 8)            88          batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 8)            32          dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 12)           48          batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 6)            54          batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 3)            39          batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 6)            24          dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 3)            12          dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 9)            0           batch_normalization_14[0][0]     \n",
      "                                                                 batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 4)            40          concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 4)            16          dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 4)            20          batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 4)            16          dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 4)            20          batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 4)            16          dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 1)            5           batch_normalization_17[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 1,795\n",
      "Trainable params: 1,511\n",
      "Non-trainable params: 284\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model0001.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "205e396f",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 50\n",
    "EPOCHS = 100\n",
    "PATIENCE = 15\n",
    "PATIENCE_MIN_DELTA = .005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0dcd1a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-07 04:31:32.074926: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n",
      "2022-01-07 04:31:32.074984: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n",
      "2022-01-07 04:31:32.075898: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1614] Profiler found 1 GPUs\n",
      "2022-01-07 04:31:32.366374: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n",
      "2022-01-07 04:31:32.366711: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1749] CUPTI activity buffer flushed\n"
     ]
    }
   ],
   "source": [
    "logdir = os.path.join(\"2022-01-06_21-27_logs\", 'results')\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, \n",
    "                                                      histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "39d75778",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-07 04:31:39.688038: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "  1/191 [..............................] - ETA: 22:36 - loss: 64458145792.0000 - root_mean_squared_error: 253886.0781"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-07 04:31:47.061909: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n",
      "2022-01-07 04:31:47.061975: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "  2/191 [..............................] - ETA: 1:37 - loss: 50553425920.0000 - root_mean_squared_error: 224840.9062 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-07 04:31:47.371780: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2022-01-07 04:31:47.372356: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1749] CUPTI activity buffer flushed\n",
      "2022-01-07 04:31:47.424916: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:673]  GpuTracer has collected 1520 callback api events and 1531 activity events. \n",
      "2022-01-07 04:31:47.463903: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n",
      "2022-01-07 04:31:47.538489: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: 2022-01-06_21-27_logs/results/train/plugins/profile/2022_01_07_04_31_47\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "  3/191 [..............................] - ETA: 1:21 - loss: 51260469248.0000 - root_mean_squared_error: 226407.7500"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-07 04:31:47.573704: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to 2022-01-06_21-27_logs/results/train/plugins/profile/2022_01_07_04_31_47/nncledfn7b.trace.json.gz\n",
      "2022-01-07 04:31:47.665612: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: 2022-01-06_21-27_logs/results/train/plugins/profile/2022_01_07_04_31_47\n",
      "\n",
      "2022-01-07 04:31:47.674411: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to 2022-01-06_21-27_logs/results/train/plugins/profile/2022_01_07_04_31_47/nncledfn7b.memory_profile.json.gz\n",
      "2022-01-07 04:31:47.687723: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: 2022-01-06_21-27_logs/results/train/plugins/profile/2022_01_07_04_31_47\n",
      "Dumped tool data for xplane.pb to 2022-01-06_21-27_logs/results/train/plugins/profile/2022_01_07_04_31_47/nncledfn7b.xplane.pb\n",
      "Dumped tool data for overview_page.pb to 2022-01-06_21-27_logs/results/train/plugins/profile/2022_01_07_04_31_47/nncledfn7b.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to 2022-01-06_21-27_logs/results/train/plugins/profile/2022_01_07_04_31_47/nncledfn7b.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to 2022-01-06_21-27_logs/results/train/plugins/profile/2022_01_07_04_31_47/nncledfn7b.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to 2022-01-06_21-27_logs/results/train/plugins/profile/2022_01_07_04_31_47/nncledfn7b.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191/191 [==============================] - 14s 35ms/step - loss: 51983241216.0000 - root_mean_squared_error: 227998.3281 - val_loss: 68090388480.0000 - val_root_mean_squared_error: 260941.3438\n",
      "Epoch 2/100\n",
      "191/191 [==============================] - 5s 28ms/step - loss: 51972816896.0000 - root_mean_squared_error: 227975.4688 - val_loss: 68079841280.0000 - val_root_mean_squared_error: 260921.1406\n",
      "Epoch 3/100\n",
      "191/191 [==============================] - 5s 28ms/step - loss: 51954466816.0000 - root_mean_squared_error: 227935.2188 - val_loss: 68105900032.0000 - val_root_mean_squared_error: 260971.0625\n",
      "Epoch 4/100\n",
      "191/191 [==============================] - 5s 28ms/step - loss: 51926626304.0000 - root_mean_squared_error: 227874.1406 - val_loss: 68168224768.0000 - val_root_mean_squared_error: 261090.4531\n",
      "Epoch 5/100\n",
      "191/191 [==============================] - 5s 28ms/step - loss: 51890081792.0000 - root_mean_squared_error: 227793.9375 - val_loss: 68207890432.0000 - val_root_mean_squared_error: 261166.4062\n",
      "Epoch 6/100\n",
      "191/191 [==============================] - 5s 27ms/step - loss: 51845271552.0000 - root_mean_squared_error: 227695.5625 - val_loss: 68081299456.0000 - val_root_mean_squared_error: 260923.9375\n",
      "Epoch 7/100\n",
      "191/191 [==============================] - 5s 28ms/step - loss: 51791114240.0000 - root_mean_squared_error: 227576.6094 - val_loss: 67973586944.0000 - val_root_mean_squared_error: 260717.4375\n",
      "Epoch 8/100\n",
      "191/191 [==============================] - 5s 27ms/step - loss: 51732557824.0000 - root_mean_squared_error: 227447.9219 - val_loss: 66541576192.0000 - val_root_mean_squared_error: 257956.5312\n",
      "Epoch 9/100\n",
      "191/191 [==============================] - 5s 28ms/step - loss: 51661799424.0000 - root_mean_squared_error: 227292.3125 - val_loss: 66658959360.0000 - val_root_mean_squared_error: 258183.9688\n",
      "Epoch 10/100\n",
      "191/191 [==============================] - 5s 28ms/step - loss: 51584700416.0000 - root_mean_squared_error: 227122.6562 - val_loss: 68456177664.0000 - val_root_mean_squared_error: 261641.3125\n",
      "Epoch 11/100\n",
      "191/191 [==============================] - 5s 28ms/step - loss: 51500122112.0000 - root_mean_squared_error: 226936.3750 - val_loss: 67983044608.0000 - val_root_mean_squared_error: 260735.5781\n",
      "Epoch 12/100\n",
      "191/191 [==============================] - 5s 27ms/step - loss: 51405660160.0000 - root_mean_squared_error: 226728.1562 - val_loss: 64972128256.0000 - val_root_mean_squared_error: 254896.3125\n",
      "Epoch 13/100\n",
      "191/191 [==============================] - 5s 28ms/step - loss: 51305107456.0000 - root_mean_squared_error: 226506.3125 - val_loss: 66852708352.0000 - val_root_mean_squared_error: 258558.9062\n",
      "Epoch 14/100\n",
      "191/191 [==============================] - 5s 28ms/step - loss: 51191767040.0000 - root_mean_squared_error: 226255.9688 - val_loss: 67823185920.0000 - val_root_mean_squared_error: 260428.8438\n",
      "Epoch 15/100\n",
      "191/191 [==============================] - 5s 28ms/step - loss: 51077464064.0000 - root_mean_squared_error: 226003.2344 - val_loss: 67571482624.0000 - val_root_mean_squared_error: 259945.1562\n",
      "Epoch 16/100\n",
      "191/191 [==============================] - 5s 28ms/step - loss: 50952081408.0000 - root_mean_squared_error: 225725.6875 - val_loss: 67907715072.0000 - val_root_mean_squared_error: 260591.0781\n",
      "Epoch 17/100\n",
      "191/191 [==============================] - 5s 28ms/step - loss: 50819522560.0000 - root_mean_squared_error: 225431.8594 - val_loss: 66029305856.0000 - val_root_mean_squared_error: 256961.6875\n",
      "Epoch 18/100\n",
      "191/191 [==============================] - 5s 27ms/step - loss: 50675453952.0000 - root_mean_squared_error: 225112.0938 - val_loss: 67809517568.0000 - val_root_mean_squared_error: 260402.6094\n",
      "Epoch 19/100\n",
      "191/191 [==============================] - 5s 28ms/step - loss: 50520424448.0000 - root_mean_squared_error: 224767.4844 - val_loss: 67104964608.0000 - val_root_mean_squared_error: 259046.2656\n",
      "Epoch 20/100\n",
      "191/191 [==============================] - 5s 28ms/step - loss: 50360983552.0000 - root_mean_squared_error: 224412.5312 - val_loss: 63139233792.0000 - val_root_mean_squared_error: 251275.2188\n",
      "Epoch 21/100\n",
      "191/191 [==============================] - 5s 28ms/step - loss: 50198507520.0000 - root_mean_squared_error: 224050.2344 - val_loss: 62019579904.0000 - val_root_mean_squared_error: 249037.2969\n",
      "Epoch 22/100\n",
      "191/191 [==============================] - 5s 28ms/step - loss: 50026315776.0000 - root_mean_squared_error: 223665.6250 - val_loss: 68785422336.0000 - val_root_mean_squared_error: 262269.7500\n",
      "Epoch 23/100\n",
      "191/191 [==============================] - 5s 27ms/step - loss: 49842315264.0000 - root_mean_squared_error: 223253.9219 - val_loss: 65050447872.0000 - val_root_mean_squared_error: 255049.8906\n",
      "Epoch 24/100\n",
      "191/191 [==============================] - 5s 28ms/step - loss: 49649496064.0000 - root_mean_squared_error: 222821.6719 - val_loss: 65385476096.0000 - val_root_mean_squared_error: 255705.8438\n",
      "Epoch 25/100\n",
      "191/191 [==============================] - 5s 28ms/step - loss: 49461395456.0000 - root_mean_squared_error: 222399.1719 - val_loss: 64569233408.0000 - val_root_mean_squared_error: 254104.7656\n",
      "Epoch 26/100\n",
      "191/191 [==============================] - 5s 28ms/step - loss: 49256706048.0000 - root_mean_squared_error: 221938.5156 - val_loss: 66085466112.0000 - val_root_mean_squared_error: 257070.9375\n",
      "Epoch 27/100\n",
      "191/191 [==============================] - 5s 28ms/step - loss: 49036087296.0000 - root_mean_squared_error: 221440.9375 - val_loss: 66703687680.0000 - val_root_mean_squared_error: 258270.5625\n",
      "Epoch 28/100\n",
      "191/191 [==============================] - 5s 27ms/step - loss: 48827039744.0000 - root_mean_squared_error: 220968.4062 - val_loss: 60513869824.0000 - val_root_mean_squared_error: 245995.6719\n",
      "Epoch 29/100\n",
      "191/191 [==============================] - 5s 28ms/step - loss: 48602124288.0000 - root_mean_squared_error: 220458.8906 - val_loss: 57349218304.0000 - val_root_mean_squared_error: 239476.9688\n",
      "Epoch 30/100\n",
      "191/191 [==============================] - 5s 28ms/step - loss: 48365977600.0000 - root_mean_squared_error: 219922.6562 - val_loss: 62887497728.0000 - val_root_mean_squared_error: 250773.7969\n",
      "Epoch 31/100\n",
      "191/191 [==============================] - 5s 28ms/step - loss: 48119705600.0000 - root_mean_squared_error: 219362.0469 - val_loss: 66857299968.0000 - val_root_mean_squared_error: 258567.7812\n",
      "Epoch 32/100\n",
      "191/191 [==============================] - 5s 28ms/step - loss: 47875547136.0000 - root_mean_squared_error: 218804.8125 - val_loss: 63748837376.0000 - val_root_mean_squared_error: 252485.3125\n",
      "Epoch 33/100\n",
      "191/191 [==============================] - 5s 27ms/step - loss: 47615569920.0000 - root_mean_squared_error: 218209.9219 - val_loss: 60689211392.0000 - val_root_mean_squared_error: 246351.7969\n",
      "Epoch 34/100\n",
      "191/191 [==============================] - 5s 28ms/step - loss: 47351234560.0000 - root_mean_squared_error: 217603.3906 - val_loss: 65843486720.0000 - val_root_mean_squared_error: 256599.8594\n",
      "Epoch 35/100\n",
      "191/191 [==============================] - 5s 27ms/step - loss: 47079555072.0000 - root_mean_squared_error: 216978.2344 - val_loss: 60019793920.0000 - val_root_mean_squared_error: 244989.3750\n",
      "Epoch 36/100\n",
      "191/191 [==============================] - 5s 27ms/step - loss: 46809055232.0000 - root_mean_squared_error: 216354.0000 - val_loss: 69731762176.0000 - val_root_mean_squared_error: 264067.7188\n",
      "Epoch 37/100\n",
      "191/191 [==============================] - 5s 27ms/step - loss: 46526459904.0000 - root_mean_squared_error: 215699.9375 - val_loss: 63829921792.0000 - val_root_mean_squared_error: 252645.8438\n",
      "Epoch 38/100\n",
      "191/191 [==============================] - 5s 28ms/step - loss: 46234107904.0000 - root_mean_squared_error: 215021.1719 - val_loss: 57718476800.0000 - val_root_mean_squared_error: 240246.7031\n",
      "Epoch 39/100\n",
      "191/191 [==============================] - 5s 28ms/step - loss: 45929930752.0000 - root_mean_squared_error: 214312.6875 - val_loss: 693650915328.0000 - val_root_mean_squared_error: 832857.0625\n",
      "Epoch 40/100\n",
      "191/191 [==============================] - 5s 28ms/step - loss: 45638696960.0000 - root_mean_squared_error: 213632.1406 - val_loss: 63979053056.0000 - val_root_mean_squared_error: 252940.8125\n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191/191 [==============================] - 5s 27ms/step - loss: 45338734592.0000 - root_mean_squared_error: 212928.9375 - val_loss: 63102205952.0000 - val_root_mean_squared_error: 251201.5312\n",
      "Epoch 42/100\n",
      "191/191 [==============================] - 5s 28ms/step - loss: 45005160448.0000 - root_mean_squared_error: 212144.2031 - val_loss: 51544850432.0000 - val_root_mean_squared_error: 227034.9062\n",
      "Epoch 43/100\n",
      "191/191 [==============================] - 5s 27ms/step - loss: 44694720512.0000 - root_mean_squared_error: 211411.2500 - val_loss: 45939122176.0000 - val_root_mean_squared_error: 214334.1406\n",
      "Epoch 44/100\n",
      "191/191 [==============================] - 5s 27ms/step - loss: 44358352896.0000 - root_mean_squared_error: 210614.2344 - val_loss: 47090561024.0000 - val_root_mean_squared_error: 217003.5938\n",
      "Epoch 45/100\n",
      "191/191 [==============================] - 5s 28ms/step - loss: 44038057984.0000 - root_mean_squared_error: 209852.4688 - val_loss: 66413940736.0000 - val_root_mean_squared_error: 257709.0156\n",
      "Epoch 46/100\n",
      "191/191 [==============================] - 5s 29ms/step - loss: 43676450816.0000 - root_mean_squared_error: 208989.1094 - val_loss: 66057728000.0000 - val_root_mean_squared_error: 257016.9844\n",
      "Epoch 47/100\n",
      "191/191 [==============================] - 5s 28ms/step - loss: 43357388800.0000 - root_mean_squared_error: 208224.3750 - val_loss: 57326673920.0000 - val_root_mean_squared_error: 239429.8906\n",
      "Epoch 48/100\n",
      "191/191 [==============================] - 5s 27ms/step - loss: 42994847744.0000 - root_mean_squared_error: 207351.9844 - val_loss: 54945734656.0000 - val_root_mean_squared_error: 234405.0625\n",
      "Epoch 49/100\n",
      "191/191 [==============================] - 5s 28ms/step - loss: 42637094912.0000 - root_mean_squared_error: 206487.5156 - val_loss: 62404792320.0000 - val_root_mean_squared_error: 249809.5156\n",
      "Epoch 50/100\n",
      "191/191 [==============================] - 5s 28ms/step - loss: 42262601728.0000 - root_mean_squared_error: 205578.7031 - val_loss: 69772288000.0000 - val_root_mean_squared_error: 264144.4375\n",
      "Epoch 51/100\n",
      "191/191 [==============================] - 5s 28ms/step - loss: 41931743232.0000 - root_mean_squared_error: 204772.4062 - val_loss: 45007769600.0000 - val_root_mean_squared_error: 212150.3438\n",
      "Epoch 52/100\n",
      "191/191 [==============================] - 5s 28ms/step - loss: 41531338752.0000 - root_mean_squared_error: 203792.3906 - val_loss: 55518830592.0000 - val_root_mean_squared_error: 235624.3438\n",
      "Epoch 53/100\n",
      "191/191 [==============================] - 5s 27ms/step - loss: 41180667904.0000 - root_mean_squared_error: 202930.2031 - val_loss: 59333632000.0000 - val_root_mean_squared_error: 243584.9531\n",
      "Epoch 54/100\n",
      "191/191 [==============================] - 5s 28ms/step - loss: 40800382976.0000 - root_mean_squared_error: 201991.0469 - val_loss: 61727301632.0000 - val_root_mean_squared_error: 248449.7969\n",
      "Epoch 55/100\n",
      "191/191 [==============================] - 5s 27ms/step - loss: 40384163840.0000 - root_mean_squared_error: 200958.1094 - val_loss: 75939233792.0000 - val_root_mean_squared_error: 275570.7500\n",
      "Epoch 56/100\n",
      "191/191 [==============================] - 5s 29ms/step - loss: 40022777856.0000 - root_mean_squared_error: 200056.9375 - val_loss: 74718527488.0000 - val_root_mean_squared_error: 273346.9062\n",
      "Epoch 57/100\n",
      "191/191 [==============================] - 5s 28ms/step - loss: 39624220672.0000 - root_mean_squared_error: 199058.3438 - val_loss: 30402682880.0000 - val_root_mean_squared_error: 174363.6406\n",
      "Epoch 58/100\n",
      "191/191 [==============================] - 5s 27ms/step - loss: 39242096640.0000 - root_mean_squared_error: 198096.1719 - val_loss: 54025236480.0000 - val_root_mean_squared_error: 232433.2969\n",
      "Epoch 59/100\n",
      "191/191 [==============================] - 5s 28ms/step - loss: 38803251200.0000 - root_mean_squared_error: 196985.4062 - val_loss: 64712994816.0000 - val_root_mean_squared_error: 254387.4844\n",
      "Epoch 60/100\n",
      "191/191 [==============================] - 5s 27ms/step - loss: 38404472832.0000 - root_mean_squared_error: 195970.5938 - val_loss: 114850406400.0000 - val_root_mean_squared_error: 338895.8750\n",
      "Epoch 61/100\n",
      "191/191 [==============================] - 5s 28ms/step - loss: 38044766208.0000 - root_mean_squared_error: 195050.6719 - val_loss: 45925658624.0000 - val_root_mean_squared_error: 214302.7188\n",
      "Epoch 62/100\n",
      "191/191 [==============================] - 5s 27ms/step - loss: 37572947968.0000 - root_mean_squared_error: 193837.4219 - val_loss: 57529024512.0000 - val_root_mean_squared_error: 239852.0781\n",
      "Epoch 63/100\n",
      "191/191 [==============================] - 5s 28ms/step - loss: 37152927744.0000 - root_mean_squared_error: 192750.9375 - val_loss: 42538209280.0000 - val_root_mean_squared_error: 206247.9219\n",
      "Epoch 64/100\n",
      "191/191 [==============================] - 5s 27ms/step - loss: 36753555456.0000 - root_mean_squared_error: 191712.1719 - val_loss: 36169433088.0000 - val_root_mean_squared_error: 190182.6250\n",
      "Epoch 65/100\n",
      "191/191 [==============================] - 5s 28ms/step - loss: 36362489856.0000 - root_mean_squared_error: 190689.5156 - val_loss: 877214957568.0000 - val_root_mean_squared_error: 936597.5000\n",
      "Epoch 66/100\n",
      "191/191 [==============================] - 5s 28ms/step - loss: 35940368384.0000 - root_mean_squared_error: 189579.4531 - val_loss: 62868406272.0000 - val_root_mean_squared_error: 250735.7344\n",
      "Epoch 67/100\n",
      "191/191 [==============================] - 5s 28ms/step - loss: 35432771584.0000 - root_mean_squared_error: 188235.9531 - val_loss: 72135262208.0000 - val_root_mean_squared_error: 268580.0625\n",
      "Epoch 68/100\n",
      "191/191 [==============================] - 5s 28ms/step - loss: 35052474368.0000 - root_mean_squared_error: 187223.0625 - val_loss: 37996220416.0000 - val_root_mean_squared_error: 194926.1875\n",
      "Epoch 69/100\n",
      "191/191 [==============================] - 5s 28ms/step - loss: 34587152384.0000 - root_mean_squared_error: 185976.2031 - val_loss: 916237647872.0000 - val_root_mean_squared_error: 957203.0625\n",
      "Epoch 70/100\n",
      "191/191 [==============================] - 5s 28ms/step - loss: 34133248000.0000 - root_mean_squared_error: 184751.8594 - val_loss: 63345315840.0000 - val_root_mean_squared_error: 251684.9531\n",
      "Epoch 71/100\n",
      "191/191 [==============================] - 5s 28ms/step - loss: 33721067520.0000 - root_mean_squared_error: 183632.9688 - val_loss: 31166642176.0000 - val_root_mean_squared_error: 176540.7656\n",
      "Epoch 72/100\n",
      "191/191 [==============================] - 5s 28ms/step - loss: 33327736832.0000 - root_mean_squared_error: 182558.8594 - val_loss: 32443815936.0000 - val_root_mean_squared_error: 180121.6719\n"
     ]
    }
   ],
   "source": [
    "history = model0001.fit(x=x_train,  \n",
    "                    y=y_train, \n",
    "                    batch_size=BATCH_SIZE, \n",
    "                    epochs=EPOCHS,      \n",
    "                    verbose='auto', \n",
    "                    callbacks=[tf.keras.callbacks.\\\n",
    "                               EarlyStopping(monitor='val_loss',\n",
    "                                             patience=PATIENCE,\n",
    "                                             min_delta=PATIENCE_MIN_DELTA,\n",
    "                                             restore_best_weights=True),\n",
    "                            tensorboard_callback], \n",
    "                    validation_split=0.3, \n",
    "                    validation_data=None, \n",
    "                    shuffle=True,\n",
    "                    class_weight=None, \n",
    "                    sample_weight=None, \n",
    "                    initial_epoch=0, \n",
    "                    steps_per_epoch=None, \n",
    "                    validation_steps=None, \n",
    "                    validation_batch_size=10, \n",
    "                    validation_freq=1, \n",
    "                    max_queue_size=10, \n",
    "                    workers=5, \n",
    "                    use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b9c48dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "hy = pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d02d00aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hy[['root_mean_squared_error','val_root_mean_squared_error']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "edd259b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-07 04:40:05.801749: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 2022-01-06_21-27_exported_ca_housing_model/assets\n"
     ]
    }
   ],
   "source": [
    "model0001.save('2022-01-06_21-27_exported_ca_housing_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7bc0e3f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "val_root_mean_squared_error    174363.640625\n",
       "dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hy[['val_root_mean_squared_error']].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aa42bd49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "val_root_mean_squared_error    957203.0625\n",
       "dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hy[['val_root_mean_squared_error']].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ccf3d4dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "val_root_mean_squared_error    261018.08125\n",
       "dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hy[['val_root_mean_squared_error']][:5].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "17222f4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "val_root_mean_squared_error    352095.328125\n",
       "dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hy[['val_root_mean_squared_error']][-5:].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "56e73318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obviously this not a good run, overfitting, training data needs preprocessing, neural network. \n",
    "# architecture does not fit this specific problem, and several hyperparameters are way off,\n",
    "# but ths does demonstrate the API aand syntax.\n",
    "# I will post a better examle run later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026b1a70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
